{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SisFall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.layers import CuDNNLSTM, CuDNNGRU, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Import own methods\n",
    "\n",
    "import data_generator as dg\n",
    "import ml_utils as mlu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if GPU are avaliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Units detected by tensorflow: \n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13795587146589718848\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10313423258\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7916239476201271594\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n",
      "GPUs used by keras:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "from keras import backend as K\n",
    "\n",
    "print(\"Process Units detected by tensorflow: \")\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "\n",
    "print(\"GPUs used by keras:\")\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Divided (train - test) found. Loading...\n",
      "\n",
      "Data loaded correctly\n",
      "\n",
      "Estructuring data in blocks...\n",
      "\n",
      "Data generated correctly\n"
     ]
    }
   ],
   "source": [
    "dataTrWinValues, dataTrWinLabel, dataTestWinValues, dataTestWinLabel, dataWinOrganization = \\\n",
    "dg.loadDataSetInBlocks('../', nTestUsers=8, windowSize=256, stride=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 89631, 1: 1031, 2: 3380}\n",
      "89631 1031 3380\n",
      "[1, 86.93598448108632, 26.518047337278105]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(dataTrWinLabel, return_counts=True)\n",
    "\n",
    "dict_counts = dict(zip(unique,counts))\n",
    "print(dict_counts)\n",
    "\n",
    "N_bkg = dict_counts[0]\n",
    "N_alert = dict_counts[1]\n",
    "N_fall = dict_counts[2]\n",
    "\n",
    "print(N_bkg, N_alert, N_fall)\n",
    "\n",
    "w_bkg = 1\n",
    "w_alert = N_bkg / N_alert \n",
    "w_fall = N_bkg / N_fall\n",
    "\n",
    "target_weights = [w_bkg,w_alert,w_fall]\n",
    "print(target_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "#\n",
    "# The loss function implemented doesn't work with int targets\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "dataTrWinLabelOneHot = to_categorical(dataTrWinLabel)\n",
    "dataTestWinLabelOneHot = to_categorical(dataTestWinLabel)\n",
    "\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256, 32)           128       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256, 32)           128       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256, 32)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 256, 32)           8448      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256, 32)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)     (None, 32)                8448      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 17,251\n",
      "Trainable params: 17,187\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      " 8768/94042 [=>............................] - ETA: 2:06 - loss: 2.8184 - acc: 0.5075"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c6f691bd98dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmodel_paper_model_100ep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mhistory_paper_model_100ep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_paper_model_100ep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataTrWinValues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataTrWinLabelOneHot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataTestWinValues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataTestWinLabelOneHot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mresults_paper_model_100ep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_paper_model_100ep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataTestWinValues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_paper_model_100ep = Sequential()\n",
    "\n",
    "model_paper_model_100ep.add(Dense(32, batch_input_shape = (None, 256, 3)))\n",
    "\n",
    "model_paper_model_100ep.add(BatchNormalization())\n",
    "\n",
    "model_paper_model_100ep.add(Dropout(0.5))\n",
    "\n",
    "model_paper_model_100ep.add(CuDNNLSTM((32), return_sequences=True))\n",
    "\n",
    "model_paper_model_100ep.add(Dropout(0.5))\n",
    "\n",
    "model_paper_model_100ep.add(CuDNNLSTM((32)))\n",
    "\n",
    "model_paper_model_100ep.add(Dropout(0.5))\n",
    "\n",
    "model_paper_model_100ep.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model_paper_model_100ep.compile(optimizer='adam', loss=mlu.weighted_categorical_crossentropy(target_weights), metrics=['accuracy'])\n",
    "\n",
    "model_paper_model_100ep.summary()\n",
    "\n",
    "history_paper_model_100ep = model_paper_model_100ep.fit(dataTrWinValues[:,:,:3], dataTrWinLabelOneHot, epochs=100, validation_data = (dataTestWinValues[:,:,:3], dataTestWinLabelOneHot))\n",
    "\n",
    "results_paper_model_100ep = model_paper_model_100ep.predict(dataTestWinValues[:,:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_paper_model_100ep.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_paper_model_100ep.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_paper_model_100ep = confusion_matrix(dataTestWinLabel, np.argmax(results_paper_model_100ep, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[10085   494    40]\n",
      " [   18    67     3]\n",
      " [    9    24   296]]\n",
      "Normalized confusion matrix\n",
      "[[0.95 0.05 0.  ]\n",
      " [0.2  0.76 0.03]\n",
      " [0.03 0.07 0.9 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "mlu.plot_confusion_matrix(confusion_matrix_paper_model_100ep, classes=['BKG', 'ALERT', 'FALL'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "mlu.plot_confusion_matrix(confusion_matrix_paper_model_100ep, classes=['BKG', 'ALERT', 'FALL'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "model_paper_model_100ep.save('paper_model_100ep.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnngru_4 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,651\n",
      "Trainable params: 3,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 38s 404us/step - loss: 2.5136 - acc: 0.5923 - val_loss: 2.2657 - val_acc: 0.5930\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 39s 414us/step - loss: 1.9576 - acc: 0.6868 - val_loss: 2.1143 - val_acc: 0.6548\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 39s 413us/step - loss: 1.8048 - acc: 0.7413 - val_loss: 2.0783 - val_acc: 0.7061\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 38s 406us/step - loss: 1.7255 - acc: 0.7807 - val_loss: 2.3490 - val_acc: 0.7918\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 38s 403us/step - loss: 1.6591 - acc: 0.7986 - val_loss: 1.9212 - val_acc: 0.7308\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 38s 404us/step - loss: 1.5989 - acc: 0.8044 - val_loss: 1.8379 - val_acc: 0.7508\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 38s 405us/step - loss: 1.5362 - acc: 0.8251 - val_loss: 1.8243 - val_acc: 0.7858\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 1.5394 - acc: 0.8310 - val_loss: 1.8249 - val_acc: 0.7844\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 1.4829 - acc: 0.8333 - val_loss: 1.8562 - val_acc: 0.7784\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 39s 415us/step - loss: 1.4715 - acc: 0.8367 - val_loss: 1.7958 - val_acc: 0.8136\n",
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 1.4408 - acc: 0.8481 - val_loss: 1.7656 - val_acc: 0.7855\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 39s 410us/step - loss: 1.4423 - acc: 0.8450 - val_loss: 1.6809 - val_acc: 0.7800\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 38s 407us/step - loss: 1.4047 - acc: 0.8409 - val_loss: 1.7042 - val_acc: 0.7549\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 38s 408us/step - loss: 1.3711 - acc: 0.8445 - val_loss: 1.7114 - val_acc: 0.7476\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 38s 408us/step - loss: 1.3715 - acc: 0.8424 - val_loss: 1.8517 - val_acc: 0.7875\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 38s 407us/step - loss: 1.3622 - acc: 0.8483 - val_loss: 1.8316 - val_acc: 0.8289\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 39s 418us/step - loss: 1.3465 - acc: 0.8434 - val_loss: 1.6796 - val_acc: 0.8107\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 39s 415us/step - loss: 1.3727 - acc: 0.8456 - val_loss: 1.6390 - val_acc: 0.7840\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 38s 406us/step - loss: 1.3262 - acc: 0.8398 - val_loss: 1.5874 - val_acc: 0.7453\n",
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 1.3650 - acc: 0.8459 - val_loss: 1.6949 - val_acc: 0.7895\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 39s 410us/step - loss: 1.3331 - acc: 0.8447 - val_loss: 1.5224 - val_acc: 0.8044\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 39s 414us/step - loss: 1.3237 - acc: 0.8564 - val_loss: 1.5849 - val_acc: 0.7744\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 1.3040 - acc: 0.8540 - val_loss: 1.6259 - val_acc: 0.8046\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 39s 414us/step - loss: 1.2793 - acc: 0.8524 - val_loss: 1.6939 - val_acc: 0.7917\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 39s 420us/step - loss: 1.2801 - acc: 0.8560 - val_loss: 1.7214 - val_acc: 0.7639\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 39s 416us/step - loss: 1.2875 - acc: 0.8583 - val_loss: 1.7345 - val_acc: 0.8091\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 39s 415us/step - loss: 1.2802 - acc: 0.8586 - val_loss: 1.6281 - val_acc: 0.8339\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 1.2694 - acc: 0.8611 - val_loss: 1.9540 - val_acc: 0.7801\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 39s 413us/step - loss: 1.2944 - acc: 0.8593 - val_loss: 1.6352 - val_acc: 0.8420\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 1.2623 - acc: 0.8628 - val_loss: 1.5910 - val_acc: 0.8113\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 1.2784 - acc: 0.8630 - val_loss: 1.7423 - val_acc: 0.8279\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 38s 407us/step - loss: 1.2767 - acc: 0.8585 - val_loss: 1.8744 - val_acc: 0.8310\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 38s 408us/step - loss: 1.2394 - acc: 0.8611 - val_loss: 1.5659 - val_acc: 0.7888\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 38s 405us/step - loss: 1.2399 - acc: 0.8569 - val_loss: 1.6388 - val_acc: 0.7492\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 39s 410us/step - loss: 1.2640 - acc: 0.8530 - val_loss: 1.5725 - val_acc: 0.8148\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 38s 403us/step - loss: 1.2698 - acc: 0.8574 - val_loss: 1.4986 - val_acc: 0.8175\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 38s 400us/step - loss: 1.2209 - acc: 0.8644 - val_loss: 1.6495 - val_acc: 0.7797\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 38s 402us/step - loss: 1.2407 - acc: 0.8623 - val_loss: 1.6555 - val_acc: 0.8354\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 38s 405us/step - loss: 1.2429 - acc: 0.8601 - val_loss: 1.6722 - val_acc: 0.8406\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 38s 407us/step - loss: 1.2284 - acc: 0.8635 - val_loss: 1.5440 - val_acc: 0.8175\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 38s 405us/step - loss: 1.2219 - acc: 0.8577 - val_loss: 1.5655 - val_acc: 0.8106\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 39s 410us/step - loss: 1.2270 - acc: 0.8580 - val_loss: 1.6652 - val_acc: 0.8306\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 38s 404us/step - loss: 1.2510 - acc: 0.8595 - val_loss: 1.5410 - val_acc: 0.7830\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 38s 405us/step - loss: 1.2228 - acc: 0.8537 - val_loss: 1.6253 - val_acc: 0.7946\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 38s 405us/step - loss: 1.2607 - acc: 0.8570 - val_loss: 1.6048 - val_acc: 0.8395\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 38s 402us/step - loss: 1.2740 - acc: 0.8525 - val_loss: 1.5457 - val_acc: 0.7681\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 38s 403us/step - loss: 1.1921 - acc: 0.8577 - val_loss: 1.5845 - val_acc: 0.8060\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 38s 403us/step - loss: 1.1947 - acc: 0.8585 - val_loss: 1.5490 - val_acc: 0.7756\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 38s 400us/step - loss: 1.1834 - acc: 0.8622 - val_loss: 1.7265 - val_acc: 0.8333\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 39s 414us/step - loss: 1.2089 - acc: 0.8673 - val_loss: 1.5574 - val_acc: 0.8096\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 38s 408us/step - loss: 1.2132 - acc: 0.8640 - val_loss: 1.6828 - val_acc: 0.8159\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 38s 404us/step - loss: 1.2251 - acc: 0.8654 - val_loss: 1.6331 - val_acc: 0.8240\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 38s 401us/step - loss: 1.1683 - acc: 0.8690 - val_loss: 1.6851 - val_acc: 0.8483\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94042/94042 [==============================] - 38s 403us/step - loss: 1.1675 - acc: 0.8722 - val_loss: 1.6271 - val_acc: 0.8245\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 38s 404us/step - loss: 1.1930 - acc: 0.8661 - val_loss: 1.5740 - val_acc: 0.8301\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 38s 408us/step - loss: 1.1634 - acc: 0.8699 - val_loss: 1.5548 - val_acc: 0.8149\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 38s 408us/step - loss: 1.1942 - acc: 0.8717 - val_loss: 1.6357 - val_acc: 0.8065\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 39s 410us/step - loss: 1.2337 - acc: 0.8569 - val_loss: 1.7556 - val_acc: 0.8085\n",
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 38s 409us/step - loss: 1.2908 - acc: 0.8484 - val_loss: 1.6644 - val_acc: 0.7770\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 38s 404us/step - loss: 1.1984 - acc: 0.8634 - val_loss: 1.5975 - val_acc: 0.8132\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 38s 409us/step - loss: 1.1635 - acc: 0.8634 - val_loss: 1.6896 - val_acc: 0.7906\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 38s 405us/step - loss: 1.1873 - acc: 0.8608 - val_loss: 1.5843 - val_acc: 0.8020\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 1.2240 - acc: 0.8620 - val_loss: 1.6613 - val_acc: 0.7763\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 39s 410us/step - loss: 1.2536 - acc: 0.8583 - val_loss: 1.5175 - val_acc: 0.7813\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 38s 408us/step - loss: 1.1839 - acc: 0.8609 - val_loss: 1.6968 - val_acc: 0.8068\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 38s 407us/step - loss: 1.1689 - acc: 0.8609 - val_loss: 1.5910 - val_acc: 0.8118\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 38s 405us/step - loss: 1.1786 - acc: 0.8626 - val_loss: 1.6000 - val_acc: 0.8128\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 38s 405us/step - loss: 1.1739 - acc: 0.8663 - val_loss: 1.6142 - val_acc: 0.7901\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 38s 405us/step - loss: 1.1845 - acc: 0.8672 - val_loss: 1.7026 - val_acc: 0.8033\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 39s 411us/step - loss: 1.1566 - acc: 0.8713 - val_loss: 1.7347 - val_acc: 0.8173\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 39s 417us/step - loss: 1.1415 - acc: 0.8694 - val_loss: 1.5368 - val_acc: 0.8242\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 38s 409us/step - loss: 1.1370 - acc: 0.8695 - val_loss: 1.4972 - val_acc: 0.7970\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 38s 408us/step - loss: 1.1219 - acc: 0.8719 - val_loss: 1.4393 - val_acc: 0.7940\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 39s 413us/step - loss: 1.1275 - acc: 0.8684 - val_loss: 1.5257 - val_acc: 0.7932\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 38s 402us/step - loss: 1.1641 - acc: 0.8675 - val_loss: 1.5372 - val_acc: 0.8032\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 38s 404us/step - loss: 1.1308 - acc: 0.8698 - val_loss: 1.5373 - val_acc: 0.7766\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 38s 407us/step - loss: 1.1716 - acc: 0.8699 - val_loss: 1.4507 - val_acc: 0.8226\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 39s 416us/step - loss: 1.1904 - acc: 0.8626 - val_loss: 1.5954 - val_acc: 0.8203\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 39s 413us/step - loss: 1.1758 - acc: 0.8667 - val_loss: 1.6010 - val_acc: 0.8226\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 39s 415us/step - loss: 1.2257 - acc: 0.8672 - val_loss: 1.7308 - val_acc: 0.8238\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 1.1708 - acc: 0.8644 - val_loss: 1.8216 - val_acc: 0.8572\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 38s 407us/step - loss: 1.1967 - acc: 0.8683 - val_loss: 1.6180 - val_acc: 0.8124\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 38s 406us/step - loss: 1.1920 - acc: 0.8619 - val_loss: 1.5965 - val_acc: 0.7958\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 38s 407us/step - loss: 1.1709 - acc: 0.8647 - val_loss: 1.6280 - val_acc: 0.8201\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 39s 410us/step - loss: 1.1737 - acc: 0.8652 - val_loss: 1.6322 - val_acc: 0.8311\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 38s 404us/step - loss: 1.1570 - acc: 0.8662 - val_loss: 1.4962 - val_acc: 0.8101\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 38s 408us/step - loss: 1.1583 - acc: 0.8703 - val_loss: 1.5010 - val_acc: 0.8474\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 38s 407us/step - loss: 1.1414 - acc: 0.8735 - val_loss: 1.6508 - val_acc: 0.8539\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 38s 399us/step - loss: 1.1214 - acc: 0.8772 - val_loss: 1.5505 - val_acc: 0.8122\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 41s 436us/step - loss: 1.1331 - acc: 0.8760 - val_loss: 1.5617 - val_acc: 0.8638\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 38s 406us/step - loss: 1.1589 - acc: 0.8783 - val_loss: 1.6488 - val_acc: 0.8365\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 38s 405us/step - loss: 1.1961 - acc: 0.8710 - val_loss: 1.5655 - val_acc: 0.7956\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 39s 410us/step - loss: 1.1293 - acc: 0.8781 - val_loss: 1.6332 - val_acc: 0.8039\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 38s 406us/step - loss: 1.2071 - acc: 0.8737 - val_loss: 1.5928 - val_acc: 0.8078\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 38s 406us/step - loss: 1.1481 - acc: 0.8788 - val_loss: 1.5933 - val_acc: 0.7977\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 38s 409us/step - loss: 1.1261 - acc: 0.8775 - val_loss: 1.6605 - val_acc: 0.8284\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 37s 399us/step - loss: 1.1531 - acc: 0.8719 - val_loss: 1.6537 - val_acc: 0.7934\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 38s 407us/step - loss: 1.1572 - acc: 0.8736 - val_loss: 1.6424 - val_acc: 0.8040\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 37s 389us/step - loss: 1.1914 - acc: 0.8736 - val_loss: 1.5837 - val_acc: 0.7830\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 36s 381us/step - loss: 1.1695 - acc: 0.8766 - val_loss: 1.5054 - val_acc: 0.8353\n"
     ]
    }
   ],
   "source": [
    "model_without_batch_norm_100ep = Sequential()\n",
    "\n",
    "model_without_batch_norm_100ep.add(CuDNNGRU((32), batch_input_shape = (None, 256, 3)))\n",
    "\n",
    "model_without_batch_norm_100ep.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model_without_batch_norm_100ep.compile(optimizer=Adam(lr=0.0008), loss=mlu.weighted_categorical_crossentropy(target_weights), metrics=['accuracy'])\n",
    "\n",
    "model_without_batch_norm_100ep.summary()\n",
    "\n",
    "history_paper_model_100ep = model_without_batch_norm_100ep.fit(dataTrWinValues[:,:,:3], dataTrWinLabelOneHot, epochs=100, validation_data = (dataTestWinValues[:,:,:3], dataTestWinLabelOneHot))\n",
    "\n",
    "results_paper_model_100ep = model_without_batch_norm_100ep.predict(dataTestWinValues[:,:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_batch_norm_100ep.save('model_without_batch_norm_100ep.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_3 (Batch (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "cu_dnngru_5 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 42s 448us/step - loss: 2.5390 - acc: 0.5355 - val_loss: 2.6264 - val_acc: 0.7351\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 41s 438us/step - loss: 2.1759 - acc: 0.5973 - val_loss: 1.9283 - val_acc: 0.5978\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 42s 443us/step - loss: 1.7036 - acc: 0.6546 - val_loss: 1.6902 - val_acc: 0.6638\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 42s 443us/step - loss: 1.4417 - acc: 0.7383 - val_loss: 1.5288 - val_acc: 0.7101\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 42s 445us/step - loss: 1.3481 - acc: 0.7397 - val_loss: 1.3894 - val_acc: 0.7636\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 41s 434us/step - loss: 1.3329 - acc: 0.7544 - val_loss: 1.4064 - val_acc: 0.7910\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 41s 440us/step - loss: 1.1788 - acc: 0.8101 - val_loss: 1.3914 - val_acc: 0.8537\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 1.1449 - acc: 0.8240 - val_loss: 1.5373 - val_acc: 0.7104\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 1.0844 - acc: 0.8300 - val_loss: 1.2948 - val_acc: 0.8070\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 41s 436us/step - loss: 1.0202 - acc: 0.8674 - val_loss: 1.1470 - val_acc: 0.8364\n",
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 42s 446us/step - loss: 0.9365 - acc: 0.8859 - val_loss: 1.1772 - val_acc: 0.8240\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 41s 435us/step - loss: 0.9159 - acc: 0.8975 - val_loss: 1.0503 - val_acc: 0.8757\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 41s 438us/step - loss: 0.8549 - acc: 0.9014 - val_loss: 1.1141 - val_acc: 0.9081\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.8389 - acc: 0.9030 - val_loss: 1.0172 - val_acc: 0.8519\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.7690 - acc: 0.9198 - val_loss: 1.0259 - val_acc: 0.8686\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 0.7473 - acc: 0.9198 - val_loss: 1.0481 - val_acc: 0.8794\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 0.7291 - acc: 0.9151 - val_loss: 1.1791 - val_acc: 0.9273\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.7218 - acc: 0.9176 - val_loss: 0.9915 - val_acc: 0.9026\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 41s 436us/step - loss: 0.6994 - acc: 0.9183 - val_loss: 0.8791 - val_acc: 0.9201\n",
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 41s 435us/step - loss: 0.6818 - acc: 0.9213 - val_loss: 0.8658 - val_acc: 0.9250\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 41s 438us/step - loss: 0.6530 - acc: 0.9244 - val_loss: 0.9521 - val_acc: 0.9165\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 41s 439us/step - loss: 0.6632 - acc: 0.9225 - val_loss: 0.9782 - val_acc: 0.9070\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 41s 435us/step - loss: 0.6491 - acc: 0.9276 - val_loss: 1.0577 - val_acc: 0.9117\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6427 - acc: 0.9277 - val_loss: 1.1146 - val_acc: 0.8973\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.6193 - acc: 0.9297 - val_loss: 0.9560 - val_acc: 0.9051\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6637 - acc: 0.9129 - val_loss: 0.8420 - val_acc: 0.8956\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5975 - acc: 0.9284 - val_loss: 0.9090 - val_acc: 0.9037\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5912 - acc: 0.9297 - val_loss: 0.8080 - val_acc: 0.8938\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5788 - acc: 0.9319 - val_loss: 0.8467 - val_acc: 0.9279\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5859 - acc: 0.9309 - val_loss: 1.0174 - val_acc: 0.9191\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 39s 417us/step - loss: 0.5822 - acc: 0.9279 - val_loss: 0.9346 - val_acc: 0.9185\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 39s 418us/step - loss: 0.5556 - acc: 0.9283 - val_loss: 0.9158 - val_acc: 0.9181\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 39s 416us/step - loss: 0.5692 - acc: 0.9307 - val_loss: 0.9692 - val_acc: 0.9271\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 39s 417us/step - loss: 0.5528 - acc: 0.9327 - val_loss: 0.8446 - val_acc: 0.8934\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 39s 418us/step - loss: 0.5414 - acc: 0.9350 - val_loss: 1.0877 - val_acc: 0.9388\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 40s 420us/step - loss: 0.5479 - acc: 0.9346 - val_loss: 0.8644 - val_acc: 0.9080\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.5479 - acc: 0.9342 - val_loss: 0.8929 - val_acc: 0.9046\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.5434 - acc: 0.9321 - val_loss: 0.9817 - val_acc: 0.9194\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 39s 418us/step - loss: 0.5264 - acc: 0.9358 - val_loss: 0.9277 - val_acc: 0.9185\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 39s 418us/step - loss: 0.5300 - acc: 0.9338 - val_loss: 0.8237 - val_acc: 0.9270\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 39s 418us/step - loss: 0.5090 - acc: 0.9369 - val_loss: 0.9118 - val_acc: 0.9372\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.5010 - acc: 0.9347 - val_loss: 0.8315 - val_acc: 0.9163\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 39s 420us/step - loss: 0.5271 - acc: 0.9339 - val_loss: 0.8442 - val_acc: 0.9295\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4895 - acc: 0.9386 - val_loss: 0.9181 - val_acc: 0.9409\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 39s 417us/step - loss: 0.4831 - acc: 0.9377 - val_loss: 0.8875 - val_acc: 0.8820\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 39s 420us/step - loss: 0.4925 - acc: 0.9330 - val_loss: 0.8787 - val_acc: 0.9373\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.5166 - acc: 0.9293 - val_loss: 1.0261 - val_acc: 0.8821\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 39s 418us/step - loss: 0.4997 - acc: 0.9344 - val_loss: 0.8447 - val_acc: 0.9371\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 39s 420us/step - loss: 0.4955 - acc: 0.9364 - val_loss: 1.0497 - val_acc: 0.9348\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 39s 418us/step - loss: 0.4991 - acc: 0.9361 - val_loss: 0.9596 - val_acc: 0.9461\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 39s 418us/step - loss: 0.4986 - acc: 0.9356 - val_loss: 0.9984 - val_acc: 0.9304\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4769 - acc: 0.9385 - val_loss: 1.0603 - val_acc: 0.9329\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94042/94042 [==============================] - 39s 420us/step - loss: 0.4673 - acc: 0.9382 - val_loss: 1.0244 - val_acc: 0.9235\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.4843 - acc: 0.9364 - val_loss: 1.1919 - val_acc: 0.9229\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 39s 420us/step - loss: 0.5033 - acc: 0.9308 - val_loss: 0.9068 - val_acc: 0.9299\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 40s 420us/step - loss: 0.4619 - acc: 0.9383 - val_loss: 0.8631 - val_acc: 0.9151\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4848 - acc: 0.9338 - val_loss: 1.1591 - val_acc: 0.9097\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.4675 - acc: 0.9359 - val_loss: 1.0784 - val_acc: 0.9326\n",
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 39s 420us/step - loss: 0.4620 - acc: 0.9381 - val_loss: 1.0293 - val_acc: 0.9362\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.5022 - acc: 0.9365 - val_loss: 1.0313 - val_acc: 0.9406\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.4704 - acc: 0.9409 - val_loss: 1.0034 - val_acc: 0.9229\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4731 - acc: 0.9367 - val_loss: 1.0957 - val_acc: 0.8744\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 39s 418us/step - loss: 0.4515 - acc: 0.9369 - val_loss: 1.1010 - val_acc: 0.9350\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.4634 - acc: 0.9388 - val_loss: 1.0061 - val_acc: 0.9352\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4675 - acc: 0.9348 - val_loss: 1.0874 - val_acc: 0.9365\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4341 - acc: 0.9404 - val_loss: 1.3233 - val_acc: 0.8988\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 39s 416us/step - loss: 0.4725 - acc: 0.9361 - val_loss: 1.1462 - val_acc: 0.9362\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4587 - acc: 0.9386 - val_loss: 0.9894 - val_acc: 0.9156\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 39s 420us/step - loss: 0.4508 - acc: 0.9380 - val_loss: 1.0770 - val_acc: 0.9327\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 40s 420us/step - loss: 0.4563 - acc: 0.9369 - val_loss: 1.0544 - val_acc: 0.9437\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4539 - acc: 0.9354 - val_loss: 1.1788 - val_acc: 0.9353\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4444 - acc: 0.9351 - val_loss: 0.9034 - val_acc: 0.9204\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.4445 - acc: 0.9399 - val_loss: 0.9962 - val_acc: 0.9168\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 40s 420us/step - loss: 0.4491 - acc: 0.9386 - val_loss: 0.9511 - val_acc: 0.9275\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4438 - acc: 0.9381 - val_loss: 1.0102 - val_acc: 0.9282\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 39s 418us/step - loss: 0.4379 - acc: 0.9411 - val_loss: 1.0494 - val_acc: 0.9176\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 39s 418us/step - loss: 0.4531 - acc: 0.9362 - val_loss: 0.9662 - val_acc: 0.9340\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4414 - acc: 0.9400 - val_loss: 0.8683 - val_acc: 0.9269\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4179 - acc: 0.9419 - val_loss: 0.9346 - val_acc: 0.9197\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4439 - acc: 0.9435 - val_loss: 1.0687 - val_acc: 0.9467\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4472 - acc: 0.9410 - val_loss: 1.0300 - val_acc: 0.9397\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.4204 - acc: 0.9424 - val_loss: 1.0261 - val_acc: 0.9141\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 39s 417us/step - loss: 0.4201 - acc: 0.9398 - val_loss: 1.2944 - val_acc: 0.9284\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 39s 418us/step - loss: 0.4462 - acc: 0.9361 - val_loss: 0.8593 - val_acc: 0.9226\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4487 - acc: 0.9392 - val_loss: 0.9801 - val_acc: 0.9180\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 39s 417us/step - loss: 0.4137 - acc: 0.9413 - val_loss: 1.2902 - val_acc: 0.9374\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4089 - acc: 0.9417 - val_loss: 1.1460 - val_acc: 0.9349\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 39s 420us/step - loss: 0.4398 - acc: 0.9405 - val_loss: 0.9892 - val_acc: 0.9111\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4264 - acc: 0.9415 - val_loss: 1.0451 - val_acc: 0.9386\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4147 - acc: 0.9427 - val_loss: 1.0162 - val_acc: 0.9247\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 40s 420us/step - loss: 0.4364 - acc: 0.9412 - val_loss: 0.9149 - val_acc: 0.9080\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.3948 - acc: 0.9441 - val_loss: 1.2100 - val_acc: 0.9382\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 39s 420us/step - loss: 0.4335 - acc: 0.9395 - val_loss: 1.2087 - val_acc: 0.9253\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 39s 417us/step - loss: 0.3983 - acc: 0.9433 - val_loss: 1.2420 - val_acc: 0.8715\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4154 - acc: 0.9380 - val_loss: 0.9230 - val_acc: 0.9403\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.3961 - acc: 0.9458 - val_loss: 1.1345 - val_acc: 0.9408\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 39s 418us/step - loss: 0.4057 - acc: 0.9419 - val_loss: 1.1104 - val_acc: 0.9260\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 39s 418us/step - loss: 0.4188 - acc: 0.9429 - val_loss: 1.0859 - val_acc: 0.9473\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.4131 - acc: 0.9414 - val_loss: 1.3623 - val_acc: 0.9423\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.4046 - acc: 0.9418 - val_loss: 1.1033 - val_acc: 0.9310\n"
     ]
    }
   ],
   "source": [
    "model_with_batch_norm_100ep = Sequential()\n",
    "\n",
    "model_with_batch_norm_100ep.add(BatchNormalization(batch_input_shape = (None, 256, 3)))\n",
    "\n",
    "model_with_batch_norm_100ep.add(CuDNNGRU((32)))\n",
    "\n",
    "model_with_batch_norm_100ep.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model_with_batch_norm_100ep.compile(optimizer=Adam(lr=0.0008), loss=mlu.weighted_categorical_crossentropy(target_weights), metrics=['accuracy'])\n",
    "\n",
    "model_with_batch_norm_100ep.summary()\n",
    "\n",
    "history_paper_model_100ep = model_with_batch_norm_100ep.fit(dataTrWinValues[:,:,:3], dataTrWinLabelOneHot, epochs=100, validation_data = (dataTestWinValues[:,:,:3], dataTestWinLabelOneHot))\n",
    "\n",
    "results_paper_model_100ep = model_with_batch_norm_100ep.predict(dataTestWinValues[:,:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_batch_norm_100ep.save('model_with_batch_norm_100ep.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RnnMmodel(w = 256, rnn_type = 'lstm', two_rnn_layers=False, drop_coeff_rnn=0.2, drop_coeff_dense=0.5, first_dense=True):\n",
    "    \n",
    "    if not (rnn_type == 'lstm' or rnn_type == 'gru'):\n",
    "        print(\"rnn_type must be 'lstm' o  'gru'\")\n",
    "        return\n",
    "    \n",
    "    rnn_model = Sequential()\n",
    "    if (first_dense):\n",
    "        rnn_model.add(Dense(32, batch_input_shape = (None, w, 3)))\n",
    "        rnn_model.add(BatchNormalization())\n",
    "    else:\n",
    "        rnn_model.add(BatchNormalization(batch_input_shape = (None, w, 3)))\n",
    "    \n",
    "    rnn_model.add(Dropout(drop_coeff_rnn))\n",
    "    \n",
    "    if two_rnn_layers:\n",
    "        \n",
    "        if rnn_type == 'lstm':\n",
    "            rnn_model.add(CuDNNLSTM((32), return_sequences=True))\n",
    "        elif rnn_type == 'gru':\n",
    "            rnn_model.add(CuDNNGRU((32), return_sequences=True))\n",
    "        \n",
    "        if(drop_coeff_rnn != 0):\n",
    "            rnn_model.add(Dropout(drop_coeff_rnn))\n",
    "    \n",
    "    if rnn_type == 'lstm':\n",
    "        rnn_model.add(CuDNNLSTM((32)))\n",
    "    elif rnn_type == 'gru':\n",
    "        rnn_model.add(CuDNNGRU((32)))\n",
    "    \n",
    "    if(drop_coeff_dense !=0):\n",
    "        rnn_model.add(Dropout(drop_coeff_dense))\n",
    "    \n",
    "    rnn_model.add(Dense(3,activation='softmax'))\n",
    "    \n",
    "    return rnn_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainRNNModel(dataTrVal, dataTrLab, dataTestVal, dataTestLab, epochs = 100, lr=0.001, w = 256, stride = 128, batch_size = 32, rnn_type = 'lstm', two_rnn_layers=False, drop_coeff_rnn=0.2, drop_coeff_dense=0.5, first_dense=True):\n",
    "    \n",
    "    dataTrLabelOneHot = to_categorical(dataTrLab)\n",
    "    dataTestLabelOneHot = to_categorical(dataTestLab)\n",
    "    \n",
    "    model = RnnMmodel(w, rnn_type, two_rnn_layers, drop_coeff_rnn, drop_coeff_dense, first_dense)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model_json = model.to_json()\n",
    "    \n",
    "    opt_adam = Adam(lr=lr)\n",
    "    \n",
    "    model.compile(optimizer=opt_adam, loss=mlu.weighted_categorical_crossentropy(target_weights), metrics=['accuracy'])\n",
    "\n",
    "    model_json = model.to_json()\n",
    "\n",
    "    model_train_history = model.fit(dataTrVal, dataTrLabelOneHot, batch_size=batch_size, epochs=epochs, validation_data = (dataTestVal, dataTestLabelOneHot))\n",
    "\n",
    "    model_prediction = model.predict(dataTestVal)\n",
    "\n",
    "    model_confusion_matrix = confusion_matrix(dataTestLab, np.argmax(model_prediction, axis = 1))\n",
    "\n",
    "    return model, model_train_history, model_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_3 (Batch (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 32)                4736      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,847\n",
      "Trainable params: 4,841\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/125\n",
      "94042/94042 [==============================] - 16s 173us/step - loss: 2.5116 - acc: 0.5136 - val_loss: 2.5016 - val_acc: 0.6859\n",
      "Epoch 2/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 2.4187 - acc: 0.5091 - val_loss: 2.5466 - val_acc: 0.0940\n",
      "Epoch 3/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 2.3682 - acc: 0.4531 - val_loss: 2.4131 - val_acc: 0.5007\n",
      "Epoch 4/125\n",
      "94042/94042 [==============================] - 16s 170us/step - loss: 2.3214 - acc: 0.5299 - val_loss: 2.3253 - val_acc: 0.1993\n",
      "Epoch 5/125\n",
      "94042/94042 [==============================] - 16s 166us/step - loss: 2.3117 - acc: 0.4813 - val_loss: 2.3367 - val_acc: 0.5994\n",
      "Epoch 6/125\n",
      "94042/94042 [==============================] - 16s 170us/step - loss: 2.3032 - acc: 0.5526 - val_loss: 2.2576 - val_acc: 0.4630\n",
      "Epoch 7/125\n",
      "94042/94042 [==============================] - 17s 184us/step - loss: 2.2074 - acc: 0.5392 - val_loss: 2.2219 - val_acc: 0.5612\n",
      "Epoch 8/125\n",
      "94042/94042 [==============================] - 17s 182us/step - loss: 2.1227 - acc: 0.6049 - val_loss: 2.2563 - val_acc: 0.5051\n",
      "Epoch 9/125\n",
      "94042/94042 [==============================] - 18s 190us/step - loss: 2.0617 - acc: 0.5543 - val_loss: 2.3627 - val_acc: 0.7362\n",
      "Epoch 10/125\n",
      "94042/94042 [==============================] - 18s 187us/step - loss: 1.8187 - acc: 0.7130 - val_loss: 2.4441 - val_acc: 0.3415\n",
      "Epoch 11/125\n",
      "94042/94042 [==============================] - 17s 186us/step - loss: 1.9163 - acc: 0.6060 - val_loss: 2.0719 - val_acc: 0.6044\n",
      "Epoch 12/125\n",
      "94042/94042 [==============================] - 18s 195us/step - loss: 1.8429 - acc: 0.6222 - val_loss: 1.9366 - val_acc: 0.5173\n",
      "Epoch 13/125\n",
      "94042/94042 [==============================] - 18s 196us/step - loss: 2.0163 - acc: 0.5255 - val_loss: 2.6906 - val_acc: 0.7060\n",
      "Epoch 14/125\n",
      "94042/94042 [==============================] - 18s 192us/step - loss: 1.9175 - acc: 0.6321 - val_loss: 1.7871 - val_acc: 0.7568\n",
      "Epoch 15/125\n",
      "94042/94042 [==============================] - 17s 184us/step - loss: 1.9226 - acc: 0.6394 - val_loss: 2.0312 - val_acc: 0.5126\n",
      "Epoch 16/125\n",
      "94042/94042 [==============================] - 18s 194us/step - loss: 1.8836 - acc: 0.6102 - val_loss: 2.0227 - val_acc: 0.7972\n",
      "Epoch 17/125\n",
      "94042/94042 [==============================] - 18s 187us/step - loss: 1.6822 - acc: 0.7029 - val_loss: 1.7113 - val_acc: 0.8140\n",
      "Epoch 18/125\n",
      "94042/94042 [==============================] - 18s 192us/step - loss: 1.5412 - acc: 0.7505 - val_loss: 1.6201 - val_acc: 0.7894\n",
      "Epoch 19/125\n",
      "94042/94042 [==============================] - 18s 192us/step - loss: 1.5330 - acc: 0.7801 - val_loss: 1.7961 - val_acc: 0.8025\n",
      "Epoch 20/125\n",
      "94042/94042 [==============================] - 17s 180us/step - loss: 1.5381 - acc: 0.8045 - val_loss: 1.6247 - val_acc: 0.8226\n",
      "Epoch 21/125\n",
      "94042/94042 [==============================] - 17s 185us/step - loss: 1.4778 - acc: 0.7774 - val_loss: 1.5342 - val_acc: 0.7601\n",
      "Epoch 22/125\n",
      "94042/94042 [==============================] - 17s 177us/step - loss: 1.4543 - acc: 0.7860 - val_loss: 1.6045 - val_acc: 0.8281\n",
      "Epoch 23/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 1.4685 - acc: 0.7547 - val_loss: 1.6020 - val_acc: 0.7881\n",
      "Epoch 24/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 1.4041 - acc: 0.7918 - val_loss: 1.4725 - val_acc: 0.8039\n",
      "Epoch 25/125\n",
      "94042/94042 [==============================] - 15s 162us/step - loss: 1.3448 - acc: 0.7890 - val_loss: 1.6132 - val_acc: 0.7474\n",
      "Epoch 26/125\n",
      "94042/94042 [==============================] - 15s 162us/step - loss: 1.3536 - acc: 0.7980 - val_loss: 1.5273 - val_acc: 0.7757\n",
      "Epoch 27/125\n",
      "94042/94042 [==============================] - 16s 170us/step - loss: 1.3596 - acc: 0.7790 - val_loss: 2.0313 - val_acc: 0.4957\n",
      "Epoch 28/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 1.8974 - acc: 0.6132 - val_loss: 1.9663 - val_acc: 0.6500\n",
      "Epoch 29/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 1.7727 - acc: 0.6726 - val_loss: 1.8953 - val_acc: 0.7404\n",
      "Epoch 30/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 1.4694 - acc: 0.6996 - val_loss: 1.4989 - val_acc: 0.7595\n",
      "Epoch 31/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 1.2677 - acc: 0.7916 - val_loss: 1.3635 - val_acc: 0.8126\n",
      "Epoch 32/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 1.2238 - acc: 0.8093 - val_loss: 1.2801 - val_acc: 0.7902\n",
      "Epoch 33/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 1.2843 - acc: 0.7917 - val_loss: 1.4345 - val_acc: 0.7764\n",
      "Epoch 34/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 1.3605 - acc: 0.7606 - val_loss: 1.3500 - val_acc: 0.8102\n",
      "Epoch 35/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 1.2401 - acc: 0.8120 - val_loss: 1.3037 - val_acc: 0.8842\n",
      "Epoch 36/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 1.1951 - acc: 0.8381 - val_loss: 1.3796 - val_acc: 0.8304\n",
      "Epoch 37/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 1.2453 - acc: 0.8272 - val_loss: 1.3130 - val_acc: 0.8211\n",
      "Epoch 38/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 1.1473 - acc: 0.8384 - val_loss: 1.1762 - val_acc: 0.8796\n",
      "Epoch 39/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 1.2661 - acc: 0.8396 - val_loss: 1.5441 - val_acc: 0.8520\n",
      "Epoch 40/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 1.1189 - acc: 0.8489 - val_loss: 1.2044 - val_acc: 0.9101\n",
      "Epoch 41/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 1.1148 - acc: 0.8635 - val_loss: 1.2410 - val_acc: 0.8999\n",
      "Epoch 42/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 1.0969 - acc: 0.8662 - val_loss: 1.2568 - val_acc: 0.9252\n",
      "Epoch 43/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 1.1699 - acc: 0.8210 - val_loss: 1.2539 - val_acc: 0.9249\n",
      "Epoch 44/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 1.0822 - acc: 0.8733 - val_loss: 1.1151 - val_acc: 0.8943\n",
      "Epoch 45/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 1.2204 - acc: 0.7903 - val_loss: 1.3164 - val_acc: 0.7551\n",
      "Epoch 46/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 1.1031 - acc: 0.8428 - val_loss: 1.1817 - val_acc: 0.8944\n",
      "Epoch 47/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 1.0257 - acc: 0.8932 - val_loss: 1.1592 - val_acc: 0.9046\n",
      "Epoch 48/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 1.0137 - acc: 0.8692 - val_loss: 1.0589 - val_acc: 0.9146\n",
      "Epoch 49/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 0.9408 - acc: 0.8963 - val_loss: 1.0624 - val_acc: 0.9366\n",
      "Epoch 50/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 0.9403 - acc: 0.9100 - val_loss: 1.0658 - val_acc: 0.9238\n",
      "Epoch 51/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 0.9426 - acc: 0.9041 - val_loss: 1.1485 - val_acc: 0.9490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/125\n",
      "94042/94042 [==============================] - 15s 162us/step - loss: 0.9750 - acc: 0.8863 - val_loss: 1.1099 - val_acc: 0.9090\n",
      "Epoch 53/125\n",
      "94042/94042 [==============================] - 16s 175us/step - loss: 0.8994 - acc: 0.9017 - val_loss: 1.1062 - val_acc: 0.9328\n",
      "Epoch 54/125\n",
      "94042/94042 [==============================] - 16s 165us/step - loss: 0.8523 - acc: 0.9194 - val_loss: 1.1849 - val_acc: 0.9508\n",
      "Epoch 55/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 0.9354 - acc: 0.9107 - val_loss: 1.0262 - val_acc: 0.9411\n",
      "Epoch 56/125\n",
      "94042/94042 [==============================] - 17s 178us/step - loss: 0.8740 - acc: 0.9269 - val_loss: 1.0719 - val_acc: 0.8946\n",
      "Epoch 57/125\n",
      "94042/94042 [==============================] - 16s 165us/step - loss: 0.8563 - acc: 0.9144 - val_loss: 1.0512 - val_acc: 0.8719\n",
      "Epoch 58/125\n",
      "94042/94042 [==============================] - 15s 159us/step - loss: 0.8710 - acc: 0.9064 - val_loss: 1.0385 - val_acc: 0.9245\n",
      "Epoch 59/125\n",
      "94042/94042 [==============================] - 15s 162us/step - loss: 0.9117 - acc: 0.9009 - val_loss: 1.0330 - val_acc: 0.9432\n",
      "Epoch 60/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 0.8364 - acc: 0.9240 - val_loss: 1.1056 - val_acc: 0.9429\n",
      "Epoch 61/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 0.8148 - acc: 0.9331 - val_loss: 0.9974 - val_acc: 0.9348\n",
      "Epoch 62/125\n",
      "94042/94042 [==============================] - 16s 167us/step - loss: 0.7823 - acc: 0.9300 - val_loss: 1.0410 - val_acc: 0.9466\n",
      "Epoch 63/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 0.8479 - acc: 0.9205 - val_loss: 1.0119 - val_acc: 0.9431\n",
      "Epoch 64/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 0.7876 - acc: 0.9195 - val_loss: 1.0328 - val_acc: 0.9487\n",
      "Epoch 65/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 0.8076 - acc: 0.9238 - val_loss: 1.0324 - val_acc: 0.9549\n",
      "Epoch 66/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 0.7836 - acc: 0.9346 - val_loss: 0.9655 - val_acc: 0.9559\n",
      "Epoch 67/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 0.7997 - acc: 0.9214 - val_loss: 1.0519 - val_acc: 0.9564\n",
      "Epoch 68/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 0.7586 - acc: 0.9358 - val_loss: 1.0018 - val_acc: 0.9458\n",
      "Epoch 69/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 0.7593 - acc: 0.9325 - val_loss: 0.9967 - val_acc: 0.9400\n",
      "Epoch 70/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 0.7665 - acc: 0.9217 - val_loss: 1.0084 - val_acc: 0.9373\n",
      "Epoch 71/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 0.7743 - acc: 0.9307 - val_loss: 1.0233 - val_acc: 0.9505\n",
      "Epoch 72/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 0.7536 - acc: 0.9371 - val_loss: 1.2166 - val_acc: 0.9530\n",
      "Epoch 73/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 0.7515 - acc: 0.9298 - val_loss: 1.0210 - val_acc: 0.9475\n",
      "Epoch 74/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 0.7440 - acc: 0.9219 - val_loss: 1.0024 - val_acc: 0.9498\n",
      "Epoch 75/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 0.7186 - acc: 0.9332 - val_loss: 1.0759 - val_acc: 0.9532\n",
      "Epoch 76/125\n",
      "94042/94042 [==============================] - 15s 162us/step - loss: 0.7354 - acc: 0.9130 - val_loss: 1.0872 - val_acc: 0.9533\n",
      "Epoch 77/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 0.6992 - acc: 0.9286 - val_loss: 1.0268 - val_acc: 0.9500\n",
      "Epoch 78/125\n",
      "94042/94042 [==============================] - 15s 162us/step - loss: 0.6846 - acc: 0.9286 - val_loss: 1.1449 - val_acc: 0.9454\n",
      "Epoch 79/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 0.6997 - acc: 0.9238 - val_loss: 1.0082 - val_acc: 0.9411\n",
      "Epoch 80/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 0.6651 - acc: 0.9305 - val_loss: 1.0540 - val_acc: 0.9486\n",
      "Epoch 81/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 0.7171 - acc: 0.9346 - val_loss: 1.0777 - val_acc: 0.9509\n",
      "Epoch 82/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 0.6778 - acc: 0.9331 - val_loss: 1.0243 - val_acc: 0.9535\n",
      "Epoch 83/125\n",
      "94042/94042 [==============================] - 16s 175us/step - loss: 0.6883 - acc: 0.9308 - val_loss: 1.0037 - val_acc: 0.9375\n",
      "Epoch 84/125\n",
      "94042/94042 [==============================] - 16s 168us/step - loss: 0.6798 - acc: 0.9309 - val_loss: 1.3401 - val_acc: 0.9516\n",
      "Epoch 85/125\n",
      "94042/94042 [==============================] - 16s 168us/step - loss: 0.6962 - acc: 0.9302 - val_loss: 1.1020 - val_acc: 0.9467\n",
      "Epoch 86/125\n",
      "94042/94042 [==============================] - 16s 168us/step - loss: 0.6777 - acc: 0.9292 - val_loss: 1.0128 - val_acc: 0.9361\n",
      "Epoch 87/125\n",
      "94042/94042 [==============================] - 16s 166us/step - loss: 0.7367 - acc: 0.9303 - val_loss: 0.9994 - val_acc: 0.9457\n",
      "Epoch 88/125\n",
      "94042/94042 [==============================] - 16s 166us/step - loss: 0.6957 - acc: 0.9256 - val_loss: 1.0195 - val_acc: 0.9518\n",
      "Epoch 89/125\n",
      "94042/94042 [==============================] - 16s 166us/step - loss: 0.6488 - acc: 0.9357 - val_loss: 0.9746 - val_acc: 0.9462\n",
      "Epoch 90/125\n",
      "94042/94042 [==============================] - 16s 168us/step - loss: 0.6749 - acc: 0.9344 - val_loss: 1.0621 - val_acc: 0.9534\n",
      "Epoch 91/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 0.6591 - acc: 0.9277 - val_loss: 1.0920 - val_acc: 0.9532\n",
      "Epoch 92/125\n",
      "94042/94042 [==============================] - 15s 162us/step - loss: 0.6379 - acc: 0.9305 - val_loss: 0.9936 - val_acc: 0.9482\n",
      "Epoch 93/125\n",
      "94042/94042 [==============================] - 15s 159us/step - loss: 0.6627 - acc: 0.9283 - val_loss: 1.1491 - val_acc: 0.9377\n",
      "Epoch 94/125\n",
      "94042/94042 [==============================] - 15s 156us/step - loss: 0.6604 - acc: 0.9292 - val_loss: 1.2499 - val_acc: 0.9431\n",
      "Epoch 95/125\n",
      "94042/94042 [==============================] - 15s 156us/step - loss: 0.6642 - acc: 0.9328 - val_loss: 1.1003 - val_acc: 0.9436\n",
      "Epoch 96/125\n",
      "94042/94042 [==============================] - 15s 157us/step - loss: 0.7006 - acc: 0.9273 - val_loss: 0.9673 - val_acc: 0.9409\n",
      "Epoch 97/125\n",
      "94042/94042 [==============================] - 15s 157us/step - loss: 0.6350 - acc: 0.9313 - val_loss: 1.0276 - val_acc: 0.9447\n",
      "Epoch 98/125\n",
      "94042/94042 [==============================] - 15s 158us/step - loss: 0.6815 - acc: 0.9271 - val_loss: 1.1369 - val_acc: 0.8742\n",
      "Epoch 99/125\n",
      "94042/94042 [==============================] - 15s 155us/step - loss: 0.6706 - acc: 0.9196 - val_loss: 1.0001 - val_acc: 0.9195\n",
      "Epoch 100/125\n",
      "94042/94042 [==============================] - 15s 159us/step - loss: 0.6830 - acc: 0.9160 - val_loss: 1.1377 - val_acc: 0.9553\n",
      "Epoch 101/125\n",
      "94042/94042 [==============================] - 15s 159us/step - loss: 0.5966 - acc: 0.9307 - val_loss: 1.1747 - val_acc: 0.9511\n",
      "Epoch 102/125\n",
      "94042/94042 [==============================] - 15s 157us/step - loss: 0.6180 - acc: 0.9393 - val_loss: 1.3440 - val_acc: 0.9525\n",
      "Epoch 103/125\n",
      "94042/94042 [==============================] - 15s 157us/step - loss: 0.6577 - acc: 0.9274 - val_loss: 0.9336 - val_acc: 0.9188\n",
      "Epoch 104/125\n",
      "94042/94042 [==============================] - 15s 155us/step - loss: 0.6452 - acc: 0.9294 - val_loss: 1.0328 - val_acc: 0.9308\n",
      "Epoch 105/125\n",
      "94042/94042 [==============================] - 15s 157us/step - loss: 0.6460 - acc: 0.9267 - val_loss: 1.1396 - val_acc: 0.8553\n",
      "Epoch 106/125\n",
      "94042/94042 [==============================] - 15s 156us/step - loss: 0.6395 - acc: 0.9256 - val_loss: 1.1214 - val_acc: 0.9460\n",
      "Epoch 107/125\n",
      "94042/94042 [==============================] - 15s 155us/step - loss: 0.6675 - acc: 0.9288 - val_loss: 1.0070 - val_acc: 0.9433\n",
      "Epoch 108/125\n",
      "94042/94042 [==============================] - 15s 155us/step - loss: 0.6544 - acc: 0.9353 - val_loss: 1.1437 - val_acc: 0.9435\n",
      "Epoch 109/125\n",
      "94042/94042 [==============================] - 15s 155us/step - loss: 0.6485 - acc: 0.9340 - val_loss: 1.2648 - val_acc: 0.9530\n",
      "Epoch 110/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94042/94042 [==============================] - 15s 155us/step - loss: 0.5915 - acc: 0.9384 - val_loss: 0.9267 - val_acc: 0.9445\n",
      "Epoch 111/125\n",
      "94042/94042 [==============================] - 15s 156us/step - loss: 0.6193 - acc: 0.9339 - val_loss: 0.9645 - val_acc: 0.9397\n",
      "Epoch 112/125\n",
      "94042/94042 [==============================] - 15s 157us/step - loss: 0.6675 - acc: 0.9288 - val_loss: 1.1903 - val_acc: 0.9499\n",
      "Epoch 113/125\n",
      "94042/94042 [==============================] - 15s 157us/step - loss: 0.6174 - acc: 0.9366 - val_loss: 1.1444 - val_acc: 0.9247\n",
      "Epoch 114/125\n",
      "94042/94042 [==============================] - 15s 156us/step - loss: 0.6699 - acc: 0.9303 - val_loss: 0.9488 - val_acc: 0.9429\n",
      "Epoch 115/125\n",
      "94042/94042 [==============================] - 16s 170us/step - loss: 0.6229 - acc: 0.9281 - val_loss: 0.9696 - val_acc: 0.9366\n",
      "Epoch 116/125\n",
      "94042/94042 [==============================] - 17s 178us/step - loss: 0.6230 - acc: 0.9353 - val_loss: 1.1113 - val_acc: 0.9480\n",
      "Epoch 117/125\n",
      "94042/94042 [==============================] - 17s 176us/step - loss: 0.6450 - acc: 0.9393 - val_loss: 0.9849 - val_acc: 0.9343\n",
      "Epoch 118/125\n",
      "94042/94042 [==============================] - 16s 170us/step - loss: 0.6361 - acc: 0.9360 - val_loss: 1.0298 - val_acc: 0.9516\n",
      "Epoch 119/125\n",
      "94042/94042 [==============================] - 16s 169us/step - loss: 0.6219 - acc: 0.9445 - val_loss: 1.0867 - val_acc: 0.9467\n",
      "Epoch 120/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 0.6581 - acc: 0.9225 - val_loss: 0.9610 - val_acc: 0.9467\n",
      "Epoch 121/125\n",
      "94042/94042 [==============================] - 16s 170us/step - loss: 0.6113 - acc: 0.9405 - val_loss: 1.1417 - val_acc: 0.9578\n",
      "Epoch 122/125\n",
      "94042/94042 [==============================] - 16s 168us/step - loss: 0.6029 - acc: 0.9347 - val_loss: 0.9401 - val_acc: 0.9300\n",
      "Epoch 123/125\n",
      "94042/94042 [==============================] - 15s 164us/step - loss: 0.6018 - acc: 0.9268 - val_loss: 1.1236 - val_acc: 0.9464\n",
      "Epoch 124/125\n",
      "94042/94042 [==============================] - 15s 163us/step - loss: 0.5970 - acc: 0.9324 - val_loss: 1.1016 - val_acc: 0.9426\n",
      "Epoch 125/125\n",
      "94042/94042 [==============================] - 16s 167us/step - loss: 0.6023 - acc: 0.9283 - val_loss: 0.9632 - val_acc: 0.9425\n"
     ]
    }
   ],
   "source": [
    "results = trainRNNModel(dataTrWinValues[:,:,:3], dataTrWinLabel, dataTestWinValues[:,:,:3], dataTestWinLabel, epochs = 125, lr=0.001, w = 256, stride = 128, batch_size = 96, rnn_type = 'lstm', two_rnn_layers=False, drop_coeff_rnn=0.2, drop_coeff_dense=0.2, first_dense=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_3 (Batch (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 32)                4736      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,847\n",
      "Trainable params: 4,841\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#plt.plot(results[1].history['val_acc'])\n",
    "#plt.show()\n",
    "#type(results[1].history['val_acc'])\n",
    "#type(results[2])\n",
    "results[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd4XNW18OHfmlFvVpes5t57wQUTsA0G2wk4lAQTLiEBLiGBALmk597whfRGQgKEOOALSWiX3myMAdPBWC64F7nLVrdVrK6Z9f0xI3ksj6yxLY3aep9nHmvO2TOzjsZas2edffYWVcUYY0zf4ejqAIwxxgSXJX5jjOljLPEbY0wfY4nfGGP6GEv8xhjTx1jiN8aYPsYSvzHG9DGW+I0xpo+xxG+MMX1MSFcH4E9ycrIOHDiwq8MwxpgeY+3ataWqmhJI226Z+AcOHEhubm5Xh2GMMT2GiOwPtK2Veowxpo+xxG+MMX2MJX5jjOljLPEbY0wfY4nfGGP6GEv8xhjTx7Sb+EUkW0RWicg2EdkiInf4aTNbRCpEZIP39lOfffNFZIeI5InIDzv6AIwxxpyeQMbxNwF3qeo6EYkF1orISlXd2qrd+6r6Bd8NIuIEHgDmAfnAGhF52c9jz1p9k4tHP9zHmIx+nDcsuaOf3hhjeo12e/yqWqCq67w/VwHbgMwAn38akKeqe1S1AXgKWHSmwZ5KqMPBkvf28Pz6/M54emOM6TVOq8YvIgOBScBqP7tnishnIrJcRMZ4t2UCB33a5NPGh4aI3CwiuSKSW1JScjphAeBwCDMGJ/Hx7jJsAXljjGlbwIlfRGKA54A7VbWy1e51wABVnQD8FXix+WF+nspvVlbVJao6VVWnpqQENN3ESWYOSaKgoo59ZTVn9HhjjOkLAkr8IhKKJ+k/rqrPt96vqpWqesz78zIgVESS8fTws32aZgGHzzrqNpw7JAmAj3aXdtZLGGNMjxfIqB4BHgG2qeq9bbRJ97ZDRKZ5n7cMWAMME5FBIhIGLAZe7qjgWxuUHE16XAQf7y7rrJcwxpgeL5BRPbOA64BNIrLBu+3HQA6Aqj4EXAV8U0SagFpgsXoK7U0ichuwAnACS1V1SwcfQwsRYeaQJN7bWYKq4v0sMsYY46PdxK+qH+C/Vu/b5n7g/jb2LQOWnVF0Z2DmkCReWH+InUXHGJEeG6yXNcaYHqPXXblrdX5jjDm1Xpf4sxKiyE6M5COr8xtjjF+9LvEDnDs4mU/2lFHX6OrqUIwxptvplYl/0aQMquqaeHatXcVrjDGt9crEP3NwEhOy41ny3h6aXO6uDscYY7qVXpn4RYRvzR7CgSM1vLapoKvDMcaYbqVXJn6AeaPSGJoaw9/e2W1z9xhjjI9em/gdDuGWC4awvbCKt7cXd3U4xhjTbfTaxA+waGIGWQmR3PfWLuv1G2OMV69O/KFOB7fPHcbG/Are3Ga9fmOMgV6e+AEun5zJgKQo7l25E7fbev3GGNPrE3+o08EdFw5jW0Elb2wt7OpwjDGmy/X6xA+waGImg1Oi+elLW3jkg71U1DR2dUjGGNNl+kTidzqEe788kcyESH7+6lam/epNbntiHW9uLaKhyS7wMsb0LdIdR7tMnTpVc3NzO+W5Nx+q4Kk1B3htYwFHaxq5cGQqj3ztnE55LWOMCRYRWauqUwNp2yd6/L7GZvbjF18cx+ofX8R/zMjhnZ0lVNVZ6ccY03f0ucTfLCzEwYKx/XG5ldz9R7s6HGOMCZpA1tzNFpFVIrJNRLaIyB1+2lwrIhu9t49EZILPvn0isklENohI59RvztDknARCncIne2zufmNM3xHImrtNwF2quk5EYoG1IrJSVbf6tNkLXKCqR0VkAbAEmO6zf46qdrslsSLDnEzIimf1niNdHYoxxgRNuz1+VS1Q1XXen6uAbUBmqzYfqWpzveQTIKujA+0sMwYnselQBcfqm7o6FGOMCYrTqvGLyEBgErD6FM1uBJb73FfgDRFZKyI3n+K5bxaRXBHJLSkpOZ2wzsqMwUmeOv8+6/UbY/qGgBO/iMQAzwF3qmplG23m4En8P/DZPEtVJwMLgFtF5Hx/j1XVJao6VVWnpqSkBHwAZ2vygHhvnd8SvzGmbwgo8YtIKJ6k/7iqPt9Gm/HAw8AiVW05W6qqh73/FgMvANPONuiOFBUWwoSseDvBa4zpMwIZ1SPAI8A2Vb23jTY5wPPAdaq602d7tPeEMCISDVwMbO6IwDtSc52/2ur8xpg+IJAe/yzgOmCud0jmBhFZKCK3iMgt3jY/BZKAB1sN20wDPhCRz4BPgddU9fWOPoiz1Vzn/9Tq/MaYPqDd4Zyq+gEg7bS5CbjJz/Y9wISTH9G9TB2YQHiIg/d2ljBnRGpXh2OMMZ2qz1656ysi1MmMwUm8uzN4o4mMMaarWOL3umB4CntKqjl4pKarQzHGmE5lid/rghGeIaTW6zfG9HaW+L0GJ0eTlRBpid8Y0+tZ4vcSES4YnsJHeaW2OIsxplezxO/jguEpVDe4WGvTNBtjejFL/D7OHZpMiEOs3GOM6dUs8fuICQ9h+uBElm0qwO3ufktSGmNMR7DE38qXpmRz4EgNn+y1uXuMMb2TJf5W5o9NJzYihKfXHOzqUIwxplNY4m8lItTJ5ZMyWb65kPKahq4OxxhjOpwlfj+uPiebhiY3L64/1NWhGGNMh7PE78eYjH6My+zHU2sOomoneY0xvYsl/jZ8aWoW2wur2FNa3dWhGGNMh7LE34aR6XEAHDpa28WRGGNMx7LE34bU2HAAiqvquzgSY4zpWIEsvZgtIqtEZJuIbBGRO/y0ERH5i4jkichGEZnss+96EdnlvV3f0QfQWVLjmhN/XRdHYowxHSuQHn8TcJeqjgJmALeKyOhWbRYAw7y3m4G/AYhIInA3MB3PIut3i0hCB8XeqaLCQogND6G48tQ9/sPltby2sSBIURljzNlrN/GraoGqrvP+XAVsAzJbNVsE/FM9PgHiRaQ/cAmwUlWPqOpRYCUwv0OPoBOlxIW32+P/3w/3cusT6yixkpAxpoc4rRq/iAwEJgGrW+3KBHwvdc33bmtre4+QGhvebo9/X5lnxa5cW6jdGNNDBJz4RSQGeA64U1UrW+/28xA9xXZ/z3+ziOSKSG5JSfeYHTM1NqLdk7sHvIl/9V5L/MaYniGgxC8ioXiS/uOq+ryfJvlAts/9LODwKbafRFWXqOpUVZ2akpISSFidLjXWU+pp6yIuVWX/Ec84/zXW4zfG9BCBjOoR4BFgm6re20azl4Gvekf3zAAqVLUAWAFcLCIJ3pO6F3u39QipceHUNbqpqm/yu7+4qp66RjcpseFsLaiksq4xyBEaY8zpC6THPwu4DpgrIhu8t4UicouI3OJtswzYA+QB/wC+BaCqR4CfA2u8t3u823qE1NgIgDbr/Pu9ZZ4rJmeiCmv32cpdxpjuL6S9Bqr6Af5r9b5tFLi1jX1LgaVnFF0XO34RVx1DU2NO2r+/zFPm+eLETB55fy+r9x5hzsjUoMZojDGny67cPYXUOE+Pv62hmgeO1OB0CENTYxif1Y9PbfEWY0wPYIn/FJqv3i2q9D+Wf39ZDRnxEYQ6HUwblMSmQxXUNriCGaIxxpw2S/ynEBseQkSoo6XG73YrhRXHPwT2H6lhQGI0ANMGJdDoUn70/EYWL/mYb/57LS5bt9cY0w1Z4j8FETlhLP/TuQc5/3erOFTumbFzf1k1OUlRAEwZkEh0mJPXNhVQdqyB5ZsLeeLTA10WuzHGtKXdk7t9XfNYfoB3d5TQ4HKzfFMBX5qaTXlNIwO9ib9fZCgf/GAukWFOwkMcXPvwan73+nbmj0knxXuSOFgqahqpd7laRiUZY4wv6/G3IzUunOKqelSVT70Xab2+ubDlit0cb6kHICE6jIhQJyLCPYvGUtfo4tfLtgU95v/3yhZueHRN0F/XGNMzWOJvR2psBCWV9eQVH+NIdQODkqNZe+Boy5W6A7w9/taGpsbwjfOH8Pz6Q6w/ENzx/cVVdWw9XGknmo0xflnib0dqXDhV9U28u9Mzf9BPFo5CFZZ+uBeAnET/iR/g67MGArDuQHmnx+mrpsGFW2F7YesplYwxxhJ/u5rr5K9sLCAtLpwLR6UyJCWa/KO1JMeEEx3e9mmSxOgwIkOdHC4P7vKNzT39LYct8RtjTmaJvx3NV+9+drCcaYOSEBEWjO0P0HJity0iQmZCZNATf3WDZ24hS/zGGH8s8bej+SIugOmDEgGYPzYdoGUo56lkxAc/8Tf3+Lcergjq6xpjegZL/O3wHRLZnPjHZMRxxeRMFnp7/qeSGR/RMu4/WKrrPYl/e2EVTS53UF/bGNP92Tj+diREhRLqFGIjQlsmahMR7v3yxIAen9EvktJjDdQ1uogIdXZmqIDn6uLaRhcDkqLYX1bD7pJqRqTHdvrrGmN6Duvxt0NEyE6I4twhnvr+6cpMiASgoOLUa/d2lLomT29/6gDPt5MtVu4xxrRiiT8Aj359GvcsGntGj82I9yT+Q0eDU+5pLvOMzYwjPMRhJ3iNMSexUk8AAjmJ25ZMb+IP1gne5hO7sRGhjOwfZz1+Y8xJrMffydL7RSBC0E7w1jR6hnJGhTkZkxHH1sOVba4ZbIzpmwJZc3epiBSLyOY29n/PZ0nGzSLiEpFE7759IrLJuy+3o4PvCUKdDtJigzeyp7nU05z4K+uayA9SmckY0zME0uN/FJjf1k5V/b2qTlTVicCPgHdbras7x7t/6tmF2nNlxEcEvdQTFRbCiDTPaJ684mNBeW1jTM/QbuJX1feAQBdIvwZ48qwi6oUyE6KClvhrGo6XepJjPBefHaluCMprG2N6hg6r8YtIFJ5vBs/5bFbgDRFZKyI3d9Rr9TSeHn8d7iCsyFXTcLzUkxAdBsDRGkv8xpjjOnJUz6XAh63KPLNU9bCIpAIrRWS79xvESbwfDDcD5OTkdGBYXS8zPpIGl5vS6vpOXxylxqfUExcRQohDrMdvjDlBR47qWUyrMo+qHvb+Wwy8AExr68GqukRVp6rq1JSUlA4Mq+sdH9LZ+RdxNZd6IsM8C8IkRIdZj98Yc4IOSfwi0g+4AHjJZ1u0iMQ2/wxcDPgdGdTbBfMiLt9SD0BiVJj1+I0xJ2i31CMiTwKzgWQRyQfuBkIBVPUhb7PLgTdUtdrnoWnAC95pDkKAJ1T19Y4LvefICOJFXDUNLsKcDkKdns/0hOhQjlY3dvrrGmN6jnYTv6peE0CbR/EM+/TdtgeYcKaB9SZxESHEhIcEZSx/bUMTUeHHJ4NLjA5jZ5EN5zTGHGdX7gaBiJAZHxmUxF/d4CLKZxbQBCv1GGNascQfJBnxEUG5gra2wUVk2Ik9/vKaBlxBGEpqjOkZLPEHyZCUGPaUHOv0BFzT0HTCOsAJUWG4FSprrc5vjPGwxB8kw9NiqW9yc/BITae+TnWDi8jQE3v8AEdsSKcxxssSf5AM966CtaOoqlNfp7bB1TKUEzh+9a7V+Y0xXpb4g2SYd9nGXZ2c+KsbmojyKfUkRnl7/Jb4jTFelviDJDo8hMz4yE4fWlnbalRPYozN12OMOZEl/iAakR7Lzk7u8de0KvUc7/HbyV1jjIcl/iAalhbDnpJqmlzuTnuNmlalnsgwJxGhDuvxG2NaWOIPouGpsTS43Owr65yRPY0uN40uPaHUA55ef9kxS/zGGA9L/EE0wjuyp7PKPc0TtPlewAXYDJ3GmBNY4g+iISkxiHRm4vdMyex7ARd4xvLbqB5jTDNL/EEUGeYkJzGKXZ00sqf1lMzNEqKsx2+MOc4Sf5ANS43ttIu4mhdaj2xd47cevzHGhyX+IBuRHsO+0moamjp+ZE91vf9ST0JUGFV1TTR24mgiY0zPYYk/yIanxdLkVp5fl09do6eHXlBRy2cHy8/6uWsa/Z/ctYu4jDG+OnKxdROAmUOSyOgXwQ+f38QvX9tGVLiTosp6AJ66eQYzBied8XM3l3qiw1qd3I1qnq+nsdMXezfGdH/t9vhFZKmIFIuI3/VyRWS2iFSIyAbv7ac+++aLyA4RyRORH3Zk4D1VamwE731/Dv+6cRqfH9+fmYOTuPvS0cRFhPDE6gNn9dzNpZ6TTu5GhwJQVl1/Vs9vjOkdAunxPwrcD/zzFG3eV9Uv+G4QESfwADAPyAfWiMjLqrr1DGPtNUKcDj43LIXPDUtp2bavtJonPz3I0eqGlhk1T1dtW6We6OM9fmOMabfHr6rvAUfO4LmnAXmqukdVG4CngEVn8Dx9wuJpOTS43Dy//tAZP0dNO6Uem5PfGAMdd3J3poh8JiLLRWSMd1smcNCnTb53m18icrOI5IpIbklJSQeF1XOM6h/HxOx4nvr0AKpntkpXTX0TIhAReuLbGh9lc/IbY47riMS/DhigqhOAvwIvereLn7ZtZjRVXaKqU1V1akpKSlvNerVrpmWzq/gYa/cfPaPH13hX3xI58VcfFuIgNjzExvIbY4AOSPyqWqmqx7w/LwNCRSQZTw8/26dpFnD4bF+vN/vC+AxiwkP47evbW6ZfAKhrdOEOYK3emkYXUWH+T9vYfD3GmGZnnfhFJF28XUwRmeZ9zjJgDTBMRAaJSBiwGHj5bF+vN4sOD+GXl49l7f6jfP1/11Be08ADq/KYdM9K/vzWrnYfX1PfdNKInmaJ0WGUHrNRPcaYAEb1iMiTwGwgWUTygbuBUABVfQi4CvimiDQBtcBi9RSpm0TkNmAF4ASWquqWTjmKXmTRRM9pkO88vYFpv3yLBpebfpGhPPnpAW6fO5QQZ9uf1a0XYfHVv19Ep6/3a4zpGdpN/Kp6TTv778cz3NPfvmXAsjMLre9aNDGTUKeDxz7ax61zhlLT4OKWf6/l/bxS5oxIbfNxtY1tJ/7M+EhW7ShGVU86B2CM6Vvsyt1uauG4/iwc1x+A+iYX8VGhPLc2/5SJv7q+qc0af0Z8JHWNbo7WNLaM6zfG9E02V08PEB7i5LIJGbyxtYiK2rYvwqppcJ108VazjPhIAA4dre2UGI0xPYcl/h7iyslZNDS5WbapoM02NQ0uottI/FkJ3sRfbonfmL7OEn8PMT6rH0NSonlubX6bbTw9/rZLPQCHLfEb0+dZ4u8hRISrpmSTu/8oecX+V/CqbWh7OGdCVCgRoQ5L/MYYS/w9yVVTsghxCE9+evIsnqpKTWPbpR4RISM+0ko9xhhL/D1JSmw4l4xJ5zmfRVya1TW6UaXNUg94hnRaj98YY4m/h/nK9BzKaxpZvvnEk7zNUzxEh/vv8YMn8R8qr+vU+Iwx3Z8l/h5m5uAkBiZFtSzaUlBRy+Or9/PjFzYBJy+07isjPpLSY/UnfVto5nIri+7/4KwXhDHGdG92AVcP43AI10zL4dfLt/Plhz5mzf4jqEJaXDiXT8rkghFtz2zaPLKnoKKOQcnRJ+1ff+Aon+VXkBRTxFem53TaMRhjupYl/h7oqilZ3L8qj8LKOu64cBhfGJ/BkJTodqdiyPQZ0ukv8b+xtQiATYcqOj5oY0y3YYm/B0qKCWfNTy4iPMRxWvPuNCd+fyN7VJUVWwpxCJRU1VNUWUdanC3MbkxvZDX+HirCz4Ir7UnrF46I/4u4dhUfY39ZTcvsoJut129Mr2WJvw8JD3GSEhPuN/G/saUQgNsvHIaIlXuM6c0s8fcxmQn+L+J6Y2sRk3LiGZQczZCUGOvxG9OLWeLvYzLiIzncaiz/4fJaNuZXcPHodADGZfazHr8xvVi7iV9ElopIsYhsbmP/tSKy0Xv7SEQm+OzbJyKbRGSDiOR2ZODmzGR6p23wLJLmsXyzp8xz8Zg0AMZkxFFUWU9xlV3sZUxvFEiP/1Fg/in27wUuUNXxwM+BJa32z1HViao69cxCNB0pMz6ShiY3ZdWehddVlafXHGBCdjxDUmIAT48fYMuhynaf72h1A0WV9gFhTE/SbuJX1feAI6fY/5GqHvXe/QTI6qDYTCcYluZJ7m96x+yvO1DOzqJjXHNOdkubMZn9Aj7B+8PnN3LTY/ZlzpiepKNr/DcCy33uK/CGiKwVkZs7+LXMGZg5OInJOfH86c2d1DQ08dSnB4gOc3LphIyWNjHhIQxKjj4p8Te53C1zAoHn28La/UfZXlhJk8sdtGMwxpydDkv8IjIHT+L/gc/mWao6GVgA3Coi55/i8TeLSK6I5JaUlHRUWKYVEeFHC0dRVFnPfW/t4tWNBVw2MYPo8BOv5Rub0Y/NhypOOBfwPy9tYeF977dsK6yso/RYA40uZf+RmqAehzHmzHVI4heR8cDDwCJVLWverqqHvf8WAy8A09p6DlVdoqpTVXVqSkrb882Ys3fOwETmjU7j7+/uobbRxdXnnDwvz3lDkymoqOOdnZ4P4fyjNTyTe5B9ZTXsK/Mk+U35x78R7CryvziMMab7OevELyI5wPPAdaq602d7tIjENv8MXAz4HRlkgu8H80fgEBiZHsuErH4n7f/ipExyEqP43es7cLuVf7y3B5e3p796j+ezfdOhChzei4d3l5x+4n92bT67iqrO/CCMMWckkOGcTwIfAyNEJF9EbhSRW0TkFm+TnwJJwIOthm2mAR+IyGfAp8Brqvp6JxyDOQNDU2P58+JJ/OqKcX6nfggLcfBf84azraCSRz/ax1NrDnLV5CySY8L4dK/nXP+mQxUMT4slMz7ytBN4bYOL7z37GX97d3eHHI8xJnDtTtKmqte0s/8m4CY/2/cAE05+hOkuLvM5odvW/ofe3c09r25FBL45ewjVDU2s3nsEVWVTfgVzRqZSXFVP3mn2+POKj6FqcwIZ0xXsyl3TJodD+N4lIwBYOK4/g1NimDYwkUPlteTuP0pZdQPjs/oxLDWGvOJjuN3azjMet8P7DSGv+BjV9U3ttDbGdCSbltmc0tyRqfz6inHM9i7wMm1QEgCPvL8XgLGZ/Qh1OqhrdHOovJbsxKiAnnenN/G7FbYWVHLOwMROiN4Y44/1+M0piXhW/OrfzzOX/8j0WOIiQlixtRCnQxjdP45hqZ6LwvKK2y73bC+spLCizud+Fene+f435lu5x5hgssRvTovDIUwblIgqDEuNISLUydB2En+jy83iJZ/w3y8eH9S1s7CKc4ckkR4Xwab88qDEbozxsMRvTtu0QZ6yTPOcPvFRYSTHhLOr2P/Ino93l1Fe08jHu0tpaHJTUdNIYWUdI9JjGZfVj412gteYoLIavzltMwZ76vzjs+Nbtg1NjW6zx798cwEA1Q0u1h84isM7+H94eiwNTW5Wbi2iqq6R2IjQTo7cGAPW4zdnYFxmP/5+3RS+NOX4fHxDU2PYVXzshCkewDO/z4otRcwekYJD4IO8UnYUer4ZjEjz9PgBNgcwE6gxpmNY4jenTUS4ZEw6EaHOlm3DUmOpqmuiuKr+hLaf7j3CkeoGFp+TzcTseN7bVcrOoipiw0Po3y+ipVy06ZDV+Y0JFiv1mA4xPC0WgPN/t4ohKTEsHJfON2cPZfnmQiJDnVwwPJWtBVXc//Yu6htdDE+PRURIigknMz7SRvYYE0TW4zcdYvqgRO5bPJGvzhxAbEQIf3hjJ9c+/AnLNxcyZ2QKkWFOzh+WjFs9QzmbPygAxmfZUo/GBJP1+E2HcDiERRMzWTQxE/BMwPY/L26mttHFgrH9AZiQHU9seAhV9U2M8C4IAzApJ57lmws5XF5LRnxkl8RvTF9iPX7TKa6aksXLt83i9guHMW+0Zy3fUKeDGUM8I4KGpx/v8c8d6dn/5rai4AdqTB9kid90mmFpsfzXvOEnnASePyadqDAno/vHtWwbmhrD4ORoVm61xG9MMFipxwTVFZMzuWRsOjGtVvyaNzqNpR/upbKukTgbz29Mp7IevwkqETkp6YMn8Te6lHd22LKbxnQ2S/ymW5iUk0BSdBhvWrnHmE5nid90C06HcOGoVFbtKKbR5e7qcIzp1QJK/CKyVESKRcTvmrni8RcRyRORjSIy2Wff9SKyy3u7vqMCN73PRaPSqKprYtmmgq4OxZheLdAe/6PA/FPsXwAM895uBv4GICKJwN3AdGAacLeIJJxpsKZ3+9ywFLITI7njqQ1c98hqW5bRmE4SUOJX1feAI6dosgj4p3p8AsSLSH/gEmClqh5R1aPASk79AWL6sMgwJyvuPJ+fLBzF1sOVXPvwauqbXF0dljG9TkfV+DOBgz73873b2tpujF9RYSH85/mD+cOXJlBR28iHeaVdHZIxvU5HJX7xs01Psf3kJxC5WURyRSS3pMSG9PV15w5NIjYihOWbCrs6FGN6nY5K/PlAts/9LODwKbafRFWXqOpUVZ2akpLSQWGZnio8xMm8UWm8sbXolKN8Dh6poaCiNoiRGdPzdVTifxn4qnd0zwygQlULgBXAxSKS4D2pe7F3mzHtmj82nYraRj7eXeZ3f1FlHV984EO+9fi6IEdmTM8W0JQNIvIkMBtIFpF8PCN1QgFU9SFgGbAQyANqgK979x0RkZ8Da7xPdY+qnuoksTEtzh+eQnSYk+WbCzl/+InfAl1u5TtPb6CsuoGy6gYKK+pI7xfRRZEa07MEOqrnGlXtr6qhqpqlqo+o6kPepI93NM+tqjpEVcepaq7PY5eq6lDv7X8760BM7xMR6mTOyFTe2FJIU6tyz9/eyeOj3WV84/zBAKzcaucCjAmUTdJmurWF4/rz6sYCLrv/Q2LCQ6hrclFcWU9hZR2LJmbwwwUjWbm1iBVbirhu5sATHutyK4fLa8lOjOqa4I3ppmzKBtOtzR2ZyhWTMkmKCcPhgPioMM4blsxd84bzq8vHISJcPCadT/aUUVHTeMJjH1+9nzl/eIe9pdVdFL0x3ZP1+E23FhHq5N6rJ56yzSVj0njo3d28vaOIyydltWx/Y0sRTW7l/3IP8oP5Izs7VGN6DOvxmx5vQlY8aXHhrNh8fGbP6vomPt3rGUfw7Nr8k84R+Hp+XT53v+R3GipjeiVL/KbHcziEeaPTeHdnCXWNnikePt5dRoPLzdfOHUhJVT2r2pjnv7iyjv95cTOPfbyf/KM1wQzbmC5jid/0CpeOz6C20cUzuZ4ZQlbtKCY6zMkP5o+WFOS5AAAU1UlEQVQkJTacp9cc9Pu4376+g/omz7eBN7bYWgCmb7DEb3qFaYMSOWdgAg+s2k1do4t3dpRw7tBkIsOcXDk5i1U7iimurDvhMesPHOW5dfnc9LnBjEiLZcUWGxJq+gZL/KZXEBG+M284hZV1/PzVrRwqr2XOiFQAvjw1C5db+dWybS2loCPVDfzPS5tJjQ3ntrlDuWRMGmv2HaHsWH1XHoYxQWGJ3/Qa5w5JZvqgRB5ffQCA2SM8V/sOTonh23OH8uKGw1z+4Ec8/P4e5v7xHbYXVPGzy8YQEx7CxWPScSu8ta24Kw/BmKCwxG96le/MGw7AiLRYMuIjW7bfdfEIln5tKoUVtfzitW0MT41l2R2fY8G4/gCMyYgjMz7ylOWe8poGKmob29xvTE9h4/hNrzJjcBJfnzWQsRn9Tto3d2Qar995PlsOVzBnRCoix2cNFxEuGZPOv1fv51h9EzHhJ/9p/Mcjq4kKDeH/bpnZqcdgTGezHr/pde6+dAxXTsnyuy8tLoK5I9NOSPrNLhmTRkOTm7++vQvVE5eN2Hq4ks2HKvl03xF2FFZ1StzGBIslfmO8pg1K5Oqp2fz93T38+IXNJ1z09cL6fEKdQpjTwZOfHujCKI05e1bqMcZLRPjNleNIjg3jgVW7OVbfxF8WT8TlVl7ccJjZI1IJD3HwwvpD/HDBSCJCnTS53Dgd4vcbhDHdlSV+Y3yICN+7ZCRRYSH8fsUOzhmYwICkaEqq6rliUiZxkaG8urGA1zcXMiQlhpv/lcuQlBj+8dWpRIY5AdhXWk16vwgiQp1dfDTG+GeJ3xg/vjV7CGv3H+UXr25jbGYccREhzB2VSqjDwYCkKP705k6KKuuIjQjlw92l3PjYGh74ymTuX5XH0g/3smBsOg9eO6WrD8MYv6zGb4wfIsLvrxpPQnQo6w6U8/nxGYSHOHE4hKvPyWZ/WQ2j+8ex7PbP8YerJvDxnjKm//otHvlgL2My4li2qZCPdpd29WEY41dAiV9E5ovIDhHJE5Ef+tn/JxHZ4L3tFJFyn30un30vd2TwxnSmpJhw7ls8iayESK6dntOy/YZZg/jz1RN54j9nkBIbzpVTsvjjlyYwKj2Wf984nWdvOZfM+EjueWWr31lBq+ubeHXjYe55ZSvbCiqDeUjGACCth62d1EDECewE5gH5eNbPvUZVt7bR/tvAJFW9wXv/mKrGnE5QU6dO1dzc3PYbGhMEqnraJ2+XbSrgW4+v4+5LR3PZhAyO1Tfx0e4y3tpWxPu7SlsmhosOc/Lgf0zhglZrChtzukRkrapODaRtIDX+aUCequ7xPvlTwCLAb+IHrsGzGLsxvcKZjNhZMDadGYMT+dkrW/nZK8f/VDLjI7lmWg7zx6aTnRjFTY/lcsOja7hh1kAGJEWTFhfBtEGJ9IsM7chDMOYEgST+TMB3Ttt8YLq/hiIyABgEvO2zOUJEcoEm4Deq+uIZxmpMjyEi3P+Vyby84TBOhxAR6mBCdjwj0mJP+CB55paZ3PnUBv7x/t6WbSEOYeaQJG48bxCzvRPNGdORAkn8/ro7bdWHFgPPqqrLZ1uOqh4WkcHA2yKySVV3n/QiIjcDNwPk5OS03m1Mj5McE84N5w06ZZuY8BAevn4qDU1ujtY0cOBIDW9uK+K1jQXc9Fguf79uCheOSqOu0dVy4jgYHwa/Xr6NoSkxfGlqdqe/lgm+QBJ/PuD77mcBh9touxi41XeDqh72/rtHRN4BJgEnJX5VXQIsAU+NP4C4jOk1wkIcpMVFkBYXwTkDE7ltzlC+8o/VfOvxdfzssjE8+tE+thdWERsewhv/dT79+0W2/6RnaHfJMf7+7h4iQ52cNyy5U1/LdI1ARvWsAYaJyCARCcOT3E8anSMiI4AE4GOfbQkiEu79ORmYRdvnBowxXrERoTx2wzRyEqP44fObKD3WwK8uH0eTW/nx85tOmkvIn+WbCvjZK1sCauvrydUHCHEILlV+s3z7mR6C6cba7fGrapOI3AasAJzAUlXdIiL3ALmq2vwhcA3wlJ74v2wU8HcRceP5kPlNW6OBjDEnSowO4/GbpvN/uQe5ZloOSTHh1DW6uOfVrby44RCXT/I/ER1AQ5Obe17dSkFFHROz41k0MTOg16xrdPHsunzmjU5jaGoMf307j+tmDGDqwMQOOSaXW3HImZ0wNx2n3eGcXcGGcxrjn8utfPnvH7OzqIpfXj6OS8f3p6y6gV+8upXthVU8+Z8zSIgO47m1+dz1zGckx4ThEOGtuy4gNuLkkUIut/LE6v1EhYVwxeRMXtpwmDuf3sC/b5zO5AHxXPjHd0mKCePlW8/D4Ti7ZN3kcrN4ySek9Yvgga9MPqvnMifr6OGcxphuwukQ/nz1RG59Yh23P7mef328j51Fx6hpaEIV/vulzdx/zSSWvLeHEWmx/Paq8Vz+4If8aeUurpySyWMf7aOitpHPj89gZHos//3CZj7ddwSAD3eXsre0mgFJUZw7JAmHQ/jB/JHc+fQGXttUwKUTMs4q9oc/2Evu/qM4HUJJVT0pseEA1De5CHE4cPp8sOwvqyY1NqJl/iPTsSzxG9PDZCdG8cK3ZvHE6v38bsUORqXH8asrxrJiSxG/X7GDqFAnO4qq+OOXJjAxO56vTMth6Yd7WfrhXiJDncRFhrBiSxEAseEh/P6q8Rwur+PPb+1EFX60YGRL7/7SCRk8+E4ef35zJwvH9cfpEIqr6th4sIILR6UGXLLZXXKMe1fuZGJ2PBsOlvPKZ4e54bxBNDS5WXjf+9Q2uLjhvEFMHZjIg6vyeGNrETedN4j//sLoTvs99mWW+I3pgZwO4bqZA1k8LYcQ77TQA5OieWtbEc+szad/v4iWHvr3LhlB6bF6JuUkcM05OcREhLB6bxnr9h/l8slZZHqXqJyQ3Y9ncvO5+pzsE17nzouG863H1/HKZ4f53LBkFv/9E/aUVnPukCR+e+V4shOjToit9Fg9qpAUHUaj282+0hp+/MImIkOdLPnqFG54dA0vrD/EDecN4pm1B9ldUs2o/nH84rVtgOfDKDM+kre3F59V4v/3J57V1K6fOTCgbw4b88t5a1sxd140rOUD7bGP9vH+rlKWXDflrEtd3YnV+I3pRfaVVnPVQx9z18XDuWZax1wP43YrC//yPnWNLuIiQ9lRWMV/fm4wj360D7cqv7lyPJd5P2SeX5fPd5/5DLfSUrpxuT055t4vT+CKyVk88sFefv7qVl67/TxueiyX/v0ieO6b57L+YDmb8iu4bEIGL6w/xD2vbuX978856YPlo7xSPsgr5WuzBpIaG+E35mfXeuIASI+L4I6LhnHJmHQSo8P8tldVLrv/QzYdquCfN0zj/OEp1DQ0MfPXb1NR28iD105moXd95kA9/P4ehqbGBO0ivNOp8VviN6aXcbn1hHp5R3hjSyE3/2stToewxHtR2aHyWu58aj1r9h3lxwtHkhkfxbefXMe0QYksGNuf4qo6HCIMTY1hTEYcQ1NjASipqmfGr98iMz6SA0dqePym6cwamnzC6+UVV3HRve/xy8vHcu30AS3bK2obufCP71B6rIHIUCdfnTmAAUnR1De5SIgK49yhSewpqea6R1ZzzsBEvj13GL99fTsbDnrmjRyRFsv354/gwlFpJ7ze29uLuOHRXJwOYeqABJ7+xkwe+2gfd7+8haToMBKjw3j9zvNP+L263MoHeaVMzIqnX9SJJ85XbCnkG/9aS3JMGO99fw5RYZ1fXLGTu8b0YR2d9AHmjU7j67MGcs7AxJakmRkfyb9unM5dz3zGr5ZtRwSm5CSw9GvnnDLRpcSGc/6wZFbtKGH6oETOHZJ0UpshKTFk9Ivg/Z2lJyT+P63cSVl1Aw9eO5k3thSy5P09tO67hjkd5CRG8bdrp9AvKpQXvnUu6w6U88meMv4v9yA/fWkLs0ektvyeVJX73sojKyGS62YM4NfLt7N6TxkPf7CHyTnxfH3WIL795Hpe21TQ8s2mvsnFnU9tYPnmQsJCHMwbncbXzvX8fsprGvjJC5vJjI/kUHkt//x4P7dcMORs34IOZYnfGNMuEeHuS8ectD0i1MlfF09iQGIU2wuruG/xxIB6t1efk8O7O0v47iUj/J4gFhHOH57Ca5sKaHK5CXE62Hq4kn9+vI9rp+ewcFx/Fo7rz/98YTRNbiXM6SD/aC3v7SphW0El379kZEsvXESYMiCBKQMSGJwczTcfX8fb24uZN9rzAfbuzhI+O1jOr68Yx6KJGTz07m5ue3I9JVX1/GThaC4encZf397Fn9/cyawhSTS6lO8+8xkf5JVy+4XDqKxt5KUNh3hto+eDocntprymgZdum8XvXt/B39/dzX/MGEBMePdJt1bqMcZ0idJj9STHhLe5/7WNBdz6xDqevWUm47PiueYfn7C3tJq377qA+Cj/tfr2NLncnPfbVQxLi+FfN06nyeXmyoc+prSqnlXfnU1YiIO/vLWLe1fuZGBSFG/dNRunQ1qm2W7mdAi/u3I8V07xXERX2+Dib+/u5qF3d9PQ5Obbc4dy18Uj+OxgOYse+JDvXjyc2+YOO6OYA2WlHmNMt3eqpA9w3tBkHALLNhXy5zd3sXb/Uf509YQzTvoAIU4HX5mew70rd7Kn5BhLP9zLZwfLuW/xRMJCPDPYXD9zIM+vy+fOi4a3lIMWjE3n3i9PoLK2ERFhXFY/JucktDxvZJiT/5o3nKsmZ/HW9iK+4l24Z0J2PBeNSuWhd/dQ1+jmi5MyGJIS0+Yw2IYmd0scncl6/MaYbuvyBz9k/YFynA7hN1eM65DZQour6pj1m7fJSYxid0k137hgMD9aMKoDovXv4BHPcNYP80pbRjtFhTpJjAljbEY/RvWP5VB5Lev2l9PocvP2d2ef0etYj98Y0yt8flx/dhRW8cC1k5nTQcMiU2MjmD+2P698dpj5Y9L5wSUjO+R525KdGMW/bpxOcVUdKzYXUlBRR02Di+KqOj7LL+e1TQXERoQwKSeBKTkJuN3a6dcMWI/fGNNtqSoNLjfhIR07dcOBshqeWnOAb88d1uXTQlTVNRIdFnLWyd56/MaYXkFEOjzpA+QkRfH9+Z3b0w+Uv8nzOlvnn0UwxhjTrVjiN8aYPsYSvzHG9DGW+I0xpo8JKPGLyHwR2SEieSLyQz/7vyYiJSKywXu7yWff9SKyy3u7viODN8YYc/raHdUjIk7gAWAekA+sEZGX/ayd+7Sq3tbqsYnA3cBUQIG13sce7ZDojTHGnLZAevzTgDxV3aOqDcBTwKIAn/8SYKWqHvEm+5XA/DML1RhjTEcIJPFnAgd97ud7t7V2pYhsFJFnRaT5uupAH4uI3CwiuSKSW1JSEkBYxhhjzkQgF3D5u5ys9eW+rwBPqmq9iNwCPAbMDfCxno2qS4AlAN7zBfsDiM2fZKD0DB/bXdgxdA92DN2DHUNgBrTfxCOQxJ8P+M6MlAUc9m2gqmU+d/8B/NbnsbNbPfad9l5QVVMCiMsvEckN9LLl7sqOoXuwY+ge7Bg6XiClnjXAMBEZJCJhwGLgZd8GIuK7GOVlwDbvzyuAi0UkQUQSgIu924wxxnSRdnv8qtokIrfhSdhOYKmqbhGRe4BcVX0ZuF1ELgOagCPA17yPPSIiP8fz4QFwj6oe6YTjMMYYE6CAJmlT1WXAslbbfurz84+AH7Xx2KXA0rOI8XQtCeJrdRY7hu7BjqF7sGPoYN1yWmZjjDGdx6ZsMMaYPqbXJP72ppXojkQkW0RWicg2EdkiInd4tyeKyErvNBcrvSfGuzURcYrIehF51Xt/kIis9h7D096BAd2aiMR7r0PZ7n1PZva090JEvuP9v7RZRJ4UkYju/l6IyFIRKRaRzT7b/P7exeMv3r/zjSIyuesiP66NY/i99//SRhF5QUTiffb9yHsMO0TkkmDH2ysSv8+0EguA0cA1IjK6a6MKSBNwl6qOAmYAt3rj/iHwlqoOA97y3u/u7uD4aC7wDOn9k/cYjgI3dklUp+c+4HVVHQlMwHM8Pea9EJFM4HZgqqqOxTMYYzHd/714lJOv6G/r974AGOa93Qz8LUgxtudRTj6GlcBYVR0P7MR7HtT7N74YGON9zIPeHBY0vSLxc3bTSnQZVS1Q1XXen6vwJJpMPLE/5m32GPDFrokwMCKSBXweeNh7X/BcwPest0lPOIY44HzgEQBVbVDVcnrYe4FnwEakiIQAUUAB3fy9UNX38IwG9NXW730R8E/1+ASIbzWcvEv4OwZVfUNVm7x3P8FzHRN4juEpVa1X1b1AHp4cFjS9JfEHPDVEdyUiA4FJwGogTVULwPPhAHTMKtOd58/A9wG3934SUO7zn74nvB+DgRLgf70lq4dFJJoe9F6o6iHgD8ABPAm/AlhLz3svoO3fe0/9W78BWO79ucuPobck/oCnhuiORCQGeA64U1Uruzqe0yEiXwCKVXWt72Y/Tbv7+xECTAb+pqqTgGq6cVnHH28dfBEwCMgAovGURlrr7u/FqfS4/1si8hM8Zd3Hmzf5aRbUY+gtib/daSW6KxEJxZP0H1fV572bi5q/vnr/Le6q+AIwC7hMRPbhKbHNxfMNIN5bboCe8X7kA/mqutp7/1k8HwQ96b24CNirqiWq2gg8D5xLz3svoO3fe4/6WxfPGiRfAK7V42Pnu/wYekvib3daie7IWwt/BNimqvf67HoZaF605nrgpWDHFihV/ZGqZqnqQDy/97dV9VpgFXCVt1m3PgYAVS0EDorICO+mC4Gt9KD3Ak+JZ4aIRHn/bzUfQ496L7za+r2/DHzVO7pnBlDRXBLqbkRkPvAD4DJVrfHZ9TKwWETCRWQQnhPVnwY1OFXtFTdgIZ4z57uBn3R1PAHGfB6er3gbgQ3e20I8NfK3gF3efxO7OtYAj2c28Kr358F4/jPnAc8A4V0dXwDxTwRyve/Hi0BCT3svgJ8B24HNwL+A8O7+XgBP4jkn0YinN3xjW793PGWSB7x/55vwjGDqrseQh6eW3/y3/ZBP+594j2EHsCDY8dqVu8YY08f0llKPMcaYAFniN8aYPsYSvzHG9DGW+I0xpo+xxG+MMX2MJX5jjOljLPEbY0wfY4nfGGP6mP8PilCLvut+QaIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_model = results[0]\n",
    "train_info = results[1].history\n",
    "eval_info = results[2]\n",
    "model_performance_info = { 'train_history' : train_info, 'eval_results' : eval_info, 'optional_data' : 'test_subjects=8, w=256, stride=128'}\n",
    "plt.plot(results[1].history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[20752  1118    97]\n",
      " [   45   280    17]\n",
      " [    7    36   594]]\n",
      "Normalized confusion matrix\n",
      "[[0.94 0.05 0.  ]\n",
      " [0.13 0.82 0.05]\n",
      " [0.01 0.06 0.93]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU8AAAEmCAYAAADiNhJgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd8FVX6x/HPNwkB6SAqJkFpKk2k6oqrKBZQihVFbNh1197bui6ra8GCu6vr/ixrXcGGgoDYFhVEaYoKWKiSgAqIoKgg8fn9MRO8CSG5udwykOfta17eO3PumWcml+eeOWeKzAznnHNVk5XpAJxzbmvkydM55xLgydM55xLgydM55xLgydM55xLgydM55xLgybMakHSTpCfD17tI+kFSdpLXsUjSIcmsM451ni/p63B7tt+Cen6Q1DKZsWWKpNmSDsx0HNWBJ88kCBPH15LqxMw7S9LEDIZVLjP70szqmllxpmPZEpJqAHcDh4XbszLRusLPL0hedMkn6VFJN1dWzszam9nENIRU7XnyTJ4c4OItrUQB/7tUbiegFjA704FEgaScTMdQ3fg/0uQZBlwhqWF5CyX1kDRN0urw/z1ilk2UdIukycCPQMtw3s2S3g0PK8dI2l7SU5LWhHU0j6njXklLwmUzJO2/mTiaSzJJOZL2DesumX6WtCgslyXpGknzJa2U9IykxjH1nCJpcbjs+op2jKTtJN0Vll8taZKk7cJlA8JDze/CbW4b87lFkq6Q9FH4uZGSaknaHfgsLPadpDdjt6vMfj0rfN1a0lthPSskjYwpZ5Jah68bSHpc0vIw3htKfswkDQljv1PSKkkLJR1ewXYvknRlGP9aSQ9L2knSeEnfS3pdUqOY8s9K+iqM8W1J7cP55wAnAVeVfBdi6r9a0kfA2vBvurH7RNI4SXfF1D9S0iMV/a1cFZiZT1s4AYuAQ4AXgJvDeWcBE8PXjYFVwCkELdQTw/fbh8snAl8C7cPlNcJ584BWQANgDvB5uJ4c4HHgPzExnAxsHy67HPgKqBUuuwl4MnzdHDAgp8w2lKzz1vD9JcB7QAFQE/g38HS4rB3wA3BAuOxuYANwyGb2z31h3flANtAj/NzuwFrg0HD9V4XbnBuzX6cCeeE+nAucV952lLdd4TrPCl8/DVxP0GCoBfw+ppwBrcPXjwMvAfXCOj8HzgyXDQF+Ac4Ot+N8YCmgCr4X7xG0kvOBb4CZQOdw+98E/hxT/oxwvTWB4cCHMcseJfxulan/Q6AZsF3sdzF83TRcZy+C5LsAqJfpfy/bypTxALaFid+SZwdgNbADpZPnKcDUMp+ZAgwJX08EhpZZPhG4Pub9XcD4mPf9Y/9xlRPTKmCv8PVNVJ48/wWMBbLC93OBg2OW7xwmjhzgRmBEzLI6wHrKSZ5hsvqpJJYyy/4EPFOmbBFwYMx+PTlm+R3AA+VtR3nbRenk+Tjwf0BBOXEY0JogIa4D2sUsOzfm7zgEmBezrHb42aYVfC9Oinn/PPCvmPcXAi9u5rMNw7obhO8fpfzkeUZ538WY98cAS4AVxPxg+LTlkx+2J5GZfQK8DFxTZlEesLjMvMUErZESS8qp8uuY1z+V875uyRtJl0uaGx7yfUfQWm0ST9ySzgUOBAab2a/h7F2BUeHh9HcEybSYoBWVFxuvma0FNjdg04SgpTe/nGWl9ku47iWU3i9fxbz+kZhtrqKrAAFTw26CMzYTay6l/1Zl/04b4zGzH8OXFcUU199QUrak28JukjUESbAkpoqU972J9TLBj8JnZjapkrKuCjx5Jt+fCQ7rYv/BLSVIRrF2IWhllUj49lZh/+bVwPFAIzNrSNACVpyf/StwpJmtjlm0BDjczBrGTLXMrAhYRnCoWFJHbYIug/KsAH4m6H4oq9R+kaSw3qJyylZmbfj/2jHzmpa8MLOvzOxsM8sjaE3eX9LPWSbWXyj9tyr7d0qVwcCRBEcwDQha0vDb33Bz34/Kvje3EPzw7SzpxC2M0cXw5JlkZjYPGAlcFDN7HLC7pMFhp/4JBP2GLydptfUI+hyXAzmSbgTqV/YhSc3CWE81s8/LLH4AuEXSrmHZHSQdGS57Dugn6feScoGhbOa7FLYmHwHulpQXtrD2lVQTeAboK+lgBaceXU5w2PxulbY+WM9ygiR3criOM4hJ2JIGSioI364iSDrFZeooDmO6RVK9cNsvA56sajwJqEew7SsJfgD+Vmb510CVzkWVdABwOnBqOP1DUn7Fn3Lx8uSZGkMJ+gEBsOAcxH4EyWElwSFkPzNbkaT1TQDGEwxuLCZo6VV2OAdwMEHr7Dn9NuJecurPvcBo4FVJ3xMMfOwTbs9s4I/AfwlaoauAwgrWcwXwMTAN+Ba4naBv9TOCga5/ELT6+gP9zWx9nNtd1tnAlQT7uD2lk3B34H1JP4TbdbGZLSynjgsJWrELgEnhNqZjhPpxgr9dEcHg4Htllj8MtAu7UV6srDJJ9cM6LzCzovCQ/WHgP2EL320hhZ3KzjnnqsBbns45lwBPns45lwBPns45lwBPns45l4BqdzMB5Wxnyq2X6TAiqWObZpUXqsayfZB6sxYvXsSKFSuStoOy6+9qtuGnuMraT8snmFmfZK07XtUveebWo+Yex2c6jEh6853hmQ4h0mrXrHb/XOK23z7dklqfbfgp7n+nP394X1xX0iWbfxuccxEkiPidGT15OueiR0BWUh92kHSePJ1z0RTxPmZPns65CPLDduecS4y3PJ1zroqEtzydc67q5ANGzjmXED9sd865qvIBI+ecqzrhLU/nnEuItzydc66qBNk+YOScc1Xjpyo551yCvM/TOeeqykfbnXMuMd7ydM65KpJfYeScc4nxw3bnnEuAH7Y751xV+YCRc84lxluezjlXRRJkRTs9RTs651z15S1P55xLgPd5OudcArzl6ZxzVSQfbXfOuYQoK9rJM9rRbcUO7dGWWaP+xCcv/ZkrTj90k+W77NyIcQ9cyNSR1zLhwYvJ37FhqeX16tRi/oSbuefqgekKOW3eeG0Ce3duT7eObRh+1x2bLF+3bh1nnjqYbh3bcOiBPfhy8SIAvly8iPwm9ei5b1d67tuVyy/6Q5ojT49XJ7xCx/Z70L5Na4bdcdsmy9etW8fJg0+gfZvW7N9jHxYvWrRx2bDbb6V9m9Z0bL8Hr706IY1RJ1dwI3nFNWWKJ88UyMoSw685niMvuJ/Ox97MwD5dadOyaakyt156NE+NncreJ9zK3/5vPEMvHFBq+Z//0Jd3ZsxLZ9hpUVxczFWXXcQzL4zh3ekf8cKzI/h07pxSZZ587BEaNmzI9I8+5fw/Xsxf/nTdxmXNW7TirSkzeGvKDO76+/3pDj/liouLueSiP/LSmPF88NEcnh3xNHPnlN4/jz7yMI0aNmL2p/O48OJLuf66qwGYO2cOz44cwcxZsxn98itcfOEfKC4uzsRmbDlVYYqnOqmPpM8kzZN0TTnLd5H0P0kfSPpI0hGV1enJMwW6d2jO/CUrWFS0kl82FPPshJn0O7BjqTJtWu7MxPc/A+CtaZ/T78A9Ny7r3LYZO25fn9enzE1r3Okwc/pUWrRsRfMWLcnNzeXo405g/NgxpcqMHzuGQSedAsCAo4/l7YlvYmaZCDftpk2dSqtWrWnRMtg/A08YxMtjXipV5uUxL3HSKacBcMyxxzHxzTcwM14e8xIDTxhEzZo1ad6iBa1atWba1KmZ2IwkiK/VGU/LU1I2cB9wONAOOFFSuzLFbgCeMbPOwCCg0l9mT54pkLdjAwq/XrXxfdHXq8jfoUGpMh9/XsRRB3cC4Mhee1G/7nY0blAHSdx22TFcd8+otMacLsuWLiW/oGDj+7z8fJYtLdqkTF5BMwBycnKo36AB365cCcCXixdyYI9u9O/diymTJ6Uv8DRZurSIgnDbAfLzCygqKtq0TLPS+2flypUUFW362aVl9u3WJImH7XsD88xsgZmtB0YAR5YpY0D98HUDYGlllUYieUoqlvShpFmSZkrqEc5vLumTmHJnh8sbhe8vk/SppI/Dz94tqUamtmNjnOUcS5RtN117zyj279qaKU9fzf5dW1P09So2FBdz7vH7M2HSbAq//i49waZZeS3Isv8ANldmp6Y7M2vuAia+O52/3jaMc844hTVr1qQs1kzYkv1DHJ/dmlQheTaRND1mOqdMVfnAkpj3heG8WDcBJ0sqBMYBF1YWX1RG238ys04AknoDtwI9YwtIOoVgg3qZ2SpJ5wGHAb8zs+8k5QKXAdsBv6Q1+jKKvvmOgp0abXyfv1Mjli5fXarMsuWrGXTFQwDU2S6Xow7uxJoffmafji3Yr3Mrzjl+f+psV5PcGtn88NM6/vT30WndhlTJy8+nqLBw4/ulRUU03TlvkzJLC5eQn1/Ahg0bWLN6NY0aN0YSNWvWBKBT5660aNGS+fM+p3OXbmndhlTKzy+gsPC3f+dFRYXk5eVtWmbJEgoKfts/jRs3Jr9g08/uXGbfbjUEyoo78a8ws4q+BOVVVPaX5kTgUTO7S9K+wBOSOpjZr5urNBItzzLqA6tiZ0g6HrgGOMzMVoSzrwfON7PvAMxsvZndZmYZb4pMn72Y1rvswK5521MjJ5uBvbswduJHpcps37DOxlbBlWf05rGX3gPg9OsfY/cjbqRN3z9z7T2j+O/LU7eZxAnQuWt3Fsyfx+JFC1m/fj2jnhvJ4Uf0K1WmzxH9GPHUEwCMHvU8+/c8CEmsWL584wDIooULmD9/Hs2bt0z7NqRSt+7dmTfvCxYtDPbPsyNH0Ldf6cHEvv0G8NQTjwHwwvPP0fOgXkiib78BPDtyBOvWrWPRwoXMm/cF3ffeOxObscWUxD5PgpZms5j3BWx6WH4m8AyAmU0BagFNKqo0Ki3P7SR9SBDwzkCvmGW7Av8EOpvZVwCS6gF1zWxhPJWHzfigKV+jbhLDLl9x8a9cevszjLn/j2Rnicdeeo+5C77iT+f3ZeacLxn71scc0G03hl44ADOYNHMel9z6TMrjioKcnBxuv+teBh7Vl+LiYgafMoQ27dpz619volOXrhzetz8nn3YG5581hG4d29CwUSMeevQpAN6d/A633fwXcnKyyc7O5q5776NR48YZ3qLkysnJ4Z57/0n/vr0pLi7mtCFn0K59e4bedCNdunajX/8BDDnjTM4Ycgrt27SmUaPGPPHUCADatW/PsQOPp3PHduTk5DD87/eRHfHH91YkiV0O04DdJLUAiggGhAaXKfMlcDDwqKS2BLloeYXxRWEUU9IPZlY3fL0v8BDQgSBxvgl8CzxlZveEZeoDi8yscfi+N3A70BAYbGbvbm5dWbV3tJp7HJ/KzdlqFU0anukQIq12zai0NaJnv326MWPG9KRlu5ztW1r9I26Oq+yqJ0+aUclhO+GpR8OBbOARM7tF0lBgupmNDkffHwTqEhzSX2Vmr1YYY1zRpZGZTZHUBNghnPUjwSkGkyR9Y2ZPmdkaSWsltTCzhWY2AZgg6WUgN1OxO+eSJ5mDXWY2jmAgKHbejTGv5wD7VaXOyPV5SmpD8OuwsmSemS0H+gB/C1uZEAwq/UtSw/BzImhqO+e2duGAUTxTpkSl5VnS5wnByNhpZlYc+8tjZgslDQDGSToG+BdQG3hf0jrgB2Ay8EF6Q3fOJVvJgFGURSJ5mlm5vdpmtoig77Pk/SxKn591Zzg557Yxnjydcy4R0c6dnjydcxEkb3k651xCsiJ+P09Pns65yPEBI+ecS1S0c6cnT+dcBHmfp3POJcaTp3POJSCTVw/Fw5Oncy6SvOXpnHNVVIV7dWaMJ0/nXCR58nTOuQR48nTOuQT4gJFzzlWVn+fpnHNVJyDiudOTp3Muiny03TnnEhLx3OnJ0zkXQYIsHzByzrmqEZ48nXMuIX7Y7pxzCfABI+ecqyp5y9M556pMyJ9h5JxzifCWp3POJcD7PJ1zrqq8z9M556ouuLY92tnTk6dzLpL8JHnnnEtAxBue1S95tt+9gBcnDMt0GJFUcNrjmQ4h0gofOzXTIURWsVlyK/T7eTrnXNX5/Tydcy4hfj9P55xLiA8YOedcVW0F53lG++JR51y1VHKeZzxTXPVJfSR9JmmepGs2U+Z4SXMkzZb038rq9Jancy6SktXnKSkbuA84FCgEpkkabWZzYsrsBlwL7GdmqyTtWFm93vJ0zkWSFN8Uh72BeWa2wMzWAyOAI8uUORu4z8xWAZjZN5VV6snTORc94TOM4pmAJpKmx0znlKktH1gS874wnBdrd2B3SZMlvSepT2Uh+mG7cy5yVLVTlVaYWbcKq9tU2bP6c4DdgAOBAuAdSR3M7LvNVeotT+dcJCXxsL0QaBbzvgBYWk6Zl8zsFzNbCHxGkEw3y5Oncy6SsqS4pjhMA3aT1EJSLjAIGF2mzIvAQQCSmhAcxi+oML4qb5FzzqVBslqeZrYBuACYAMwFnjGz2ZKGShoQFpsArJQ0B/gfcKWZrayo3s32eUqqX0lAayoP2znnqk5JvjGImY0DxpWZd2PMawMuC6e4VDRgNJugUzV2C0reG7BLvCtxzrmqyt5aL880s2abW+acc6m2TVyeKWmQpOvC1wWSuqY2LOdcdSbC05Xi+C9TKk2ekv5JMAp1SjjrR+CBVAblnHNZim/KlHhOku9hZl0kfQBgZt+Gw/3OOZcaVbjpR6bEkzx/kZRFeEa+pO2BX1MalXOuWhPRHzCKp8/zPuB5YAdJfwEmAbenNCrnXLWXxCuMUqLSlqeZPS5pBnBIOGugmX2S2rCcc9XdtnDYDpAN/EJw6O5XJTnnUirTrcp4xDPafj3wNJBHcEH9fyVdm+rAnHPVWxKvbU+JeFqeJwNdzexHAEm3ADOAW1MZmHOuestkYoxHPMlzcZlyOVRytxHnnNsSIrPncMajohuD3EPQx/kjMFvShPD9YQQj7s45lxpb+XmeJSPqs4GxMfPfS104zjkXiHjurPDGIA+nMxDnnIsV9ZZnPKPtrSSNkPSRpM9LpnQEtzV7681XObTHXvTapwMP/P3OTZZPnTKJAYfsyx559Rg/ZtTG+UVLvuTIQ3vQv9c+9DmgK/997MF0hp0Wh3bK58N7j+XjfxzH5Ud13GR5QZM6jL/pcKYMO5L37zqK3p0LAOjVMY/Jtw9g6l1HMfn2AfTssHO6Q0+LN16bwN6d29OtYxuG33XHJsvXrVvHmacOplvHNhx6YA++XLwIgC8XLyK/ST167tuVnvt25fKL/pDmyJOn5AqjeKZMiWfA6FHgZuBO4HDgdPzyzAoVFxdz0zWX8tgzL9M0L59jeu/Pwb37stsebTeWyctvxh33/h8P/eveUp/dYaemPPPy/6hZsyZr1/7AET27cXDvvuzUNC/dm5ESWVninrP2pd/QCRR9u5Z3bhvA2Olf8mnhb8/ZuubYTrzw7kIefPVT2hQ0ZNR1h9L2D8+y8vufOe6211i26ifaNWvI6Bt60/rckRncmuQrLi7mqssu4vnR48nLL+CQA35HnyP60aZtu41lnnzsERo2bMj0jz7lhWdH8pc/XcfDj/8XgOYtWvHWlBmZCj+pot3ujO+E99pmNgHAzOab2Q2Ez/pw5Zs1czq7tmjFLs1bkJubS9+jjuP1V14uVaZgl11p035PsrJK/wlyc3OpWbMmAOvXrePXX7et36lurZsw/6s1LPrme37Z8CvPTV5Av+6l76ttZtSrXQOA+rVrsGzVjwDMWvgty1b9BMCcJd9RMzeb3Jxt65qNmdOn0qJlK5q3aElubi5HH3cC48eOKVVm/NgxDDopuMnZgKOP5e2JbxLcCH3bIUX/PM94vnnrFHQ+zJd0nqT+wI4pjmur9vVXS9k577fHQjfNy+frr8o+rG/zlhYV0vfAvdm/y+6cc8Fl20yrEyCvcR2KVqzd+L5o5VryGtcuVeaWZz5g0P6t+OLfJzDqusO4/OFNxyiP+l1zZi38lvUbtq0fl2VLl5JfULDxfV5+PsuWFm1SJq8guFd5Tk4O9Rs04NuVweN2vly8kAN7dKN/715Mmbx1nxQT9Wvb40melwJ1gYuA/YCzgTPiqVzS0ZJMUpvwfXNJm1wXL+lRSQslfRhO74bzh0haHs77VNKl4fzrY8oWx7y+KL7NTq3yWgFVuWlrXn4BYydO5Y33PmbUyKdY8c3XyQwvo8r7spfdXQN/35InJ85jt3NHcvTfXuWhCw8o9bm2BQ25+eRuXPjvyakNNgPK/e6U2WmbK7NT052ZNXcBE9+dzl9vG8Y5Z5zCmjVb76PGFJ6uVNmUKZUmTzN738y+N7MvzewUMxtgZvF+a08kOCd0UBxlrzSzTuHUI2b+SDPrRJC4r5fUzMxuKSkL/BTzub/HGVdKNd25dGvhq6VF7Ni06oMbOzXNY7c2bZn2/rvJDC+jilauJb9JnY3v87evs/GwvMRpB+/O8+8uBGDq58uplZtDk3q1gvKNazPiqoM56x9vs/Dr79MXeJrk5edTVFi48f3SoiKa7py3SZmlhUsA2LBhA2tWr6ZR48bUrFmTxttvD0Cnzl1p0aIl8+dtnWO7Ir7BokwOGG02eUoaJemFzU2VVSypLkHCO5P4kmeFwseAzgMiP8TasXNXFi+Yx5LFi1i/fj1jX3yOg3v3jeuzy5YW8vNPQb/e6u9WMWPqe7RstVsqw02rGfNW0HrnBuy6Y11q5GRx3H4tGTvty1JlCles5aA9gz/zHvkNqFUjm+VrfqZB7Vyev+4wbnxqOu999k0mwk+5zl27s2D+PBYvWsj69esZ9dxIDj+iX6kyfY7ox4inngBg9Kjn2b/nQUhixfLlFBcXA7Bo4QLmz59H8+Yt074NSRHnIXtUb0n3zy2s+yjgFTP7XNK3kroA31ZQfpikG8LXs83spNiFknYBagEfVTUQSecA5wAb+4pSKScnhz/fejenDxpAcXExA088ld3btGP47UPpsFcXDunTj48+mM75pw9izXff8ear47h32M288vYM5n/xGbf++VokYWacdf7F7NGuQ8pjTpfiX43LHprC6Bt6k50lHn/zC+YWfsefTujMzPkrGDt9Cdc8NpX7ztuPC/p1ADPOue9tAM47vC2tmtbj2uM6ce1xnQDo/9cJLF/zcyY3KalycnK4/a57GXhUX4qLixl8yhDatGvPrX+9iU5dunJ43/6cfNoZnH/WELp1bEPDRo146NGnAHh38jvcdvNfyMnJJjs7m7vuvY9GjRtneIsSF/XzPJWqUTpJY4HhZvZa2BfZjODGyi+bWYcyZR8N5z9XZv4QYBjwDbAHcLaZ/adMmR/MrG68ce3ZqYu9+Oq211eWDHv+4elMhxBphY+dmukQIqvX/vvw4cwZSct2O7buYCcMezausv88pt0MM+uWrHXHK977eVZJ+KiOXkAHSUZwP1AD7k+gupFmdoGkfYGxksab2VdJDNc5FzEi+i3PVJ0kdxzwuJntambNw2fALyS4H2hCzGwK8ARwcZJidM5FWE5WfFOmxL1qSTWrUO+JwKgy854HrgP2kFQYMw0Mlw+LOeXow808ofN24HRJ9aoQi3NuKxMMBkX7VKVKD9sl7Q08DDQAdpG0F3CWmV24uc+Y2YHlzPs7sLlTiTbXufFoOJXUsRRoWqbeuPs7nXNbj6jfzzOeluffgX7ASgAzm4VfnumcS7Gt+VSlEllmtrhM87g4RfE451x4J/loNz3jSZ5LwkN3k5QNXAhsnZctOOe2GtnRzp1xJc/zCQ7ddwG+Bl4P5znnXEoow3dMikelydPMviEJl1c651xVRDx3xjXa/iDBCe6lmNk5KYnIOeeI/mh7PIftr8e8rgUcDSxJTTjOObeNDBiZWannHEh6AngtZRE555wgO+IPCUgkvBbArskOxDnnYinO/+KqS+oj6TNJ8yRdU0G548IbuFd6o5F4+jxX8VufZxbBbeU2u3LnnNtSwWF7kuoKTrG8DzgUKASmSRptZnPKlKtH8MSM9+Opt8LkGT67aC+g5Lbov9q29qQp51wkJXHAaG9gnpktAJA0AjgSmFOm3F+BO4Ar4oqvooVhohxlZsXh5InTOZcWVbgxSBNJ02OmsmcC5VN6kLswnBe7rs5AMzMr/ZjbCsQz2j5VUhczmxlvpc45tyVUtQGjFZXcDLm8NuzGhqCkLOAeYEjca6SC5Ckpx8w2AL8HzpY0H1gbBmJm1qUqK3LOuapI4qlKhQRPsihRAMQ+C7we0AGYGLZkmwKjJQ0ws+mbq7SiludUoAvBs4iccy5tkjlgBEwDdpPUgmD8ZhAwuGShma0GmmxctzQRuKKixAkVJ0+FFc9PPGbnnEtMshqeZrZB0gXABIJHAj1iZrMlDQWmm9noROqtKHnuIOmyCgK6O5EVOudc5URWnOdwxsPMxgHjysy7cTNlD4ynzoqSZzZQl/I7W51zLmWCB8BlOoqKVZQ8l5nZ0LRF4pxzJQQ5Eb8zSKV9ns45l25be8vz4LRF4ZxzZWy1d1Uys2/TGYhzzsWKeO6M6woj55xLK5HYLd/SyZOncy56tBUftjvnXKZsE3eSd865TIh26vTk6ZyLqIg3PD15OueiaOO9OiPLk6dzLnIEZHvyjJYa2VnkNaqV6TAiacmjp2Y6hEjL7xnX0xmqpXWfFSa9zminzmqYPJ1zWwHhh+3OOVdVfpK8c84lyFuezjmXgIjfkc6Tp3MueoLD9mhnT0+ezrlIivhRuydP51wUCXnL0znnqs5bns45V0WSX2HknHMJiXju9OTpnIsm7/N0zrkqCm6GnOkoKubJ0zkXSd7ydM65BPhjOJxzror8sN055xLiJ8k751zVyU9Vcs65hEQ8d3rydM5Fjz/DyDnnEhXt3OnJ0zkXTT5g5JxzCYj4UbsnT+dcNEU8d3rydM5Fj4j+A+Ci/nRP51x1FJ7nGc8UV3VSH0mfSZon6Zpyll8maY6kjyS9IWnXyur05OmciyTFOVVaj5QN3AccDrQDTpTUrkyxD4BuZtYReA64o7J6PXk656IpWdkT9gbmmdkCM1sPjACOjC1gZv8zsx/Dt+8BBZVV6snTORdBivs/oImk6THTOWUqyweWxLwvDOdtzpnA+Moi9AEj51zkVPHkyr3XAAAS6klEQVSuSivMrFsl1ZVl5RaUTga6AT0rW6m3PFPk1QmvsFf7NnRouxt33nHbJsvXrVvHKYMH0aHtbhyw3+9YvGgRACtXrqTPob3YoVE9Lr34gjRHnR5vvDaBfTq3p/tebbj3rk27ltatW8eZpw2m+15tOOygHny5eNHGZbM/+Yg+vX7Pft33Yv99OvHzzz+nMfL0OHTfNsx6/jo+GXU9V5x28CbLd2naiHH3/4GpT1/FhH9fQP6ODTbOn/zE5bz31JXMGHk1Zx3bI92hJ1fyDtsLgWYx7wuApZusTjoEuB4YYGbrKqvUk2cKFBcXc+nFF/DimHHMnDWbZ0eOYO6cOaXKPPqfh2nYqCGfzP2CCy+6hBuuCwYAa9WqxY03DeVvtw/LROgpV1xczNWXX8TIF8YwedpHvPDcCD77tPS+eerxR2jYsCHTZn3KeX+8mL/ceB0AGzZs4PyzTuPOe+9j8rRZvDTuDWrUqJGJzUiZrCwx/OrjOPKif9N54G0M7N2FNi12KlXm1kuO5Kmx09j7xDv424MTGHpBPwCWrVjDQWcM53cnDeOAIfdwxWmHsHOT+pnYjKSowmF7ZaYBu0lqISkXGASMLrUuqTPwb4LE+U08lXryTIHp06bSqlVrWrRsSW5uLscdfwIvj3mpVJmxY0Zz8imnAXD0sccx8X9vYGbUqVOHHvv9nlq1amUi9JSbOX0qLVq2onmLYN8cfewJjH95TKky48eOYdDgUwAYcNSxvDPxTcyM/73xGu067EmHPfcCoPH225OdnZ32bUil7u13Zf6SFSwqWskvG4p59tUP6Ndzz1Jl2rTYiYnTPgfgrelf0O+AYPkvG4pZ/0sxADVzc8iK+t2EK5GsU5XMbANwATABmAs8Y2azJQ2VNCAsNgyoCzwr6UNJozdT3UaePFNgaVER+QW/Ddbl5xewdGlROWWCI4mcnBzqN2jAypUr0xpnJixbtpS8/N/2TV5+PsuWld43y5Yu3WTffLtyJfPnfY4kBh51BAf9vjt/v+fOtMaeDnk7NqDw61Ub3xd9893Gw/ISH3+xlKN6BT8gRx7Ukfp1a9G4QW0ACnZqyNSnr+KLsTdx12NvsGzFmvQFn2TJO2oHMxtnZrubWSszuyWcd6OZjQ5fH2JmO5lZp3AaUHGNGUyekorDDF8yNY9Zdq+kIklZMfOGSPpnOfUsktQkPVHHx2zTvuiyV0vEU2ZbtCX7ZsOGYt6f8i4PPPQ4Y199i3FjXuTtiW+mLNZMKHdko8z+uHb4S+zfpRVTnrqC/bu0oujr79iw4VcACr/+jr1PvIMOR93Myf26s2PjummIOgUU/M3jmTIlky3Pn2KyfCczWwQQJsyjCU4tOCCD8SUsv6CAosLCje+LigrZeee8csoEZ09s2LCBNatX07hx47TGmQl5efksLfpt3ywtKqJp09L7Ji8/f5N906hxY/Ly8+mx3/5s36QJtWvX5pDehzPrww/SGn+qFX2zmoKdGm18n79jQ5YuL916XLZiDYOu+g/7nnQnf75/LABr1v68SZk5879iv86tUh90CgSXZybvCqNUiOJh+0HAJ8C/gBMzHEtCunbrzrx5X7Bo4ULWr1/Pc8+MpG+/0kcBR/Trz5NPPAbAqOefo+eBvapFy7Nz1+4smD+PxYuCfTPq+ZH06duvVJk+R/RjxH+fAGD0i8+zf8+DkESvgw9j9uyP+fHHH9mwYQPvTnqbPdq0zcRmpMz0OV/SulkTds1rTI2cbAYe1pmxb39Sqsz2Deps/K5cefohPDb6fQDyd2xArZrBAFrDetux714t+HxRXGMfkZTMw/ZUyOR5nttJ+jB8vdDMjg5fnwg8DbwE/E1SDTP7ZUtWFJ40ew5As1122ZKq4pKTk8Pdw//BgL59KP61mFNPO5127dsz9KYb6dK1G/36D2DI6Wdy5pBT6dB2Nxo1aszjTz698fNtdmvB92vWsH79esaMfokxYyfQtl3Zq8m2Tjk5Odx2570MPKovv/5azOBThtCmbXtuvfkmOnXuyuF9+3PSqWfwh7OH0H2vNjRs1IgH//MUAA0bNeL8Cy7h0J77IolDDuvDYX2OyOwGJVlx8a9cOux5xvzjPLKzs3hs9PvMXfAVfzr3cGbO/ZKxb8/mgG6tGfrHfpgZkz6YzyW3PwfAHi124rZLjsLMkMTwJ//H7PnLMrxFWyDibQmV17+UlhVLP5hZ3TLzcoFFwB5m9r2kF4CHzWyspCEE155eUOYzi8L5K+JZb5eu3Wzye9OSsQnbnB/XFWc6hEgrOPCKTIcQWevmPs2va79OWrrrsFcXe+6VSXGVbZtXZ0YlJ8mnRNSuMOoDNAA+Dg9LagM/AmMzGZRzLv2i3osVteR5InCWmT0NIKkOsFBS7cyG5ZxLt6gnz8gMGIUJsjcxrUwzWwtMAvqHs4ZIKoyZSk4Y/Chm3t3pjdw5l2zBYFDSrjBKiYy1PMv2d4a3g9rkXB0zOybm7aPlVNU8qYE55zIvw6chxSNqh+3OOQdEfrDdk6dzLqIinj09eTrnIkhkRfy43ZOncy5yMn31UDw8eTrnoini2dOTp3MukjJ5GlI8PHk65yIp4l2enjydcxGkKj0ALiM8eTrnIira2dOTp3Muckpuhhxlnjydc5EU8dzpydM5F03e8nTOuQRE/bE0njydc5EU7dTpydM5F0GZfjJmPDx5Ouciya8wcs65REQ7d3rydM5Fk19h5JxzVZbZ5xPFw5Oncy5ytoYrjCLz9EznnNuaeMvTORdJUW95evJ0zkWP8GcYOedcVfkzjJxzLlERz56ePJ1zkeSnKjnnXAIi3uXpydM5F02ePJ1zLgFRP2yXmWU6hrSStBxYnOk4Qk2AFZkOIsJ8/2xe1PbNrma2Q7Iqk/QKwTbGY4WZ9UnWuuNV7ZJnlEiabmbdMh1HVPn+2TzfN5nnl2c651wCPHk651wCPHlm1v9lOoCI8/2zeb5vMsz7PJ1zLgHe8nTOuQR48nTOuQR48nRbHUm1Mx2Dc5483VZF0sHARZJqZToWV7158owASe0l+QnPlZDUG7gLmGRmP2c6Hle9efLMMEmHA48Cp0jaI8PhRJakw4BxwANmNklSjUzH5Ko3P1UpgyQdAQwDTjezqTHz65rZD5mLLFrCFuffgMnA8cAAM5sqKdvMijMbXeZI+j2wn5ndnulYqiO/q1IGSBJQCzgBuLxM4rwTMEn/MLMvMxVjVEhqBBwHXGJm70j6FJgg6VAzm17NE+hy4AJJv5rZsJKZkmTeKko5P2zPAAv8RLD/FSZTJJ0M9ASaA38ME0e1JakBsBo4P0ycWWZ2P3At8JqkbmZWLCk7s5Gmn6QcM/sMOBg4Q9LV4XzFlOkuqV6mYtzWefJMM0kHS7oy7LNbD7QyM5OUBcw0s+5mNhDoALTMaLAZJKkf8BzwPtBPUg7h99XMHiBIoOMk/a46tTxLkqGZbQgT6OfAkcAQSdeGP8wm6VzgH0CdTMa7LfPD9jSJOZTaG/jBzH6R9CBBAlhjZo8Dc8KyRwM1gMLMRZw5YV/wUOBM4HfAVcACM/uo5DDdzB6QtB3wtKS2wLpt/VBVUgvgakkPm9m02AQq6UjgJUkrgB+Bq4FjzOyrjAa9DfPkmSYx/7DrEiRGzOw9SYOAEZKaAMuA+sAfgUFm9nVGgs2gcD9cB8wwsw+ADyTVAXpJmm9ma0vKmtk9kv5TjU5bqgV8BZwqqdjMZoYJtGZMAn0dqA30MrOPMhrtNs4P29NAUgdJo8O33wLbhfNlZq8ChwPNCPo79wIGm9mcjASbQZJamNkKYDjwvaSLwkWdgMHAbEmXSzo75mOr0x1nppjZXOAZYClwlqQu4aL14f83AL2Abp44U89PVUoDSXWBJ4G1wLvA92b2eNjPmWtmP0uqY2Zrw8OwDRkNOAMk9SHoo/s9wWHnIcChBH2/PwKDgL4Ej2Y4AzisOrTMJR1IcIT4tpmtD+ftCfQDdgUeNLMZks4B7gZa+6F6enjyTKHwELTYzFZJqgncD5xO0FJ4HmgBiOBw/VvgXODXbb3vrqwwcf4FuNbM3izp15TUH7gAGG9mw2PKV4sfmPBsg7EE35PhBN+lu8NlLYCTgHpANkEyPcHMZmUo3GrHk2eKhIMeNwGLgC/M7PpwpPQ2glZVT4L+z5bAKmBNeOpJtSKpOzASuMLMXpC0K/Av4EKCw9PDgQOA5WZ2S/iZanMeo6RrCH5ULyX4ISkERgFvEiTNqwm6NI40sw8zFWd15H2eKRC2pK4DbiG4MmYXSbXN7HvgcmA6wTXaC83s1XDktNolzlBTYDbwlaROBN0b481sfngu7ARgCtCk5LzXbT1xSmoac77mXcB4gq6eQ4Bc4B7gbYIflXFAV0+c6ectzyST1JjgkbDHmtkoSXsDLxG0FrLN7FxJuQTnMK4xs5MzGG7GxLYeJQ0mOOzsAjxmZrfGlGtjZp9Wl0tWJfUF/kzQv7uSoL/zOuAH4AWC0fTTCS6k6AVcZmYrMxJsNefJMwXCfwA3A0OAOwkGiR4iSJgLzWxQePpNAzNbmrFAM0xSbswgSH+CgaBHgMlm9m14xdVfgb3NbHkGQ02L8IjleuAWM3ulZP9IagbMIOjmOd7MXg7L1zazHzMYcrXm53mmgJmNlVQMfABcZ2a3wcZ7Ub4kafuwtbC2onq2ReFI8c3AUWFiyDWz9WY2RlJ9YCBQHA6IDAb6VZPE2ZjgEPyYMHG2Am6UdKWZLZF0A9DRzF6O2WeeODPI+zxTxMxeAXoDp0tqGM4eSHCO5/rNfnDbtwj4heB8RUoSaPj6KWAMcBFwPnCOmc3OUJxpZWbfAv0JEmZHgqdjfmBm34RFZgEHS9q9pLXuMsuTZwqZ2WvAJcAkSX8g6Ks6Jxw4qlYkNQUIt/0kYL2kF8N5GxMoweHpSOCI6pI4S5jZWIL+zQ+B18xseMlNT8zsfeC/mYzPleZ9nmkQ3uTiBaBzdUsIEAz6EFy3fy8wx8weDPt87wF2Jrg/p4VXFJ1FcGnhisxFnFmSDiW4YGAfM1sdXn65LtNxudI8eaZJde7cDwc8RgCjCW6htoygdfkJQct8R+At4EqCE70/yFCokaHgCQPDgX3DQ3oXMT5glCbVNXEChAMeUwlORTqCoO/3HKAhwU1Q/gP0wW9msZGZjQ+7Ml5X8Hwr29bPb93aeMvTpVTJ+ZxhInicoKXZhiBhvk5wF6liYKiZfZq5SKOpupzfujXylqdLqTBxiuAa/nkEN6/oAlxqZi9K2p3g0stVmYwzqjxxRpe3PF3aKHg66DvAP8zsr5mOx7kt4acqubQJr9+/GsiWVDvT8Ti3JTx5unSbAnTNdBDObSk/bHdpV51P23LbDk+ezjmXAD9sd865BHjydM65BHjydM65BHjydM65BHjydABIKpb0oaRPJD27JedhSjpQUsndzgeEDzHbXNmG4e36qrqOmyRdEe/8MmUelXRcFdbVXNInVY3Rbds8eboSP5lZJzPrQHCz5vNiFypQ5e+LmY0uuZP+ZjQEqpw8ncs0T56uPO8ArcMW11xJ9wMzgWaSDpM0RdLMsIVaF4Ln70j6VNIk4JiSiiQNkfTP8PVOkkZJmhVOPQgexdwqbPUOC8tdKWmapI8k/SWmruslfSbpdWCPyjZC0tlhPbMkPV+mNX2IpHckfR7ebxVJ2ZKGxaz73C3dkW7b5cnTlSIph+BZ6R+Hs/YAHjezzgTPXLoBOMTMuhA8QvkySbWABwkeI7E/weOEy/N34C0z24vg5iCzgWuA+WGr90pJhwG7AXsDnYCukg6Q1BUYBHQmSM7d49icF8yse7i+ucCZMcuaAz0JnlL5QLgNZwKrzax7WP/Z4bOUnNuE31XJldhOUsmzv98BHgbygMVm9l44/3dAO2BycKMkcgkut2xD8FTQLwAkPUlwv86yegGnAphZMbBa4bPYYxwWTiU3RK5LkEzrAaNKrkySNDqObeog6WaCroG6BM+AL/GMmf0KfCFpQbgNhwEdY/pDG4Tr/jyOdblqxpOnK/GTmXWKnREmyNgnfIrg2TonlinXCUjWpWoCbjWzf5dZxyUJrONRgqd0zpI0BDgwZlnZuixc94VmFptkkdS8iut11YAftruqeA/YT1JrCK5RD+/H+SnQInxcLsCJm/n8GwRPxSzpX6wPfE/QqiwxATgjpi81X9KOwNvA0ZK2k1SPoIugMvWAZZJqEDx0LtZASVlhzC2Bz8J1nx+WR9Lu4bOWnNuEtzxd3MxsediCe1pSzXD2DWb2uaRzgLGSVgCTgA7lVHEx8H+SziS4e/z5ZjZF0uTwVKDxYb9nW2BK2PL9ATjZzGZKGknwZMnFBF0LlfkT8H5Y/mNKJ+nPCJ6btBNwnpn9LOkhgr7QmeENnJcDR8W3d1x14zcGcc65BPhhu3POJcCTp3POJcCTp3POJcCTp3POJcCTp3POJcCTp3POJcCTp3POJeD/AUcUMWs7n+X1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_confusion_matrix = results[2]\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "mlu.plot_confusion_matrix(model_confusion_matrix, classes=['BKG', 'ALERT', 'FALL'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "mlu.plot_confusion_matrix(model_confusion_matrix, classes=['BKG', 'ALERT', 'FALL'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 256, 128, 'lstm', 0.0008, 32, 0.2, 0, False, False]\n",
      "[2, 256, 128, 'lstm', 0.0008, 32, 0.2, 0.2, False, False]\n",
      "[3, 256, 128, 'lstm', 0.0008, 32, 0.35, 0, False, False]\n",
      "[4, 256, 128, 'lstm', 0.0008, 32, 0.35, 0.2, False, False]\n",
      "[5, 256, 128, 'lstm', 0.0008, 64, 0.2, 0, False, False]\n",
      "[6, 256, 128, 'lstm', 0.0008, 64, 0.2, 0.2, False, False]\n",
      "[7, 256, 128, 'lstm', 0.0008, 64, 0.35, 0, False, False]\n",
      "[8, 256, 128, 'lstm', 0.0008, 64, 0.35, 0.2, False, False]\n",
      "[9, 256, 128, 'gru', 0.0008, 32, 0.2, 0, False, False]\n",
      "[10, 256, 128, 'gru', 0.0008, 32, 0.2, 0.2, False, False]\n",
      "[11, 256, 128, 'gru', 0.0008, 32, 0.35, 0, False, False]\n",
      "[12, 256, 128, 'gru', 0.0008, 32, 0.35, 0.2, False, False]\n",
      "[13, 256, 128, 'gru', 0.0008, 64, 0.2, 0, False, False]\n",
      "[14, 256, 128, 'gru', 0.0008, 64, 0.2, 0.2, False, False]\n",
      "[15, 256, 128, 'gru', 0.0008, 64, 0.35, 0, False, False]\n",
      "[16, 256, 128, 'gru', 0.0008, 64, 0.35, 0.2, False, False]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 32)                4736      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,847\n",
      "Trainable params: 4,841\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 48s 509us/step - loss: 2.4900 - acc: 0.5399 - val_loss: 2.4626 - val_acc: 0.6113\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 2.3139 - acc: 0.5057 - val_loss: 2.3457 - val_acc: 0.2671\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 2.2628 - acc: 0.4659 - val_loss: 2.3378 - val_acc: 0.6885\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 41s 435us/step - loss: 2.0532 - acc: 0.5782 - val_loss: 2.1373 - val_acc: 0.7098\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 1.8706 - acc: 0.6652 - val_loss: 1.9919 - val_acc: 0.5153\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 41s 436us/step - loss: 1.9307 - acc: 0.6081 - val_loss: 1.9756 - val_acc: 0.6045\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 1.8380 - acc: 0.6555 - val_loss: 1.7561 - val_acc: 0.8126\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 41s 437us/step - loss: 1.7382 - acc: 0.6974 - val_loss: 1.9767 - val_acc: 0.7451\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 41s 435us/step - loss: 1.7012 - acc: 0.6953 - val_loss: 1.6840 - val_acc: 0.7480\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 41s 435us/step - loss: 1.4539 - acc: 0.7442 - val_loss: 1.4420 - val_acc: 0.7572\n",
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 41s 435us/step - loss: 1.3390 - acc: 0.7795 - val_loss: 1.5161 - val_acc: 0.8307\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 1.3224 - acc: 0.7917 - val_loss: 1.4633 - val_acc: 0.8603\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 1.2697 - acc: 0.7947 - val_loss: 1.5180 - val_acc: 0.8589\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 1.3480 - acc: 0.8031 - val_loss: 1.3387 - val_acc: 0.8207\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 1.2220 - acc: 0.7877 - val_loss: 1.3962 - val_acc: 0.8390\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 41s 437us/step - loss: 1.1952 - acc: 0.8077 - val_loss: 1.2176 - val_acc: 0.8707\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 41s 434us/step - loss: 1.1114 - acc: 0.8342 - val_loss: 1.1926 - val_acc: 0.8744\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 42s 442us/step - loss: 1.0353 - acc: 0.8539 - val_loss: 1.2768 - val_acc: 0.8849\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 41s 437us/step - loss: 0.9954 - acc: 0.8584 - val_loss: 1.2110 - val_acc: 0.9282\n",
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 41s 439us/step - loss: 0.9968 - acc: 0.8597 - val_loss: 1.1896 - val_acc: 0.9206\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 42s 451us/step - loss: 0.9540 - acc: 0.8663 - val_loss: 1.0317 - val_acc: 0.9361\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 42s 445us/step - loss: 0.9340 - acc: 0.8941 - val_loss: 1.1367 - val_acc: 0.9167\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 42s 444us/step - loss: 0.9018 - acc: 0.8951 - val_loss: 1.2760 - val_acc: 0.9202\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 41s 441us/step - loss: 0.8730 - acc: 0.8941 - val_loss: 1.1843 - val_acc: 0.8418\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.8793 - acc: 0.9034 - val_loss: 1.1275 - val_acc: 0.9234\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.8203 - acc: 0.9082 - val_loss: 1.0583 - val_acc: 0.8978\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.8052 - acc: 0.9175 - val_loss: 1.0730 - val_acc: 0.9363\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.8180 - acc: 0.9135 - val_loss: 1.0420 - val_acc: 0.8986\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.7702 - acc: 0.9203 - val_loss: 1.0615 - val_acc: 0.9080\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.7713 - acc: 0.9153 - val_loss: 1.0602 - val_acc: 0.9297\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.7435 - acc: 0.9243 - val_loss: 0.9842 - val_acc: 0.9369\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.7499 - acc: 0.9215 - val_loss: 1.0761 - val_acc: 0.9401\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.7238 - acc: 0.9277 - val_loss: 1.0779 - val_acc: 0.8935\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.7031 - acc: 0.9286 - val_loss: 1.1410 - val_acc: 0.9339\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.7084 - acc: 0.9313 - val_loss: 0.9770 - val_acc: 0.9049\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.6940 - acc: 0.9284 - val_loss: 0.9069 - val_acc: 0.9229\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6688 - acc: 0.9309 - val_loss: 0.9412 - val_acc: 0.9336\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.6585 - acc: 0.9287 - val_loss: 1.1267 - val_acc: 0.9372\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.6641 - acc: 0.9318 - val_loss: 1.0699 - val_acc: 0.9412\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.6531 - acc: 0.9320 - val_loss: 0.9451 - val_acc: 0.9037\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.6594 - acc: 0.9314 - val_loss: 0.9406 - val_acc: 0.9361\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.6524 - acc: 0.9288 - val_loss: 0.9911 - val_acc: 0.9380\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.6391 - acc: 0.9279 - val_loss: 0.9609 - val_acc: 0.9403\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.6260 - acc: 0.9326 - val_loss: 1.0790 - val_acc: 0.9307\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 40s 420us/step - loss: 0.6114 - acc: 0.9328 - val_loss: 1.0692 - val_acc: 0.9398\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.6145 - acc: 0.9356 - val_loss: 1.1170 - val_acc: 0.9399\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.6196 - acc: 0.9280 - val_loss: 1.1261 - val_acc: 0.9383\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.6209 - acc: 0.9306 - val_loss: 0.9474 - val_acc: 0.9385\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.6141 - acc: 0.9316 - val_loss: 0.9402 - val_acc: 0.9024\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.6292 - acc: 0.9331 - val_loss: 0.9720 - val_acc: 0.9160\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.6030 - acc: 0.9335 - val_loss: 0.9536 - val_acc: 0.9456\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.5951 - acc: 0.9294 - val_loss: 1.1061 - val_acc: 0.9311\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5912 - acc: 0.9324 - val_loss: 1.0518 - val_acc: 0.9335\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.5752 - acc: 0.9299 - val_loss: 0.9974 - val_acc: 0.9272\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.6123 - acc: 0.9342 - val_loss: 1.1244 - val_acc: 0.9342\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5772 - acc: 0.9388 - val_loss: 0.9899 - val_acc: 0.9373\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5756 - acc: 0.9348 - val_loss: 1.1963 - val_acc: 0.9409\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.5564 - acc: 0.9374 - val_loss: 1.1225 - val_acc: 0.9324\n",
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.6130 - acc: 0.9307 - val_loss: 1.0773 - val_acc: 0.9319\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5709 - acc: 0.9357 - val_loss: 1.0400 - val_acc: 0.9366\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5442 - acc: 0.9358 - val_loss: 1.1619 - val_acc: 0.9230\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.6061 - acc: 0.9273 - val_loss: 1.0446 - val_acc: 0.9272\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.5508 - acc: 0.9359 - val_loss: 1.1082 - val_acc: 0.9350\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5590 - acc: 0.9382 - val_loss: 1.1848 - val_acc: 0.9375\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.5634 - acc: 0.9361 - val_loss: 0.8525 - val_acc: 0.9092\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5489 - acc: 0.9388 - val_loss: 0.8584 - val_acc: 0.9352\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5323 - acc: 0.9363 - val_loss: 1.0251 - val_acc: 0.9335\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.6260 - acc: 0.9403 - val_loss: 0.9156 - val_acc: 0.9191\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5579 - acc: 0.9347 - val_loss: 1.1155 - val_acc: 0.9360\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5723 - acc: 0.9377 - val_loss: 0.9745 - val_acc: 0.9277\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5377 - acc: 0.9358 - val_loss: 1.0138 - val_acc: 0.9308\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.5342 - acc: 0.9381 - val_loss: 1.0685 - val_acc: 0.9443\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5308 - acc: 0.9369 - val_loss: 0.9933 - val_acc: 0.9245\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5405 - acc: 0.9400 - val_loss: 0.8752 - val_acc: 0.9300\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5145 - acc: 0.9384 - val_loss: 0.9973 - val_acc: 0.9436\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5391 - acc: 0.9412 - val_loss: 0.9114 - val_acc: 0.9396\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.5079 - acc: 0.9384 - val_loss: 0.8905 - val_acc: 0.9314\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.4912 - acc: 0.9403 - val_loss: 1.1000 - val_acc: 0.9512\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5437 - acc: 0.9355 - val_loss: 1.0326 - val_acc: 0.9336\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.5330 - acc: 0.9371 - val_loss: 1.0154 - val_acc: 0.9221\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5249 - acc: 0.9374 - val_loss: 1.1075 - val_acc: 0.9351\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.4962 - acc: 0.9418 - val_loss: 1.0159 - val_acc: 0.9277\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5121 - acc: 0.9422 - val_loss: 1.2159 - val_acc: 0.9345\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.4784 - acc: 0.9428 - val_loss: 1.1165 - val_acc: 0.9468\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5079 - acc: 0.9388 - val_loss: 1.0665 - val_acc: 0.9474\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.5032 - acc: 0.9395 - val_loss: 1.0091 - val_acc: 0.9485\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5163 - acc: 0.9379 - val_loss: 1.0326 - val_acc: 0.9387\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5189 - acc: 0.9370 - val_loss: 1.1087 - val_acc: 0.8775\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.5424 - acc: 0.9329 - val_loss: 0.9537 - val_acc: 0.9312\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.5070 - acc: 0.9377 - val_loss: 0.9669 - val_acc: 0.9328\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5264 - acc: 0.9369 - val_loss: 1.1250 - val_acc: 0.9420\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.5108 - acc: 0.9348 - val_loss: 0.9526 - val_acc: 0.9379\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5301 - acc: 0.9367 - val_loss: 0.9590 - val_acc: 0.9290\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.4989 - acc: 0.9380 - val_loss: 0.9678 - val_acc: 0.9406\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.4853 - acc: 0.9390 - val_loss: 1.0213 - val_acc: 0.9367\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.4897 - acc: 0.9406 - val_loss: 0.9772 - val_acc: 0.9433\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.5036 - acc: 0.9431 - val_loss: 0.8972 - val_acc: 0.9426\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.4877 - acc: 0.9417 - val_loss: 1.0362 - val_acc: 0.9528\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.4821 - acc: 0.9409 - val_loss: 1.1251 - val_acc: 0.9420\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.4730 - acc: 0.9429 - val_loss: 1.2418 - val_acc: 0.9518\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, 32)                4736      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,847\n",
      "Trainable params: 4,841\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 2.5135 - acc: 0.5184 - val_loss: 2.4384 - val_acc: 0.4019\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 2.3266 - acc: 0.5476 - val_loss: 2.2712 - val_acc: 0.5792\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 2.1834 - acc: 0.6328 - val_loss: 2.2194 - val_acc: 0.5658\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 2.4773 - acc: 0.4950 - val_loss: 2.3972 - val_acc: 0.6782\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 2.2048 - acc: 0.5043 - val_loss: 2.1864 - val_acc: 0.3832\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 2.1307 - acc: 0.5801 - val_loss: 2.0686 - val_acc: 0.6324\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 1.9770 - acc: 0.6269 - val_loss: 2.1229 - val_acc: 0.7569\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 1.9563 - acc: 0.7112 - val_loss: 2.2152 - val_acc: 0.6809\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 1.9372 - acc: 0.7132 - val_loss: 1.7445 - val_acc: 0.6762\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 1.7563 - acc: 0.7317 - val_loss: 1.8419 - val_acc: 0.7861\n",
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 1.6899 - acc: 0.7184 - val_loss: 1.6566 - val_acc: 0.6397\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 1.7010 - acc: 0.7054 - val_loss: 1.7421 - val_acc: 0.6974\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 1.5123 - acc: 0.7113 - val_loss: 1.6121 - val_acc: 0.8616\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 1.5084 - acc: 0.7487 - val_loss: 1.8395 - val_acc: 0.7695\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 1.4676 - acc: 0.7428 - val_loss: 1.6396 - val_acc: 0.8282\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 1.3917 - acc: 0.7695 - val_loss: 1.4113 - val_acc: 0.7224\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 1.3620 - acc: 0.7678 - val_loss: 1.5183 - val_acc: 0.8272\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 1.3407 - acc: 0.7588 - val_loss: 1.6599 - val_acc: 0.7354\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 1.3022 - acc: 0.7763 - val_loss: 1.3883 - val_acc: 0.7057\n",
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 1.3760 - acc: 0.7856 - val_loss: 1.4811 - val_acc: 0.7443\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 1.2647 - acc: 0.7862 - val_loss: 1.3638 - val_acc: 0.8335\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 1.2604 - acc: 0.7775 - val_loss: 1.3041 - val_acc: 0.7805\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 1.1504 - acc: 0.8058 - val_loss: 1.2781 - val_acc: 0.8180\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 1.1188 - acc: 0.8346 - val_loss: 1.1416 - val_acc: 0.9144\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 1.0506 - acc: 0.8720 - val_loss: 1.2148 - val_acc: 0.8893\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 1.0171 - acc: 0.8699 - val_loss: 1.1389 - val_acc: 0.8991\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.9625 - acc: 0.8865 - val_loss: 1.1356 - val_acc: 0.9233\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.9394 - acc: 0.8861 - val_loss: 1.3627 - val_acc: 0.8991\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.9213 - acc: 0.8971 - val_loss: 1.0792 - val_acc: 0.8839\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.8820 - acc: 0.9059 - val_loss: 1.0013 - val_acc: 0.9018\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.8993 - acc: 0.8973 - val_loss: 1.0596 - val_acc: 0.9342\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.8384 - acc: 0.9120 - val_loss: 1.0055 - val_acc: 0.9260\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.8573 - acc: 0.9076 - val_loss: 1.0584 - val_acc: 0.8815\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.8059 - acc: 0.9136 - val_loss: 0.9521 - val_acc: 0.9080\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.8385 - acc: 0.9031 - val_loss: 1.0045 - val_acc: 0.9293\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.8076 - acc: 0.9104 - val_loss: 0.8882 - val_acc: 0.9403\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.7596 - acc: 0.9129 - val_loss: 1.0758 - val_acc: 0.9440\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.7711 - acc: 0.9198 - val_loss: 1.0496 - val_acc: 0.9372\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.7625 - acc: 0.9149 - val_loss: 1.1152 - val_acc: 0.9432\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.7707 - acc: 0.9176 - val_loss: 1.0761 - val_acc: 0.9193\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.7622 - acc: 0.9212 - val_loss: 0.9775 - val_acc: 0.9286\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.7486 - acc: 0.9219 - val_loss: 0.8423 - val_acc: 0.8932\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.8133 - acc: 0.9236 - val_loss: 0.9280 - val_acc: 0.9411\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.7393 - acc: 0.9241 - val_loss: 1.1027 - val_acc: 0.8979\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.7154 - acc: 0.9233 - val_loss: 0.9556 - val_acc: 0.9117\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.7484 - acc: 0.9195 - val_loss: 0.8684 - val_acc: 0.9439\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.7173 - acc: 0.9240 - val_loss: 0.9446 - val_acc: 0.9410\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6949 - acc: 0.9265 - val_loss: 0.9328 - val_acc: 0.9395\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.7085 - acc: 0.9202 - val_loss: 0.9525 - val_acc: 0.9386\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6969 - acc: 0.9122 - val_loss: 1.0112 - val_acc: 0.9423\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.6945 - acc: 0.9288 - val_loss: 0.9022 - val_acc: 0.9494\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6668 - acc: 0.9268 - val_loss: 0.8931 - val_acc: 0.9309\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6802 - acc: 0.9264 - val_loss: 0.8957 - val_acc: 0.9476\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.6808 - acc: 0.9275 - val_loss: 0.9265 - val_acc: 0.9355\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6602 - acc: 0.9310 - val_loss: 0.9537 - val_acc: 0.9176\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6583 - acc: 0.9287 - val_loss: 0.9133 - val_acc: 0.9482\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6392 - acc: 0.9277 - val_loss: 0.8462 - val_acc: 0.9398\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6523 - acc: 0.9249 - val_loss: 0.8928 - val_acc: 0.9386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6026 - acc: 0.9345 - val_loss: 0.9013 - val_acc: 0.9335\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6379 - acc: 0.9241 - val_loss: 0.8820 - val_acc: 0.9421\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6330 - acc: 0.9281 - val_loss: 0.9381 - val_acc: 0.9209\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6376 - acc: 0.9228 - val_loss: 1.0291 - val_acc: 0.9482\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6200 - acc: 0.9309 - val_loss: 0.9045 - val_acc: 0.9362\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5951 - acc: 0.9302 - val_loss: 0.8467 - val_acc: 0.8978\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.6164 - acc: 0.9224 - val_loss: 0.8924 - val_acc: 0.9424\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5933 - acc: 0.9281 - val_loss: 0.8896 - val_acc: 0.7979\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6276 - acc: 0.9117 - val_loss: 0.9371 - val_acc: 0.9413\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6041 - acc: 0.9341 - val_loss: 0.7600 - val_acc: 0.9391\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5882 - acc: 0.9314 - val_loss: 0.8922 - val_acc: 0.8640\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5882 - acc: 0.9254 - val_loss: 0.9833 - val_acc: 0.9081\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6279 - acc: 0.9270 - val_loss: 0.9462 - val_acc: 0.9436\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6508 - acc: 0.9263 - val_loss: 0.8717 - val_acc: 0.9328\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5809 - acc: 0.9313 - val_loss: 1.0875 - val_acc: 0.9097\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5923 - acc: 0.9293 - val_loss: 1.0264 - val_acc: 0.9479\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6586 - acc: 0.9155 - val_loss: 0.9308 - val_acc: 0.9204\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5837 - acc: 0.9294 - val_loss: 0.9660 - val_acc: 0.9390\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5994 - acc: 0.9252 - val_loss: 0.9172 - val_acc: 0.9418\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5848 - acc: 0.9276 - val_loss: 0.9472 - val_acc: 0.9443\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5801 - acc: 0.9278 - val_loss: 0.8976 - val_acc: 0.9437\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5587 - acc: 0.9302 - val_loss: 0.7989 - val_acc: 0.9251\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5544 - acc: 0.9304 - val_loss: 0.8455 - val_acc: 0.9392\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5699 - acc: 0.9283 - val_loss: 0.8790 - val_acc: 0.9351\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5832 - acc: 0.9294 - val_loss: 0.8693 - val_acc: 0.9369\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6020 - acc: 0.9282 - val_loss: 1.0134 - val_acc: 0.9465\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5765 - acc: 0.9256 - val_loss: 0.8542 - val_acc: 0.9384\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5918 - acc: 0.9250 - val_loss: 0.8212 - val_acc: 0.9342\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5701 - acc: 0.9263 - val_loss: 0.8384 - val_acc: 0.9279\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5656 - acc: 0.9244 - val_loss: 0.8200 - val_acc: 0.9360\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5764 - acc: 0.9311 - val_loss: 0.8780 - val_acc: 0.9427\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5649 - acc: 0.9306 - val_loss: 0.9876 - val_acc: 0.9440\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5621 - acc: 0.9306 - val_loss: 1.0093 - val_acc: 0.9418\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5669 - acc: 0.9316 - val_loss: 0.9445 - val_acc: 0.9448\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5821 - acc: 0.9242 - val_loss: 0.9201 - val_acc: 0.9493\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5404 - acc: 0.9295 - val_loss: 1.0067 - val_acc: 0.9440\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5517 - acc: 0.9301 - val_loss: 0.8842 - val_acc: 0.9413\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5285 - acc: 0.9335 - val_loss: 0.9280 - val_acc: 0.9355\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5488 - acc: 0.9343 - val_loss: 0.8730 - val_acc: 0.9335\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5269 - acc: 0.9313 - val_loss: 0.9641 - val_acc: 0.9396\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5471 - acc: 0.9278 - val_loss: 1.1308 - val_acc: 0.9466\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5476 - acc: 0.9194 - val_loss: 0.8615 - val_acc: 0.9432\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_3 (Batch (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 32)                4736      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,847\n",
      "Trainable params: 4,841\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 40s 431us/step - loss: 2.4684 - acc: 0.5340 - val_loss: 2.4132 - val_acc: 0.6457\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 2.3655 - acc: 0.5667 - val_loss: 2.2421 - val_acc: 0.6685\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 2.1054 - acc: 0.6814 - val_loss: 2.1817 - val_acc: 0.7142\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 1.7787 - acc: 0.7423 - val_loss: 1.9896 - val_acc: 0.7979\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 1.7696 - acc: 0.7230 - val_loss: 2.0791 - val_acc: 0.6600\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 1.7838 - acc: 0.6324 - val_loss: 1.9351 - val_acc: 0.3805\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 1.7140 - acc: 0.7258 - val_loss: 1.9171 - val_acc: 0.8007\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 1.7927 - acc: 0.7186 - val_loss: 2.0390 - val_acc: 0.8271\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 1.5863 - acc: 0.6860 - val_loss: 1.7242 - val_acc: 0.6927\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 1.4743 - acc: 0.7191 - val_loss: 1.6909 - val_acc: 0.5905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 1.5001 - acc: 0.6918 - val_loss: 1.6601 - val_acc: 0.5448\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 1.5596 - acc: 0.7196 - val_loss: 1.7465 - val_acc: 0.8287\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 1.3968 - acc: 0.6828 - val_loss: 1.4588 - val_acc: 0.7145\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 1.3408 - acc: 0.7382 - val_loss: 1.6662 - val_acc: 0.7801\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 1.2579 - acc: 0.7633 - val_loss: 1.4488 - val_acc: 0.8168\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 1.2251 - acc: 0.7845 - val_loss: 1.6045 - val_acc: 0.8764\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 1.2140 - acc: 0.8029 - val_loss: 1.5479 - val_acc: 0.7728\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 1.3231 - acc: 0.8096 - val_loss: 1.7025 - val_acc: 0.8634\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 1.2325 - acc: 0.8437 - val_loss: 1.6595 - val_acc: 0.8719\n",
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 1.3593 - acc: 0.8314 - val_loss: 1.4829 - val_acc: 0.8875\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 1.0569 - acc: 0.8597 - val_loss: 1.4647 - val_acc: 0.9284\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 1.0412 - acc: 0.8858 - val_loss: 1.5315 - val_acc: 0.9296\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.9712 - acc: 0.8898 - val_loss: 1.3407 - val_acc: 0.9288\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.9497 - acc: 0.8938 - val_loss: 1.2110 - val_acc: 0.9354\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.9008 - acc: 0.9033 - val_loss: 1.4339 - val_acc: 0.9579\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.9023 - acc: 0.9073 - val_loss: 1.1376 - val_acc: 0.9097\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.8569 - acc: 0.9095 - val_loss: 1.1083 - val_acc: 0.9147\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.8558 - acc: 0.8999 - val_loss: 1.3804 - val_acc: 0.8713\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.8324 - acc: 0.9177 - val_loss: 1.1954 - val_acc: 0.8934\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.8054 - acc: 0.9152 - val_loss: 1.2866 - val_acc: 0.9566\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.7768 - acc: 0.9143 - val_loss: 1.2460 - val_acc: 0.9095\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.7838 - acc: 0.9168 - val_loss: 1.3686 - val_acc: 0.9479\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.7832 - acc: 0.9148 - val_loss: 1.2348 - val_acc: 0.9412\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.7690 - acc: 0.9211 - val_loss: 1.1462 - val_acc: 0.9352\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.7653 - acc: 0.9190 - val_loss: 1.2766 - val_acc: 0.9249\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.7727 - acc: 0.9156 - val_loss: 1.2503 - val_acc: 0.9579\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.7401 - acc: 0.9136 - val_loss: 1.3099 - val_acc: 0.9486\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.7362 - acc: 0.9191 - val_loss: 1.3267 - val_acc: 0.9517\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.7063 - acc: 0.9197 - val_loss: 1.1764 - val_acc: 0.8354\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.7503 - acc: 0.9092 - val_loss: 1.2044 - val_acc: 0.9520\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.7193 - acc: 0.9216 - val_loss: 1.1619 - val_acc: 0.9494\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.7009 - acc: 0.9237 - val_loss: 1.1197 - val_acc: 0.9502\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.6953 - acc: 0.9264 - val_loss: 1.1448 - val_acc: 0.9481\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.7068 - acc: 0.9233 - val_loss: 1.5843 - val_acc: 0.9661\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.7074 - acc: 0.9187 - val_loss: 1.1657 - val_acc: 0.9337\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.6969 - acc: 0.9235 - val_loss: 1.2373 - val_acc: 0.9551\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.6772 - acc: 0.9290 - val_loss: 1.1361 - val_acc: 0.9378\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.6866 - acc: 0.9302 - val_loss: 1.2311 - val_acc: 0.9344\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6621 - acc: 0.9308 - val_loss: 1.2153 - val_acc: 0.9505\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6836 - acc: 0.9223 - val_loss: 1.2121 - val_acc: 0.9585\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.6794 - acc: 0.9288 - val_loss: 1.2375 - val_acc: 0.9627\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.6576 - acc: 0.9324 - val_loss: 0.9869 - val_acc: 0.9496\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6503 - acc: 0.9278 - val_loss: 1.2788 - val_acc: 0.9384\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.6620 - acc: 0.9267 - val_loss: 1.2226 - val_acc: 0.9577\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6533 - acc: 0.9260 - val_loss: 1.1348 - val_acc: 0.9477\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 40s 421us/step - loss: 0.6364 - acc: 0.9295 - val_loss: 1.3294 - val_acc: 0.9565\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6367 - acc: 0.9272 - val_loss: 1.0615 - val_acc: 0.9457\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.6102 - acc: 0.9298 - val_loss: 1.2389 - val_acc: 0.9498\n",
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.6258 - acc: 0.9347 - val_loss: 1.1018 - val_acc: 0.9276\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.6332 - acc: 0.9331 - val_loss: 1.1696 - val_acc: 0.9536\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6113 - acc: 0.9318 - val_loss: 1.1327 - val_acc: 0.9503\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.6065 - acc: 0.9314 - val_loss: 1.3591 - val_acc: 0.9573\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.6077 - acc: 0.9321 - val_loss: 1.0773 - val_acc: 0.9249\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5912 - acc: 0.9294 - val_loss: 0.9416 - val_acc: 0.9116\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5789 - acc: 0.9306 - val_loss: 1.2615 - val_acc: 0.9525\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.6121 - acc: 0.9293 - val_loss: 1.1362 - val_acc: 0.9465\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5890 - acc: 0.9349 - val_loss: 1.1011 - val_acc: 0.9616\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.6220 - acc: 0.9288 - val_loss: 1.1323 - val_acc: 0.9497\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5951 - acc: 0.9342 - val_loss: 1.1820 - val_acc: 0.9350\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5875 - acc: 0.9322 - val_loss: 1.0320 - val_acc: 0.9250\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5986 - acc: 0.9279 - val_loss: 1.0802 - val_acc: 0.9508\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5756 - acc: 0.9318 - val_loss: 1.0061 - val_acc: 0.9535\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5689 - acc: 0.9332 - val_loss: 1.0003 - val_acc: 0.9403\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5953 - acc: 0.9266 - val_loss: 1.2156 - val_acc: 0.9402\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5667 - acc: 0.9279 - val_loss: 1.0287 - val_acc: 0.9326\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.5633 - acc: 0.9321 - val_loss: 1.2857 - val_acc: 0.9499\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5662 - acc: 0.9257 - val_loss: 1.0859 - val_acc: 0.9478\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5511 - acc: 0.9296 - val_loss: 1.1067 - val_acc: 0.9423\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5566 - acc: 0.9316 - val_loss: 1.0757 - val_acc: 0.9530\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 40s 422us/step - loss: 0.5464 - acc: 0.9348 - val_loss: 1.0666 - val_acc: 0.9492\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5686 - acc: 0.9261 - val_loss: 1.0522 - val_acc: 0.9477\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5389 - acc: 0.9317 - val_loss: 1.1829 - val_acc: 0.9533\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5407 - acc: 0.9307 - val_loss: 0.9821 - val_acc: 0.9502\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5546 - acc: 0.9343 - val_loss: 0.9497 - val_acc: 0.9495\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5373 - acc: 0.9351 - val_loss: 0.9474 - val_acc: 0.9430\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5579 - acc: 0.9372 - val_loss: 1.1186 - val_acc: 0.9363\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5231 - acc: 0.9362 - val_loss: 1.0259 - val_acc: 0.9487\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5343 - acc: 0.9326 - val_loss: 1.0311 - val_acc: 0.8343\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5543 - acc: 0.9274 - val_loss: 1.1265 - val_acc: 0.9311\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5188 - acc: 0.9334 - val_loss: 1.1343 - val_acc: 0.9531\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5507 - acc: 0.9290 - val_loss: 0.9741 - val_acc: 0.9515\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5135 - acc: 0.9359 - val_loss: 1.1035 - val_acc: 0.9470\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5108 - acc: 0.9349 - val_loss: 0.9559 - val_acc: 0.9472\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5219 - acc: 0.9329 - val_loss: 1.1324 - val_acc: 0.9546\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5387 - acc: 0.9311 - val_loss: 1.0978 - val_acc: 0.9491\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5111 - acc: 0.9340 - val_loss: 1.4923 - val_acc: 0.9559\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5331 - acc: 0.9382 - val_loss: 1.0348 - val_acc: 0.9396\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5101 - acc: 0.9346 - val_loss: 1.0487 - val_acc: 0.9439\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5096 - acc: 0.9343 - val_loss: 1.0688 - val_acc: 0.9511\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5132 - acc: 0.9385 - val_loss: 1.0017 - val_acc: 0.9477\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_4 (Batch (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_4 (CuDNNLSTM)     (None, 32)                4736      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,847\n",
      "Trainable params: 4,841\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 41s 434us/step - loss: 2.5148 - acc: 0.5209 - val_loss: 2.4514 - val_acc: 0.0815\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 2.4103 - acc: 0.5066 - val_loss: 2.5563 - val_acc: 0.0408\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 2.3440 - acc: 0.4653 - val_loss: 2.3712 - val_acc: 0.6536\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 2.2777 - acc: 0.5214 - val_loss: 2.1534 - val_acc: 0.6414\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 2.1016 - acc: 0.6092 - val_loss: 1.9977 - val_acc: 0.6467\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 1.9795 - acc: 0.6505 - val_loss: 1.9869 - val_acc: 0.6154\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 1.8607 - acc: 0.6415 - val_loss: 1.7820 - val_acc: 0.6473\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 1.7571 - acc: 0.7249 - val_loss: 1.8351 - val_acc: 0.8160\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 1.8405 - acc: 0.7068 - val_loss: 1.9156 - val_acc: 0.7107\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 1.7030 - acc: 0.7147 - val_loss: 1.5986 - val_acc: 0.7473\n",
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 1.6281 - acc: 0.7261 - val_loss: 1.5872 - val_acc: 0.7316\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 1.5851 - acc: 0.7601 - val_loss: 1.8417 - val_acc: 0.8323\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 1.5817 - acc: 0.7661 - val_loss: 1.6638 - val_acc: 0.8071\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 1.7152 - acc: 0.7043 - val_loss: 1.7750 - val_acc: 0.7329\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 1.5966 - acc: 0.7126 - val_loss: 1.5277 - val_acc: 0.7523\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 1.5615 - acc: 0.7616 - val_loss: 2.6097 - val_acc: 0.8024\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 1.5971 - acc: 0.7579 - val_loss: 1.5127 - val_acc: 0.7688\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 1.4218 - acc: 0.7591 - val_loss: 1.6394 - val_acc: 0.7331\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 1.3503 - acc: 0.7635 - val_loss: 1.5293 - val_acc: 0.8157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 1.3678 - acc: 0.7609 - val_loss: 1.7833 - val_acc: 0.7406\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 1.3561 - acc: 0.7695 - val_loss: 1.6546 - val_acc: 0.7768\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 1.2976 - acc: 0.7871 - val_loss: 1.3769 - val_acc: 0.7865\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 1.2553 - acc: 0.8054 - val_loss: 1.5581 - val_acc: 0.8910\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 1.2311 - acc: 0.7843 - val_loss: 1.3572 - val_acc: 0.7323\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 1.2344 - acc: 0.7990 - val_loss: 1.6845 - val_acc: 0.7319\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 40s 431us/step - loss: 1.3707 - acc: 0.7766 - val_loss: 1.4373 - val_acc: 0.7569\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 1.2568 - acc: 0.7827 - val_loss: 1.4924 - val_acc: 0.8103\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 1.2424 - acc: 0.7947 - val_loss: 1.3015 - val_acc: 0.9172\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 1.2037 - acc: 0.8297 - val_loss: 1.4180 - val_acc: 0.7924\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 1.1777 - acc: 0.8273 - val_loss: 1.5003 - val_acc: 0.8497\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 1.3177 - acc: 0.7951 - val_loss: 1.4671 - val_acc: 0.7955\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 1.2465 - acc: 0.7990 - val_loss: 1.2538 - val_acc: 0.7650\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 1.2051 - acc: 0.7960 - val_loss: 1.5988 - val_acc: 0.8243\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 1.1545 - acc: 0.8152 - val_loss: 1.2010 - val_acc: 0.8999\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 1.0696 - acc: 0.8452 - val_loss: 1.1123 - val_acc: 0.9206\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 1.0627 - acc: 0.8545 - val_loss: 1.1404 - val_acc: 0.9388\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 1.0321 - acc: 0.8602 - val_loss: 1.2305 - val_acc: 0.9450\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.9913 - acc: 0.8865 - val_loss: 1.2717 - val_acc: 0.9370\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.9625 - acc: 0.8936 - val_loss: 1.3496 - val_acc: 0.9519\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.9260 - acc: 0.9050 - val_loss: 1.1581 - val_acc: 0.9364\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.8909 - acc: 0.9014 - val_loss: 1.2497 - val_acc: 0.9019\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.9480 - acc: 0.8923 - val_loss: 1.0898 - val_acc: 0.9267\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.9246 - acc: 0.9040 - val_loss: 1.2025 - val_acc: 0.9302\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.9026 - acc: 0.9181 - val_loss: 1.0991 - val_acc: 0.9228\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.8817 - acc: 0.9173 - val_loss: 1.0845 - val_acc: 0.9297\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.8564 - acc: 0.9198 - val_loss: 1.0552 - val_acc: 0.9493\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.8548 - acc: 0.9243 - val_loss: 1.1332 - val_acc: 0.9280\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.8748 - acc: 0.9291 - val_loss: 1.0435 - val_acc: 0.9346\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.8324 - acc: 0.9207 - val_loss: 1.3039 - val_acc: 0.9652\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.7990 - acc: 0.9261 - val_loss: 1.0969 - val_acc: 0.9458\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.8350 - acc: 0.9279 - val_loss: 1.1084 - val_acc: 0.9216\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.7820 - acc: 0.9285 - val_loss: 1.0115 - val_acc: 0.9212\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.7961 - acc: 0.9230 - val_loss: 1.0147 - val_acc: 0.8924\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.7760 - acc: 0.9215 - val_loss: 1.1250 - val_acc: 0.9505\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.7750 - acc: 0.9277 - val_loss: 1.0198 - val_acc: 0.9402\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.7686 - acc: 0.9276 - val_loss: 1.0601 - val_acc: 0.9549\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.7828 - acc: 0.9306 - val_loss: 1.1005 - val_acc: 0.9460\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.7610 - acc: 0.9257 - val_loss: 1.1325 - val_acc: 0.9080\n",
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.7516 - acc: 0.9242 - val_loss: 1.0181 - val_acc: 0.9493\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.7429 - acc: 0.9266 - val_loss: 1.1106 - val_acc: 0.9070\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.7419 - acc: 0.9327 - val_loss: 1.1508 - val_acc: 0.9287\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.7227 - acc: 0.9295 - val_loss: 1.1357 - val_acc: 0.9143\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.7516 - acc: 0.9262 - val_loss: 1.0322 - val_acc: 0.9185\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.7256 - acc: 0.9289 - val_loss: 1.0988 - val_acc: 0.9487\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.7095 - acc: 0.9193 - val_loss: 1.0681 - val_acc: 0.9434\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.7335 - acc: 0.9310 - val_loss: 1.0659 - val_acc: 0.9512\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.6826 - acc: 0.9353 - val_loss: 1.1669 - val_acc: 0.9200\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.7221 - acc: 0.9327 - val_loss: 1.1503 - val_acc: 0.9487\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.7362 - acc: 0.9372 - val_loss: 1.1110 - val_acc: 0.9357\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.7054 - acc: 0.9349 - val_loss: 1.0775 - val_acc: 0.9457\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6968 - acc: 0.9322 - val_loss: 1.1557 - val_acc: 0.9540\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6818 - acc: 0.9258 - val_loss: 1.1364 - val_acc: 0.9474\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6765 - acc: 0.9324 - val_loss: 1.1283 - val_acc: 0.9538\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.7259 - acc: 0.9265 - val_loss: 1.1150 - val_acc: 0.9079\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6811 - acc: 0.9150 - val_loss: 1.0587 - val_acc: 0.9311\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6797 - acc: 0.9288 - val_loss: 1.1580 - val_acc: 0.9555\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6754 - acc: 0.9300 - val_loss: 1.0436 - val_acc: 0.9437\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6525 - acc: 0.9275 - val_loss: 1.1771 - val_acc: 0.9524\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6423 - acc: 0.9353 - val_loss: 1.1384 - val_acc: 0.9408\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6621 - acc: 0.9318 - val_loss: 1.1193 - val_acc: 0.9392\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6519 - acc: 0.9290 - val_loss: 1.2106 - val_acc: 0.9515\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6559 - acc: 0.9331 - val_loss: 1.1257 - val_acc: 0.9465\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6509 - acc: 0.9327 - val_loss: 1.1525 - val_acc: 0.9593\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6230 - acc: 0.9310 - val_loss: 1.2170 - val_acc: 0.9529\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.6427 - acc: 0.9326 - val_loss: 1.0929 - val_acc: 0.9425\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6468 - acc: 0.9288 - val_loss: 1.1308 - val_acc: 0.9233\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6272 - acc: 0.9317 - val_loss: 1.2581 - val_acc: 0.9549\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6277 - acc: 0.9331 - val_loss: 1.0708 - val_acc: 0.9484\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6337 - acc: 0.9358 - val_loss: 1.0379 - val_acc: 0.9409\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6284 - acc: 0.9332 - val_loss: 1.0680 - val_acc: 0.9435\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6381 - acc: 0.9345 - val_loss: 1.2764 - val_acc: 0.9472\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6189 - acc: 0.9307 - val_loss: 1.1255 - val_acc: 0.9484\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5982 - acc: 0.9356 - val_loss: 1.2134 - val_acc: 0.9512\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5986 - acc: 0.9368 - val_loss: 1.1840 - val_acc: 0.9479\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6340 - acc: 0.9337 - val_loss: 1.1021 - val_acc: 0.9104\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6144 - acc: 0.9381 - val_loss: 1.0803 - val_acc: 0.9564\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6400 - acc: 0.9328 - val_loss: 1.1333 - val_acc: 0.9508\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6025 - acc: 0.9338 - val_loss: 1.2950 - val_acc: 0.9513\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6091 - acc: 0.9341 - val_loss: 1.1270 - val_acc: 0.9539\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6197 - acc: 0.9334 - val_loss: 1.2360 - val_acc: 0.9576\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_5 (Batch (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_5 (CuDNNLSTM)     (None, 32)                4736      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,847\n",
      "Trainable params: 4,841\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 2.4806 - acc: 0.5419 - val_loss: 2.4413 - val_acc: 0.3293\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 2.3271 - acc: 0.5019 - val_loss: 2.2091 - val_acc: 0.5672\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 2.2981 - acc: 0.5110 - val_loss: 2.2781 - val_acc: 0.3707\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 2.0961 - acc: 0.4837 - val_loss: 2.2446 - val_acc: 0.3689\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.9982 - acc: 0.4762 - val_loss: 2.0292 - val_acc: 0.4134\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.9472 - acc: 0.4884 - val_loss: 2.3475 - val_acc: 0.4521\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 21s 219us/step - loss: 2.0029 - acc: 0.5174 - val_loss: 1.9140 - val_acc: 0.5278\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.7448 - acc: 0.6027 - val_loss: 2.1681 - val_acc: 0.6814\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.8060 - acc: 0.6197 - val_loss: 1.8613 - val_acc: 0.6420\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.8719 - acc: 0.6770 - val_loss: 2.0461 - val_acc: 0.6638\n",
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.9123 - acc: 0.5368 - val_loss: 1.9597 - val_acc: 0.3601\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 2.0108 - acc: 0.5096 - val_loss: 2.1642 - val_acc: 0.4794\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.9057 - acc: 0.6046 - val_loss: 1.9091 - val_acc: 0.6007\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 21s 219us/step - loss: 1.7559 - acc: 0.6457 - val_loss: 2.1497 - val_acc: 0.6512\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.7837 - acc: 0.6768 - val_loss: 2.0542 - val_acc: 0.6611\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.7274 - acc: 0.6320 - val_loss: 2.0199 - val_acc: 0.7171\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 21s 219us/step - loss: 1.8513 - acc: 0.6714 - val_loss: 1.9753 - val_acc: 0.7875\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.6845 - acc: 0.7470 - val_loss: 1.8262 - val_acc: 0.7973\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.5471 - acc: 0.7529 - val_loss: 2.1862 - val_acc: 0.7448\n",
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.8618 - acc: 0.7105 - val_loss: 1.8588 - val_acc: 0.8011\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.5598 - acc: 0.7641 - val_loss: 1.6453 - val_acc: 0.8760\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.4188 - acc: 0.7885 - val_loss: 1.5854 - val_acc: 0.8228\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.4682 - acc: 0.8010 - val_loss: 1.7947 - val_acc: 0.8148\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.5833 - acc: 0.7903 - val_loss: 1.7892 - val_acc: 0.7910\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.4046 - acc: 0.8116 - val_loss: 1.7050 - val_acc: 0.8167\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.4004 - acc: 0.7651 - val_loss: 1.6016 - val_acc: 0.8153\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 21s 219us/step - loss: 1.4168 - acc: 0.8229 - val_loss: 1.6397 - val_acc: 0.8946\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.2810 - acc: 0.8346 - val_loss: 1.5331 - val_acc: 0.8715\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 21s 219us/step - loss: 1.2799 - acc: 0.8457 - val_loss: 1.5747 - val_acc: 0.7902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.4317 - acc: 0.8313 - val_loss: 1.6012 - val_acc: 0.8757\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.3195 - acc: 0.8462 - val_loss: 1.5990 - val_acc: 0.8717\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.3689 - acc: 0.8677 - val_loss: 1.7640 - val_acc: 0.8577\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.4894 - acc: 0.8555 - val_loss: 1.7909 - val_acc: 0.9062\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.4310 - acc: 0.8268 - val_loss: 1.5505 - val_acc: 0.8516\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.2739 - acc: 0.8164 - val_loss: 1.4916 - val_acc: 0.9058\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.1743 - acc: 0.8759 - val_loss: 1.3497 - val_acc: 0.9052\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.1112 - acc: 0.8914 - val_loss: 1.5773 - val_acc: 0.9250\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0813 - acc: 0.8979 - val_loss: 1.4549 - val_acc: 0.9291\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.3141 - acc: 0.8883 - val_loss: 1.5223 - val_acc: 0.8656\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.3297 - acc: 0.8628 - val_loss: 1.6331 - val_acc: 0.8913\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.3529 - acc: 0.8553 - val_loss: 1.7271 - val_acc: 0.8990\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.3562 - acc: 0.8346 - val_loss: 1.8190 - val_acc: 0.9179\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.3512 - acc: 0.8638 - val_loss: 1.5163 - val_acc: 0.8894\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.2650 - acc: 0.8542 - val_loss: 1.6031 - val_acc: 0.8922\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.2203 - acc: 0.8573 - val_loss: 1.5796 - val_acc: 0.8918\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.2677 - acc: 0.8532 - val_loss: 1.5553 - val_acc: 0.8793\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.2462 - acc: 0.8765 - val_loss: 1.7366 - val_acc: 0.9141\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.2204 - acc: 0.8796 - val_loss: 1.5602 - val_acc: 0.9226\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.1746 - acc: 0.9133 - val_loss: 1.4704 - val_acc: 0.9172\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.1417 - acc: 0.9119 - val_loss: 1.4956 - val_acc: 0.9281\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.1796 - acc: 0.9100 - val_loss: 1.6466 - val_acc: 0.9117\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.2680 - acc: 0.8513 - val_loss: 1.5281 - val_acc: 0.7690\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.1392 - acc: 0.8288 - val_loss: 1.3949 - val_acc: 0.7739\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.1744 - acc: 0.7925 - val_loss: 1.5270 - val_acc: 0.7669\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 21s 219us/step - loss: 1.0697 - acc: 0.8318 - val_loss: 1.4105 - val_acc: 0.7833\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0318 - acc: 0.8421 - val_loss: 1.3618 - val_acc: 0.8393\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.1485 - acc: 0.8524 - val_loss: 1.5691 - val_acc: 0.7779\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.2042 - acc: 0.8135 - val_loss: 1.4615 - val_acc: 0.8149\n",
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.1014 - acc: 0.8418 - val_loss: 1.4096 - val_acc: 0.8082\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.1022 - acc: 0.8367 - val_loss: 1.4137 - val_acc: 0.7947\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.1995 - acc: 0.8045 - val_loss: 1.4801 - val_acc: 0.8071\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.1568 - acc: 0.8257 - val_loss: 1.4235 - val_acc: 0.8077\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.1493 - acc: 0.8253 - val_loss: 1.2909 - val_acc: 0.8239\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0960 - acc: 0.8398 - val_loss: 1.3851 - val_acc: 0.8381\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0712 - acc: 0.8614 - val_loss: 1.3433 - val_acc: 0.8649\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0395 - acc: 0.8743 - val_loss: 1.3260 - val_acc: 0.8555\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0185 - acc: 0.8776 - val_loss: 1.2220 - val_acc: 0.8947\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9956 - acc: 0.8788 - val_loss: 1.2889 - val_acc: 0.8982\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9965 - acc: 0.8813 - val_loss: 1.2720 - val_acc: 0.8679\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9733 - acc: 0.8808 - val_loss: 1.2511 - val_acc: 0.9005\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.9494 - acc: 0.8973 - val_loss: 1.1933 - val_acc: 0.9080\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.9107 - acc: 0.9051 - val_loss: 1.2069 - val_acc: 0.9115\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.8958 - acc: 0.8933 - val_loss: 1.2365 - val_acc: 0.9239\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.8868 - acc: 0.9148 - val_loss: 1.1968 - val_acc: 0.9289\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.8698 - acc: 0.9100 - val_loss: 1.2582 - val_acc: 0.9447\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.8961 - acc: 0.9073 - val_loss: 1.2063 - val_acc: 0.9425\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.8613 - acc: 0.9094 - val_loss: 1.1690 - val_acc: 0.9274\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9035 - acc: 0.8986 - val_loss: 1.1111 - val_acc: 0.9141\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.8494 - acc: 0.9101 - val_loss: 1.0912 - val_acc: 0.9367\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8031 - acc: 0.9152 - val_loss: 1.0569 - val_acc: 0.8503\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.7988 - acc: 0.9211 - val_loss: 1.1526 - val_acc: 0.9259\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8416 - acc: 0.9054 - val_loss: 1.1001 - val_acc: 0.9386\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.7944 - acc: 0.9163 - val_loss: 1.0330 - val_acc: 0.9331\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.7768 - acc: 0.9114 - val_loss: 1.2687 - val_acc: 0.9237\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.8640 - acc: 0.9158 - val_loss: 1.0086 - val_acc: 0.9033\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.8391 - acc: 0.9113 - val_loss: 1.0165 - val_acc: 0.9078\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7779 - acc: 0.9189 - val_loss: 1.1445 - val_acc: 0.9187\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.8010 - acc: 0.9185 - val_loss: 1.1859 - val_acc: 0.9304\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7716 - acc: 0.9167 - val_loss: 1.0817 - val_acc: 0.9193\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.8240 - acc: 0.8947 - val_loss: 1.1149 - val_acc: 0.9163\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.7927 - acc: 0.9054 - val_loss: 1.1358 - val_acc: 0.9222\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.7870 - acc: 0.9096 - val_loss: 1.1064 - val_acc: 0.9256\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.7823 - acc: 0.9156 - val_loss: 1.0773 - val_acc: 0.9193\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 21s 219us/step - loss: 0.7701 - acc: 0.9182 - val_loss: 1.1114 - val_acc: 0.9237\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.7278 - acc: 0.9234 - val_loss: 1.1252 - val_acc: 0.9284\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.7382 - acc: 0.9243 - val_loss: 1.1521 - val_acc: 0.9273\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.7486 - acc: 0.9246 - val_loss: 1.1371 - val_acc: 0.9384\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.7210 - acc: 0.9311 - val_loss: 1.1366 - val_acc: 0.9174\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.7549 - acc: 0.9200 - val_loss: 1.1482 - val_acc: 0.8882\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7483 - acc: 0.9212 - val_loss: 1.0281 - val_acc: 0.9078\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_6 (Batch (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_6 (CuDNNLSTM)     (None, 32)                4736      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,847\n",
      "Trainable params: 4,841\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 21s 228us/step - loss: 2.5284 - acc: 0.5155 - val_loss: 2.4993 - val_acc: 0.6242\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 2.4018 - acc: 0.5007 - val_loss: 2.3875 - val_acc: 0.2858\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 2.3065 - acc: 0.5078 - val_loss: 2.3209 - val_acc: 0.2718\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 21s 219us/step - loss: 2.3065 - acc: 0.4742 - val_loss: 2.6118 - val_acc: 0.4783\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 2.2556 - acc: 0.4644 - val_loss: 2.3526 - val_acc: 0.4823\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 2.0497 - acc: 0.5984 - val_loss: 2.0493 - val_acc: 0.5838\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.9971 - acc: 0.5601 - val_loss: 2.0271 - val_acc: 0.5842\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.9324 - acc: 0.6623 - val_loss: 2.0315 - val_acc: 0.6981\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 2.0150 - acc: 0.6368 - val_loss: 2.3901 - val_acc: 0.2778\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 2.1825 - acc: 0.5580 - val_loss: 2.1364 - val_acc: 0.7810\n",
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 2.0187 - acc: 0.6641 - val_loss: 1.8719 - val_acc: 0.6884\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 21s 219us/step - loss: 1.8930 - acc: 0.7015 - val_loss: 1.8580 - val_acc: 0.6626\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.7644 - acc: 0.6802 - val_loss: 1.5394 - val_acc: 0.7344\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.7115 - acc: 0.6690 - val_loss: 1.5440 - val_acc: 0.6661\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.5594 - acc: 0.7139 - val_loss: 1.4765 - val_acc: 0.7026\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.4894 - acc: 0.7491 - val_loss: 1.4302 - val_acc: 0.7530\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.5052 - acc: 0.7328 - val_loss: 1.3743 - val_acc: 0.7995\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.4467 - acc: 0.7475 - val_loss: 1.5449 - val_acc: 0.7944\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.4862 - acc: 0.7420 - val_loss: 1.3894 - val_acc: 0.7689\n",
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.3422 - acc: 0.7746 - val_loss: 1.4113 - val_acc: 0.8093\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.3299 - acc: 0.7791 - val_loss: 1.3489 - val_acc: 0.8230\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.2694 - acc: 0.7947 - val_loss: 1.3637 - val_acc: 0.7810\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.3807 - acc: 0.7722 - val_loss: 1.4073 - val_acc: 0.8324\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.3339 - acc: 0.7668 - val_loss: 1.3724 - val_acc: 0.7430\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.2780 - acc: 0.8028 - val_loss: 1.2616 - val_acc: 0.8126\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.2164 - acc: 0.8007 - val_loss: 1.3904 - val_acc: 0.8532\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.2424 - acc: 0.8118 - val_loss: 1.3415 - val_acc: 0.8506\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.1913 - acc: 0.8144 - val_loss: 1.3535 - val_acc: 0.8038\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.3008 - acc: 0.7745 - val_loss: 1.4147 - val_acc: 0.8811\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.2530 - acc: 0.8235 - val_loss: 1.3934 - val_acc: 0.8966\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.1566 - acc: 0.8468 - val_loss: 1.2031 - val_acc: 0.8859\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.1066 - acc: 0.8493 - val_loss: 1.2294 - val_acc: 0.9103\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0921 - acc: 0.8594 - val_loss: 1.1770 - val_acc: 0.8883\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.1525 - acc: 0.8563 - val_loss: 1.3133 - val_acc: 0.9095\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0857 - acc: 0.8510 - val_loss: 1.4690 - val_acc: 0.8982\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.1003 - acc: 0.8437 - val_loss: 1.2259 - val_acc: 0.8950\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0919 - acc: 0.8320 - val_loss: 1.1880 - val_acc: 0.8144\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.1000 - acc: 0.8334 - val_loss: 1.2668 - val_acc: 0.8316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.1317 - acc: 0.8373 - val_loss: 1.3308 - val_acc: 0.9036\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.2036 - acc: 0.8335 - val_loss: 1.3209 - val_acc: 0.8304\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.1471 - acc: 0.8228 - val_loss: 1.2590 - val_acc: 0.8222\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.0749 - acc: 0.8347 - val_loss: 1.1633 - val_acc: 0.8567\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.1133 - acc: 0.8406 - val_loss: 1.2988 - val_acc: 0.8483\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0644 - acc: 0.8457 - val_loss: 1.1698 - val_acc: 0.8435\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.0843 - acc: 0.8433 - val_loss: 1.1356 - val_acc: 0.8948\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0279 - acc: 0.8622 - val_loss: 1.2099 - val_acc: 0.8659\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0520 - acc: 0.8326 - val_loss: 1.1274 - val_acc: 0.9029\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0590 - acc: 0.8244 - val_loss: 1.1738 - val_acc: 0.8964\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0712 - acc: 0.8123 - val_loss: 1.2170 - val_acc: 0.8609\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0686 - acc: 0.8362 - val_loss: 1.2010 - val_acc: 0.9136\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0859 - acc: 0.8139 - val_loss: 1.1985 - val_acc: 0.8880\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.1365 - acc: 0.8385 - val_loss: 1.4158 - val_acc: 0.8556\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.1066 - acc: 0.8419 - val_loss: 1.0635 - val_acc: 0.8914\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.0443 - acc: 0.8567 - val_loss: 1.0845 - val_acc: 0.8942\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0907 - acc: 0.8455 - val_loss: 1.1598 - val_acc: 0.8736\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0621 - acc: 0.8085 - val_loss: 1.1380 - val_acc: 0.8501\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0423 - acc: 0.8190 - val_loss: 1.1303 - val_acc: 0.8953\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.0117 - acc: 0.8609 - val_loss: 1.0889 - val_acc: 0.8996\n",
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0262 - acc: 0.8518 - val_loss: 1.3475 - val_acc: 0.8759\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.9807 - acc: 0.8522 - val_loss: 1.2517 - val_acc: 0.8800\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.9787 - acc: 0.8678 - val_loss: 1.2433 - val_acc: 0.8918\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.9828 - acc: 0.8704 - val_loss: 1.1450 - val_acc: 0.8955\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0544 - acc: 0.8439 - val_loss: 1.1441 - val_acc: 0.8514\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9929 - acc: 0.8242 - val_loss: 1.1796 - val_acc: 0.8876\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9908 - acc: 0.8523 - val_loss: 1.2371 - val_acc: 0.9040\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9656 - acc: 0.8539 - val_loss: 1.1271 - val_acc: 0.8924\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0100 - acc: 0.8397 - val_loss: 1.1303 - val_acc: 0.8885\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0311 - acc: 0.8509 - val_loss: 1.1472 - val_acc: 0.8813\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9596 - acc: 0.8542 - val_loss: 1.1929 - val_acc: 0.8887\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.9654 - acc: 0.8420 - val_loss: 1.0758 - val_acc: 0.9053\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9818 - acc: 0.8478 - val_loss: 1.1622 - val_acc: 0.8847\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.9435 - acc: 0.8673 - val_loss: 1.1092 - val_acc: 0.9181\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9995 - acc: 0.8611 - val_loss: 1.1396 - val_acc: 0.9353\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9333 - acc: 0.8621 - val_loss: 1.1066 - val_acc: 0.8914\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9295 - acc: 0.8774 - val_loss: 1.1585 - val_acc: 0.8783\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.8923 - acc: 0.8675 - val_loss: 1.1759 - val_acc: 0.9159\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9313 - acc: 0.8877 - val_loss: 1.1723 - val_acc: 0.9025\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9171 - acc: 0.8867 - val_loss: 1.1537 - val_acc: 0.9234\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9308 - acc: 0.8763 - val_loss: 1.2245 - val_acc: 0.9052\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9397 - acc: 0.8637 - val_loss: 1.1358 - val_acc: 0.9064\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9106 - acc: 0.8671 - val_loss: 1.2005 - val_acc: 0.9278\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9064 - acc: 0.8604 - val_loss: 1.2872 - val_acc: 0.8865\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9280 - acc: 0.8853 - val_loss: 1.1617 - val_acc: 0.9322\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.9067 - acc: 0.8915 - val_loss: 1.1576 - val_acc: 0.9291\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8857 - acc: 0.8900 - val_loss: 1.0769 - val_acc: 0.9531\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.8621 - acc: 0.9030 - val_loss: 1.0403 - val_acc: 0.9093\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9319 - acc: 0.8665 - val_loss: 1.2860 - val_acc: 0.8252\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9708 - acc: 0.8470 - val_loss: 1.1324 - val_acc: 0.8753\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9164 - acc: 0.8547 - val_loss: 1.1933 - val_acc: 0.9377\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8730 - acc: 0.8741 - val_loss: 1.0781 - val_acc: 0.9382\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8526 - acc: 0.8852 - val_loss: 1.1286 - val_acc: 0.9325\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.8358 - acc: 0.8962 - val_loss: 1.0621 - val_acc: 0.9569\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.8599 - acc: 0.8831 - val_loss: 1.0004 - val_acc: 0.9439\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.8333 - acc: 0.8889 - val_loss: 1.0612 - val_acc: 0.9345\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8113 - acc: 0.9030 - val_loss: 1.0855 - val_acc: 0.9199\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.8190 - acc: 0.9094 - val_loss: 1.1187 - val_acc: 0.9532\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8216 - acc: 0.9032 - val_loss: 1.3152 - val_acc: 0.9145\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.8618 - acc: 0.8823 - val_loss: 1.1517 - val_acc: 0.9020\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8266 - acc: 0.8920 - val_loss: 1.3223 - val_acc: 0.9388\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.8447 - acc: 0.8821 - val_loss: 1.2092 - val_acc: 0.9266\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_7 (Batch (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_7 (CuDNNLSTM)     (None, 32)                4736      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,847\n",
      "Trainable params: 4,841\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 21s 227us/step - loss: 2.4819 - acc: 0.5443 - val_loss: 2.5215 - val_acc: 0.6929\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 2.3370 - acc: 0.5727 - val_loss: 2.1711 - val_acc: 0.6188\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 2.0242 - acc: 0.6087 - val_loss: 2.0108 - val_acc: 0.6696\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 21s 219us/step - loss: 1.9687 - acc: 0.5792 - val_loss: 1.9237 - val_acc: 0.7048\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.8237 - acc: 0.6127 - val_loss: 1.9580 - val_acc: 0.7072\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.6201 - acc: 0.6667 - val_loss: 1.6881 - val_acc: 0.7081\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.4600 - acc: 0.7195 - val_loss: 1.7399 - val_acc: 0.7604\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.3465 - acc: 0.7098 - val_loss: 1.5921 - val_acc: 0.7060\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.3192 - acc: 0.7272 - val_loss: 1.5132 - val_acc: 0.7346\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.2665 - acc: 0.7405 - val_loss: 1.4364 - val_acc: 0.7769\n",
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.2467 - acc: 0.7540 - val_loss: 1.4888 - val_acc: 0.7685\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.3605 - acc: 0.7516 - val_loss: 1.5158 - val_acc: 0.7856\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.1931 - acc: 0.7623 - val_loss: 1.3825 - val_acc: 0.8279\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.1815 - acc: 0.7785 - val_loss: 1.4278 - val_acc: 0.7960\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.1883 - acc: 0.7950 - val_loss: 1.4152 - val_acc: 0.8232\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.1499 - acc: 0.8146 - val_loss: 1.4834 - val_acc: 0.7317\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.1326 - acc: 0.8086 - val_loss: 1.3187 - val_acc: 0.8209\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0959 - acc: 0.8326 - val_loss: 1.4305 - val_acc: 0.8254\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0853 - acc: 0.8332 - val_loss: 1.5260 - val_acc: 0.8835\n",
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 1.0469 - acc: 0.8619 - val_loss: 1.3490 - val_acc: 0.8517\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0077 - acc: 0.8724 - val_loss: 1.2739 - val_acc: 0.8995\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9926 - acc: 0.8483 - val_loss: 1.2579 - val_acc: 0.8696\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9835 - acc: 0.8670 - val_loss: 1.3635 - val_acc: 0.8691\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0099 - acc: 0.8800 - val_loss: 1.6816 - val_acc: 0.8435\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9643 - acc: 0.8410 - val_loss: 1.3875 - val_acc: 0.8388\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9366 - acc: 0.8465 - val_loss: 1.2669 - val_acc: 0.8327\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9467 - acc: 0.8702 - val_loss: 1.4353 - val_acc: 0.8840\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9486 - acc: 0.8788 - val_loss: 1.5538 - val_acc: 0.8395\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9322 - acc: 0.8825 - val_loss: 1.5559 - val_acc: 0.8440\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.9509 - acc: 0.8712 - val_loss: 1.4021 - val_acc: 0.9261\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8799 - acc: 0.8921 - val_loss: 1.4077 - val_acc: 0.8953\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9109 - acc: 0.8731 - val_loss: 1.5175 - val_acc: 0.9167\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8686 - acc: 0.8858 - val_loss: 1.3024 - val_acc: 0.9365\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.9594 - acc: 0.8768 - val_loss: 1.2735 - val_acc: 0.8869\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.8568 - acc: 0.9104 - val_loss: 1.4769 - val_acc: 0.9284\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8427 - acc: 0.9115 - val_loss: 1.4070 - val_acc: 0.9112\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.8469 - acc: 0.9073 - val_loss: 1.3661 - val_acc: 0.8978\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8948 - acc: 0.8890 - val_loss: 1.3198 - val_acc: 0.9268\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.8955 - acc: 0.8985 - val_loss: 1.2159 - val_acc: 0.9267\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8475 - acc: 0.8916 - val_loss: 1.2205 - val_acc: 0.9156\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.8349 - acc: 0.8983 - val_loss: 1.2007 - val_acc: 0.9014\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.8166 - acc: 0.9086 - val_loss: 1.1658 - val_acc: 0.9211\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7995 - acc: 0.9179 - val_loss: 1.2918 - val_acc: 0.9238\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.8020 - acc: 0.9099 - val_loss: 1.2497 - val_acc: 0.9319\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7769 - acc: 0.9207 - val_loss: 1.1962 - val_acc: 0.9250\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7615 - acc: 0.9149 - val_loss: 1.4032 - val_acc: 0.9149\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.7466 - acc: 0.9211 - val_loss: 1.2023 - val_acc: 0.9367\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.7434 - acc: 0.9178 - val_loss: 1.3437 - val_acc: 0.9377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.7417 - acc: 0.9110 - val_loss: 1.3988 - val_acc: 0.9013\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.7317 - acc: 0.9180 - val_loss: 1.3426 - val_acc: 0.9458\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.7270 - acc: 0.9256 - val_loss: 1.1782 - val_acc: 0.9433\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.7158 - acc: 0.9222 - val_loss: 1.2467 - val_acc: 0.8520\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.7162 - acc: 0.9151 - val_loss: 1.2946 - val_acc: 0.9336\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7043 - acc: 0.9278 - val_loss: 1.2573 - val_acc: 0.9375\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.6983 - acc: 0.9214 - val_loss: 1.3662 - val_acc: 0.9456\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6926 - acc: 0.9253 - val_loss: 1.1372 - val_acc: 0.9227\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.6880 - acc: 0.9227 - val_loss: 1.2254 - val_acc: 0.9296\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.6532 - acc: 0.9316 - val_loss: 1.2560 - val_acc: 0.9315\n",
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8098 - acc: 0.9152 - val_loss: 1.2600 - val_acc: 0.9214\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.6759 - acc: 0.9286 - val_loss: 1.3266 - val_acc: 0.9376\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6646 - acc: 0.9231 - val_loss: 1.2183 - val_acc: 0.9398\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.6779 - acc: 0.9269 - val_loss: 1.2642 - val_acc: 0.9371\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.6848 - acc: 0.9270 - val_loss: 1.2666 - val_acc: 0.9336\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6475 - acc: 0.9299 - val_loss: 1.2625 - val_acc: 0.9467\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.6672 - acc: 0.9253 - val_loss: 1.3463 - val_acc: 0.9340\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.6641 - acc: 0.9272 - val_loss: 1.1079 - val_acc: 0.9156\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.6817 - acc: 0.9140 - val_loss: 1.1369 - val_acc: 0.9171\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 21s 219us/step - loss: 0.6801 - acc: 0.9184 - val_loss: 1.1862 - val_acc: 0.9270\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6626 - acc: 0.9259 - val_loss: 1.4088 - val_acc: 0.9380\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6839 - acc: 0.9275 - val_loss: 1.2045 - val_acc: 0.9327\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6331 - acc: 0.9323 - val_loss: 1.3119 - val_acc: 0.9289\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6288 - acc: 0.9303 - val_loss: 1.0028 - val_acc: 0.9177\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.5964 - acc: 0.9336 - val_loss: 1.2347 - val_acc: 0.9088\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 21s 219us/step - loss: 0.6224 - acc: 0.9313 - val_loss: 1.2684 - val_acc: 0.9227\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.5962 - acc: 0.9345 - val_loss: 1.3842 - val_acc: 0.9240\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.6081 - acc: 0.9314 - val_loss: 1.2590 - val_acc: 0.9170\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.6011 - acc: 0.9296 - val_loss: 1.4948 - val_acc: 0.9347\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.6224 - acc: 0.9345 - val_loss: 1.2951 - val_acc: 0.9176\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.6192 - acc: 0.9319 - val_loss: 1.2488 - val_acc: 0.9265\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.6185 - acc: 0.9313 - val_loss: 1.4273 - val_acc: 0.9220\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6006 - acc: 0.9299 - val_loss: 1.1768 - val_acc: 0.9149\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.6165 - acc: 0.9302 - val_loss: 1.3154 - val_acc: 0.9416\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.5787 - acc: 0.9354 - val_loss: 1.1285 - val_acc: 0.9495\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.5822 - acc: 0.9327 - val_loss: 1.0641 - val_acc: 0.9255\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.5597 - acc: 0.9307 - val_loss: 1.1942 - val_acc: 0.9407\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.5744 - acc: 0.9321 - val_loss: 1.2064 - val_acc: 0.9235\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.5830 - acc: 0.9277 - val_loss: 1.4158 - val_acc: 0.9335\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.5724 - acc: 0.9335 - val_loss: 1.3403 - val_acc: 0.9199\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.5767 - acc: 0.9353 - val_loss: 1.3091 - val_acc: 0.9358\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.5766 - acc: 0.9355 - val_loss: 1.3607 - val_acc: 0.9454\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.5740 - acc: 0.9335 - val_loss: 1.2389 - val_acc: 0.9330\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.5533 - acc: 0.9365 - val_loss: 1.5868 - val_acc: 0.9423\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.5734 - acc: 0.9379 - val_loss: 1.3369 - val_acc: 0.9368\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.5590 - acc: 0.9376 - val_loss: 1.2101 - val_acc: 0.9255\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5558 - acc: 0.9309 - val_loss: 1.1961 - val_acc: 0.9231\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.5568 - acc: 0.9366 - val_loss: 1.0794 - val_acc: 0.9169\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.5484 - acc: 0.9352 - val_loss: 1.2272 - val_acc: 0.9364\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.5754 - acc: 0.9382 - val_loss: 1.2185 - val_acc: 0.9334\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.5464 - acc: 0.9377 - val_loss: 1.3200 - val_acc: 0.9352\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.5821 - acc: 0.9279 - val_loss: 1.3450 - val_acc: 0.9399\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_8 (Batch (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_8 (CuDNNLSTM)     (None, 32)                4736      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,847\n",
      "Trainable params: 4,841\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 22s 231us/step - loss: 2.5293 - acc: 0.4960 - val_loss: 2.5076 - val_acc: 0.6212\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 2.3977 - acc: 0.5077 - val_loss: 2.4027 - val_acc: 0.4623\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 2.2917 - acc: 0.5503 - val_loss: 2.2455 - val_acc: 0.6088\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 2.3173 - acc: 0.4588 - val_loss: 2.3922 - val_acc: 0.5590\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 2.2835 - acc: 0.5345 - val_loss: 2.3902 - val_acc: 0.6078\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 2.2161 - acc: 0.5560 - val_loss: 2.1701 - val_acc: 0.4536\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 2.3023 - acc: 0.4843 - val_loss: 2.4759 - val_acc: 0.1400\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 2.4132 - acc: 0.4444 - val_loss: 2.5545 - val_acc: 0.3767\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 2.4569 - acc: 0.5318 - val_loss: 2.5125 - val_acc: 0.3707\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 2.3240 - acc: 0.5317 - val_loss: 2.2578 - val_acc: 0.5222\n",
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 2.1669 - acc: 0.6013 - val_loss: 2.1958 - val_acc: 0.6508\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 2.1861 - acc: 0.5633 - val_loss: 2.4781 - val_acc: 0.8030\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 2.4111 - acc: 0.5858 - val_loss: 2.4454 - val_acc: 0.5841\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 2.3536 - acc: 0.5348 - val_loss: 2.4047 - val_acc: 0.7150\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 2.3058 - acc: 0.5604 - val_loss: 2.3073 - val_acc: 0.5644\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 2.2363 - acc: 0.5511 - val_loss: 2.3272 - val_acc: 0.7020\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 2.1810 - acc: 0.6133 - val_loss: 2.2767 - val_acc: 0.6314\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 2.1065 - acc: 0.6616 - val_loss: 2.0188 - val_acc: 0.7118\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 2.1183 - acc: 0.6438 - val_loss: 2.2352 - val_acc: 0.7234\n",
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 2.0172 - acc: 0.6217 - val_loss: 2.3112 - val_acc: 0.5702\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 2.0009 - acc: 0.6382 - val_loss: 2.0952 - val_acc: 0.6473\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.8671 - acc: 0.6679 - val_loss: 2.0308 - val_acc: 0.6646\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 1.9086 - acc: 0.5955 - val_loss: 2.0952 - val_acc: 0.6154\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.7681 - acc: 0.6661 - val_loss: 1.9711 - val_acc: 0.6860\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.9183 - acc: 0.6407 - val_loss: 2.0319 - val_acc: 0.7446\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.7908 - acc: 0.6781 - val_loss: 1.9208 - val_acc: 0.7669\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.7339 - acc: 0.6720 - val_loss: 1.7652 - val_acc: 0.7523\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 1.6690 - acc: 0.6804 - val_loss: 1.7768 - val_acc: 0.7686\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 1.5716 - acc: 0.6878 - val_loss: 1.8118 - val_acc: 0.7953\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.4730 - acc: 0.7516 - val_loss: 1.5186 - val_acc: 0.8589\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.4100 - acc: 0.7706 - val_loss: 1.5120 - val_acc: 0.8496\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.3599 - acc: 0.7710 - val_loss: 1.5813 - val_acc: 0.8302\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.3702 - acc: 0.7891 - val_loss: 1.6581 - val_acc: 0.8868\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.3904 - acc: 0.7636 - val_loss: 1.6734 - val_acc: 0.8308\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.4288 - acc: 0.7601 - val_loss: 2.3282 - val_acc: 0.6922\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.4626 - acc: 0.7165 - val_loss: 1.7084 - val_acc: 0.7237\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 1.5808 - acc: 0.7180 - val_loss: 1.8057 - val_acc: 0.7837\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.3484 - acc: 0.7680 - val_loss: 1.6384 - val_acc: 0.8135\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 20s 213us/step - loss: 1.2630 - acc: 0.7934 - val_loss: 1.6931 - val_acc: 0.8281\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.3153 - acc: 0.7658 - val_loss: 1.7101 - val_acc: 0.6512\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 1.2878 - acc: 0.7927 - val_loss: 1.3227 - val_acc: 0.8265\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.2934 - acc: 0.7713 - val_loss: 1.4292 - val_acc: 0.7813\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.2700 - acc: 0.7508 - val_loss: 1.3122 - val_acc: 0.8658\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.2006 - acc: 0.8132 - val_loss: 1.3976 - val_acc: 0.8997\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.2075 - acc: 0.8054 - val_loss: 1.3491 - val_acc: 0.8353\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.3388 - acc: 0.7924 - val_loss: 1.5393 - val_acc: 0.9177\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.3442 - acc: 0.7898 - val_loss: 1.3857 - val_acc: 0.9356\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.1367 - acc: 0.8449 - val_loss: 1.4075 - val_acc: 0.8834\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.2489 - acc: 0.8270 - val_loss: 1.4446 - val_acc: 0.9476\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.1701 - acc: 0.8422 - val_loss: 1.4437 - val_acc: 0.8961\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.1525 - acc: 0.8602 - val_loss: 1.4811 - val_acc: 0.8978\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.1872 - acc: 0.8407 - val_loss: 1.2956 - val_acc: 0.8967\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.1483 - acc: 0.8745 - val_loss: 1.3507 - val_acc: 0.9650\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.1458 - acc: 0.8651 - val_loss: 1.3553 - val_acc: 0.9242\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0703 - acc: 0.8852 - val_loss: 1.1649 - val_acc: 0.9378\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 1.0754 - acc: 0.8776 - val_loss: 1.3601 - val_acc: 0.9348\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.0401 - acc: 0.8825 - val_loss: 1.2916 - val_acc: 0.9375\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0263 - acc: 0.8911 - val_loss: 1.4831 - val_acc: 0.7899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.0750 - acc: 0.8607 - val_loss: 1.2998 - val_acc: 0.9162\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 1.0222 - acc: 0.8992 - val_loss: 1.4477 - val_acc: 0.9508\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 1.0272 - acc: 0.9015 - val_loss: 1.1427 - val_acc: 0.9320\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.9467 - acc: 0.8926 - val_loss: 1.1296 - val_acc: 0.9376\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9948 - acc: 0.8933 - val_loss: 1.1454 - val_acc: 0.9303\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.9622 - acc: 0.9012 - val_loss: 1.2882 - val_acc: 0.9565\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.9357 - acc: 0.9061 - val_loss: 1.2404 - val_acc: 0.9648\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9340 - acc: 0.9022 - val_loss: 1.4012 - val_acc: 0.8283\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.9620 - acc: 0.8823 - val_loss: 1.1973 - val_acc: 0.9309\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.8871 - acc: 0.9114 - val_loss: 1.1380 - val_acc: 0.9593\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8906 - acc: 0.9241 - val_loss: 1.1613 - val_acc: 0.9684\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.8595 - acc: 0.9183 - val_loss: 1.1732 - val_acc: 0.9595\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.8508 - acc: 0.9173 - val_loss: 1.1489 - val_acc: 0.9657\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8367 - acc: 0.9134 - val_loss: 1.1048 - val_acc: 0.9049\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8256 - acc: 0.9082 - val_loss: 1.1269 - val_acc: 0.9507\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.8102 - acc: 0.9128 - val_loss: 1.1801 - val_acc: 0.9648\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.9087 - acc: 0.8908 - val_loss: 1.2562 - val_acc: 0.9279\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.8491 - acc: 0.9115 - val_loss: 1.1222 - val_acc: 0.9524\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8350 - acc: 0.9106 - val_loss: 1.1951 - val_acc: 0.9575\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8183 - acc: 0.9272 - val_loss: 1.1704 - val_acc: 0.9651\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7892 - acc: 0.9231 - val_loss: 1.1042 - val_acc: 0.9619\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7512 - acc: 0.9237 - val_loss: 1.0906 - val_acc: 0.9630\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7973 - acc: 0.9258 - val_loss: 1.1485 - val_acc: 0.9321\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7945 - acc: 0.9231 - val_loss: 0.9972 - val_acc: 0.9307\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7580 - acc: 0.9169 - val_loss: 1.2035 - val_acc: 0.9619\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7460 - acc: 0.9290 - val_loss: 0.9995 - val_acc: 0.9612\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.8153 - acc: 0.9170 - val_loss: 1.2332 - val_acc: 0.9505\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7539 - acc: 0.9268 - val_loss: 1.0847 - val_acc: 0.9548\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7680 - acc: 0.9236 - val_loss: 1.2519 - val_acc: 0.9596\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7204 - acc: 0.9301 - val_loss: 1.2233 - val_acc: 0.9422\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7150 - acc: 0.9314 - val_loss: 1.2141 - val_acc: 0.9641\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7546 - acc: 0.9226 - val_loss: 1.1464 - val_acc: 0.9199\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7166 - acc: 0.9308 - val_loss: 1.1417 - val_acc: 0.9599\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7273 - acc: 0.9342 - val_loss: 1.1908 - val_acc: 0.9655\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7303 - acc: 0.9229 - val_loss: 1.2161 - val_acc: 0.9606\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7126 - acc: 0.9260 - val_loss: 1.1420 - val_acc: 0.9400\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7065 - acc: 0.9245 - val_loss: 1.0818 - val_acc: 0.9529\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7065 - acc: 0.9301 - val_loss: 1.0925 - val_acc: 0.9619\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6822 - acc: 0.9272 - val_loss: 1.0411 - val_acc: 0.9457\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6930 - acc: 0.9286 - val_loss: 1.3509 - val_acc: 0.9667\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7057 - acc: 0.9246 - val_loss: 1.0680 - val_acc: 0.9627\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7329 - acc: 0.9250 - val_loss: 1.0544 - val_acc: 0.9572\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_9 (Batch (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 41s 436us/step - loss: 2.5369 - acc: 0.5110 - val_loss: 2.4649 - val_acc: 0.4844\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 2.2489 - acc: 0.6036 - val_loss: 2.0552 - val_acc: 0.6161\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 1.9734 - acc: 0.6193 - val_loss: 1.8681 - val_acc: 0.6212\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 1.5702 - acc: 0.7002 - val_loss: 1.4682 - val_acc: 0.8195\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 1.2921 - acc: 0.7712 - val_loss: 1.4995 - val_acc: 0.8751\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 1.2039 - acc: 0.7978 - val_loss: 1.1682 - val_acc: 0.8166\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 1.1308 - acc: 0.8196 - val_loss: 1.1920 - val_acc: 0.9309\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 1.0422 - acc: 0.8522 - val_loss: 1.1596 - val_acc: 0.9075\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 1.0061 - acc: 0.8734 - val_loss: 1.1983 - val_acc: 0.9003\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.9318 - acc: 0.8910 - val_loss: 1.0381 - val_acc: 0.9260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.8834 - acc: 0.8973 - val_loss: 1.2515 - val_acc: 0.9394\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.8523 - acc: 0.9033 - val_loss: 0.9576 - val_acc: 0.9086\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.8248 - acc: 0.9155 - val_loss: 0.9824 - val_acc: 0.9195\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.8049 - acc: 0.9124 - val_loss: 1.0086 - val_acc: 0.9520\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.7800 - acc: 0.9193 - val_loss: 1.2446 - val_acc: 0.9507\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.7852 - acc: 0.9185 - val_loss: 1.2818 - val_acc: 0.9662\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.7611 - acc: 0.9183 - val_loss: 1.0276 - val_acc: 0.9414\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.7263 - acc: 0.9252 - val_loss: 1.0329 - val_acc: 0.9495\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.7279 - acc: 0.9234 - val_loss: 0.9506 - val_acc: 0.9474\n",
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.7041 - acc: 0.9238 - val_loss: 0.9775 - val_acc: 0.9514\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.7040 - acc: 0.9218 - val_loss: 1.0748 - val_acc: 0.8775\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6963 - acc: 0.9199 - val_loss: 0.8515 - val_acc: 0.9286\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.7002 - acc: 0.9223 - val_loss: 0.9091 - val_acc: 0.9507\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.6935 - acc: 0.9277 - val_loss: 0.8813 - val_acc: 0.9474\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6688 - acc: 0.9195 - val_loss: 0.9043 - val_acc: 0.9474\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6521 - acc: 0.9259 - val_loss: 0.9867 - val_acc: 0.9506\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6540 - acc: 0.9222 - val_loss: 0.8826 - val_acc: 0.9431\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6357 - acc: 0.9275 - val_loss: 1.0997 - val_acc: 0.9545\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6492 - acc: 0.9284 - val_loss: 1.0716 - val_acc: 0.9582\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6252 - acc: 0.9266 - val_loss: 0.9927 - val_acc: 0.9424\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6389 - acc: 0.9245 - val_loss: 0.9151 - val_acc: 0.9439\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6252 - acc: 0.9287 - val_loss: 0.9088 - val_acc: 0.9251\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6189 - acc: 0.9260 - val_loss: 0.9367 - val_acc: 0.9452\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5961 - acc: 0.9279 - val_loss: 1.0235 - val_acc: 0.9498\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6189 - acc: 0.9310 - val_loss: 0.9272 - val_acc: 0.9470\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5956 - acc: 0.9279 - val_loss: 1.0146 - val_acc: 0.9012\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6200 - acc: 0.9305 - val_loss: 0.9165 - val_acc: 0.9359\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6150 - acc: 0.9266 - val_loss: 0.9219 - val_acc: 0.9481\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6040 - acc: 0.9281 - val_loss: 0.8491 - val_acc: 0.9415\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5747 - acc: 0.9316 - val_loss: 0.9590 - val_acc: 0.9408\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5754 - acc: 0.9296 - val_loss: 0.8590 - val_acc: 0.9383\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5530 - acc: 0.9309 - val_loss: 1.0362 - val_acc: 0.9328\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5527 - acc: 0.9301 - val_loss: 0.8394 - val_acc: 0.9249\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5483 - acc: 0.9336 - val_loss: 0.9205 - val_acc: 0.9293\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5627 - acc: 0.9276 - val_loss: 0.9104 - val_acc: 0.9302\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5421 - acc: 0.9290 - val_loss: 1.0178 - val_acc: 0.9468\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5553 - acc: 0.9310 - val_loss: 1.1538 - val_acc: 0.9540\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5583 - acc: 0.9287 - val_loss: 1.0222 - val_acc: 0.9473\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5283 - acc: 0.9328 - val_loss: 0.9086 - val_acc: 0.9167\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5578 - acc: 0.9299 - val_loss: 0.8674 - val_acc: 0.9377\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5409 - acc: 0.9351 - val_loss: 0.9263 - val_acc: 0.9389\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5423 - acc: 0.9356 - val_loss: 1.1576 - val_acc: 0.9434\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5328 - acc: 0.9338 - val_loss: 0.9880 - val_acc: 0.9415\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5406 - acc: 0.9299 - val_loss: 0.8722 - val_acc: 0.9247\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5374 - acc: 0.9278 - val_loss: 0.9538 - val_acc: 0.9509\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5215 - acc: 0.9338 - val_loss: 0.8856 - val_acc: 0.9449\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5186 - acc: 0.9349 - val_loss: 0.9956 - val_acc: 0.9408\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5391 - acc: 0.9336 - val_loss: 0.8849 - val_acc: 0.9330\n",
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5293 - acc: 0.9289 - val_loss: 1.0462 - val_acc: 0.9449\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5023 - acc: 0.9322 - val_loss: 0.9583 - val_acc: 0.9480\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5202 - acc: 0.9303 - val_loss: 1.0032 - val_acc: 0.9435\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5039 - acc: 0.9347 - val_loss: 1.0740 - val_acc: 0.9383\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5309 - acc: 0.9337 - val_loss: 0.9188 - val_acc: 0.9410\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5500 - acc: 0.9322 - val_loss: 1.0299 - val_acc: 0.9528\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5043 - acc: 0.9336 - val_loss: 1.1144 - val_acc: 0.9448\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5346 - acc: 0.9337 - val_loss: 0.9704 - val_acc: 0.9477\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5024 - acc: 0.9344 - val_loss: 0.8791 - val_acc: 0.9370\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5127 - acc: 0.9335 - val_loss: 1.0074 - val_acc: 0.9499\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5144 - acc: 0.9327 - val_loss: 0.9510 - val_acc: 0.9429\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5047 - acc: 0.9362 - val_loss: 0.8671 - val_acc: 0.9384\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.4928 - acc: 0.9353 - val_loss: 0.8985 - val_acc: 0.9428\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.5158 - acc: 0.9345 - val_loss: 0.9513 - val_acc: 0.9333\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.4913 - acc: 0.9348 - val_loss: 1.1435 - val_acc: 0.9450\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.4878 - acc: 0.9355 - val_loss: 1.0330 - val_acc: 0.9422\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.4873 - acc: 0.9345 - val_loss: 0.8825 - val_acc: 0.9329\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.5027 - acc: 0.9324 - val_loss: 1.0286 - val_acc: 0.9374\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.4750 - acc: 0.9373 - val_loss: 1.0199 - val_acc: 0.9389\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.4682 - acc: 0.9376 - val_loss: 1.0050 - val_acc: 0.9340\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.4872 - acc: 0.9345 - val_loss: 1.0234 - val_acc: 0.9487\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.4963 - acc: 0.9363 - val_loss: 1.1069 - val_acc: 0.9412\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.4665 - acc: 0.9382 - val_loss: 0.9815 - val_acc: 0.9461\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.4768 - acc: 0.9356 - val_loss: 1.0481 - val_acc: 0.9511\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.4865 - acc: 0.9367 - val_loss: 0.9703 - val_acc: 0.9431\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.4715 - acc: 0.9371 - val_loss: 1.0650 - val_acc: 0.9420\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.4700 - acc: 0.9376 - val_loss: 0.9705 - val_acc: 0.9469\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5022 - acc: 0.9371 - val_loss: 0.9350 - val_acc: 0.9280\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.4984 - acc: 0.9332 - val_loss: 1.0160 - val_acc: 0.9354\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.4935 - acc: 0.9331 - val_loss: 1.0676 - val_acc: 0.9430\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.4768 - acc: 0.9339 - val_loss: 0.9675 - val_acc: 0.9367\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.4890 - acc: 0.9332 - val_loss: 0.8694 - val_acc: 0.9357\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.4733 - acc: 0.9349 - val_loss: 1.0354 - val_acc: 0.9510\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.4664 - acc: 0.9358 - val_loss: 0.9613 - val_acc: 0.9430\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.4509 - acc: 0.9393 - val_loss: 0.9692 - val_acc: 0.9409\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.4724 - acc: 0.9373 - val_loss: 0.9424 - val_acc: 0.9416\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.4732 - acc: 0.9392 - val_loss: 0.9870 - val_acc: 0.9463\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.4782 - acc: 0.9340 - val_loss: 0.9997 - val_acc: 0.9444\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.4517 - acc: 0.9378 - val_loss: 0.9697 - val_acc: 0.9458\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.4641 - acc: 0.9386 - val_loss: 1.0512 - val_acc: 0.9460\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.4691 - acc: 0.9381 - val_loss: 0.7457 - val_acc: 0.9377\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.4433 - acc: 0.9383 - val_loss: 0.9473 - val_acc: 0.9440\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_10 (Batc (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 41s 439us/step - loss: 2.5765 - acc: 0.5296 - val_loss: 2.5659 - val_acc: 0.7685\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 2.4484 - acc: 0.5150 - val_loss: 2.4000 - val_acc: 0.4764\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 2.0788 - acc: 0.6242 - val_loss: 2.0559 - val_acc: 0.6074\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 1.7141 - acc: 0.6950 - val_loss: 1.7891 - val_acc: 0.7606\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 1.5207 - acc: 0.7213 - val_loss: 1.6717 - val_acc: 0.8107\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 1.3947 - acc: 0.7487 - val_loss: 1.5690 - val_acc: 0.8390\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 1.2767 - acc: 0.7769 - val_loss: 1.2824 - val_acc: 0.8137\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 1.1950 - acc: 0.8086 - val_loss: 1.2283 - val_acc: 0.7920\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 1.1223 - acc: 0.8385 - val_loss: 1.2515 - val_acc: 0.8923\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 1.0712 - acc: 0.8584 - val_loss: 1.1314 - val_acc: 0.8524\n",
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.9918 - acc: 0.8706 - val_loss: 1.1510 - val_acc: 0.9159\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.9481 - acc: 0.8833 - val_loss: 1.1019 - val_acc: 0.9224\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.9383 - acc: 0.8841 - val_loss: 1.1745 - val_acc: 0.9375\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.9005 - acc: 0.9035 - val_loss: 0.9869 - val_acc: 0.8822\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.8541 - acc: 0.9027 - val_loss: 1.2553 - val_acc: 0.9468\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.8304 - acc: 0.9055 - val_loss: 0.9271 - val_acc: 0.9189\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.8154 - acc: 0.9097 - val_loss: 1.0092 - val_acc: 0.9179\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.8187 - acc: 0.9089 - val_loss: 1.3137 - val_acc: 0.9441\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.7983 - acc: 0.9102 - val_loss: 1.0609 - val_acc: 0.9186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.7548 - acc: 0.9162 - val_loss: 1.1149 - val_acc: 0.9260\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.7568 - acc: 0.9168 - val_loss: 0.9354 - val_acc: 0.9227\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.7508 - acc: 0.9119 - val_loss: 1.0576 - val_acc: 0.8882\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.7553 - acc: 0.9128 - val_loss: 0.9079 - val_acc: 0.9215\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.7704 - acc: 0.9127 - val_loss: 0.9652 - val_acc: 0.9344\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 40s 431us/step - loss: 0.7262 - acc: 0.9205 - val_loss: 1.0766 - val_acc: 0.9350\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.7064 - acc: 0.9215 - val_loss: 0.8639 - val_acc: 0.9465\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.7127 - acc: 0.9203 - val_loss: 0.9367 - val_acc: 0.9287\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.6995 - acc: 0.9219 - val_loss: 0.9138 - val_acc: 0.9192\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6927 - acc: 0.9233 - val_loss: 1.0689 - val_acc: 0.9523\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.6856 - acc: 0.9231 - val_loss: 0.8357 - val_acc: 0.9457\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.6518 - acc: 0.9282 - val_loss: 0.7630 - val_acc: 0.9201\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.6617 - acc: 0.9267 - val_loss: 0.7871 - val_acc: 0.9399\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6471 - acc: 0.9312 - val_loss: 0.8016 - val_acc: 0.9406\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.6432 - acc: 0.9241 - val_loss: 0.7963 - val_acc: 0.9331\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6339 - acc: 0.9298 - val_loss: 0.8768 - val_acc: 0.9390\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.6350 - acc: 0.9277 - val_loss: 0.8129 - val_acc: 0.9442\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.6480 - acc: 0.9281 - val_loss: 0.8227 - val_acc: 0.9289\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6246 - acc: 0.9304 - val_loss: 0.8771 - val_acc: 0.9515\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.6149 - acc: 0.9308 - val_loss: 0.8561 - val_acc: 0.9465\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.6187 - acc: 0.9289 - val_loss: 0.8371 - val_acc: 0.9387\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6091 - acc: 0.9312 - val_loss: 1.0337 - val_acc: 0.9522\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6284 - acc: 0.9295 - val_loss: 0.8180 - val_acc: 0.9571\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.6144 - acc: 0.9352 - val_loss: 0.8788 - val_acc: 0.9252\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 40s 431us/step - loss: 0.5935 - acc: 0.9305 - val_loss: 0.7989 - val_acc: 0.9232\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.6039 - acc: 0.9277 - val_loss: 0.8030 - val_acc: 0.9116\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.6391 - acc: 0.9265 - val_loss: 1.0391 - val_acc: 0.8802\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.6093 - acc: 0.9306 - val_loss: 0.8365 - val_acc: 0.9478\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6121 - acc: 0.9293 - val_loss: 0.8946 - val_acc: 0.9521\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 0.6192 - acc: 0.9294 - val_loss: 0.7656 - val_acc: 0.9250\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6069 - acc: 0.9291 - val_loss: 0.7496 - val_acc: 0.9421\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.5895 - acc: 0.9358 - val_loss: 0.8472 - val_acc: 0.9318\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5796 - acc: 0.9297 - val_loss: 1.0246 - val_acc: 0.9549\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.5793 - acc: 0.9337 - val_loss: 0.8279 - val_acc: 0.9430\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 40s 431us/step - loss: 0.5681 - acc: 0.9296 - val_loss: 0.8729 - val_acc: 0.9520\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.6054 - acc: 0.9318 - val_loss: 0.7327 - val_acc: 0.9394\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5755 - acc: 0.9230 - val_loss: 0.7757 - val_acc: 0.9314\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5622 - acc: 0.9334 - val_loss: 0.9132 - val_acc: 0.9440\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5827 - acc: 0.9288 - val_loss: 0.8117 - val_acc: 0.9515\n",
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5796 - acc: 0.9337 - val_loss: 0.7635 - val_acc: 0.9482\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5717 - acc: 0.9300 - val_loss: 0.8381 - val_acc: 0.9460\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5709 - acc: 0.9318 - val_loss: 0.9296 - val_acc: 0.9222\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5824 - acc: 0.9335 - val_loss: 0.7657 - val_acc: 0.9267\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5695 - acc: 0.9315 - val_loss: 0.8127 - val_acc: 0.9434\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5605 - acc: 0.9340 - val_loss: 0.9446 - val_acc: 0.8993\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5648 - acc: 0.9356 - val_loss: 0.8364 - val_acc: 0.9426\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 40s 431us/step - loss: 0.5463 - acc: 0.9338 - val_loss: 0.8022 - val_acc: 0.9431\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5428 - acc: 0.9334 - val_loss: 0.8806 - val_acc: 0.9476\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5306 - acc: 0.9340 - val_loss: 0.8840 - val_acc: 0.9366\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5328 - acc: 0.9361 - val_loss: 1.0114 - val_acc: 0.9458\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5495 - acc: 0.9365 - val_loss: 0.8860 - val_acc: 0.9532\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 38s 408us/step - loss: 0.5365 - acc: 0.9305 - val_loss: 0.7885 - val_acc: 0.9488\n",
      "Epoch 72/100\n",
      "  544/94042 [..............................] - ETA: 3:47 - loss: 0.4769 - acc: 0.9430"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/curroatc/miniconda3/envs/deeplearning/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.402981). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/home/curroatc/miniconda3/envs/deeplearning/lib/python3.6/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.201795). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94042/94042 [==============================] - 39s 419us/step - loss: 0.5480 - acc: 0.9347 - val_loss: 0.8831 - val_acc: 0.9524\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 39s 416us/step - loss: 0.5353 - acc: 0.9335 - val_loss: 0.8253 - val_acc: 0.9452\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5310 - acc: 0.9308 - val_loss: 0.6883 - val_acc: 0.9301\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5440 - acc: 0.9295 - val_loss: 0.8304 - val_acc: 0.9469\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5084 - acc: 0.9385 - val_loss: 0.9324 - val_acc: 0.9484\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5311 - acc: 0.9361 - val_loss: 0.8531 - val_acc: 0.9435\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5078 - acc: 0.9371 - val_loss: 0.8759 - val_acc: 0.9450\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5293 - acc: 0.9374 - val_loss: 0.8821 - val_acc: 0.9454\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 40s 431us/step - loss: 0.4951 - acc: 0.9390 - val_loss: 0.8725 - val_acc: 0.9437\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5117 - acc: 0.9366 - val_loss: 0.9058 - val_acc: 0.9329\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5244 - acc: 0.9370 - val_loss: 0.8894 - val_acc: 0.9365\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5131 - acc: 0.9360 - val_loss: 0.8949 - val_acc: 0.9508\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5190 - acc: 0.9397 - val_loss: 0.9324 - val_acc: 0.9461\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5085 - acc: 0.9374 - val_loss: 0.9596 - val_acc: 0.9445\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5238 - acc: 0.9360 - val_loss: 0.8035 - val_acc: 0.9335\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5307 - acc: 0.9355 - val_loss: 0.8378 - val_acc: 0.9328\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5245 - acc: 0.9349 - val_loss: 0.8324 - val_acc: 0.9229\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5017 - acc: 0.9351 - val_loss: 0.8608 - val_acc: 0.9489\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5176 - acc: 0.9354 - val_loss: 0.7850 - val_acc: 0.9320\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5135 - acc: 0.9358 - val_loss: 0.7622 - val_acc: 0.9465\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5162 - acc: 0.9348 - val_loss: 0.7518 - val_acc: 0.9478\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.4983 - acc: 0.9378 - val_loss: 0.7995 - val_acc: 0.9481\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.5127 - acc: 0.9345 - val_loss: 0.8320 - val_acc: 0.9515\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.4912 - acc: 0.9386 - val_loss: 0.8898 - val_acc: 0.9503\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5196 - acc: 0.9320 - val_loss: 0.8467 - val_acc: 0.9278\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.4983 - acc: 0.9388 - val_loss: 1.0711 - val_acc: 0.9514\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5252 - acc: 0.9310 - val_loss: 0.7565 - val_acc: 0.9397\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.4757 - acc: 0.9399 - val_loss: 0.8703 - val_acc: 0.9399\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.4773 - acc: 0.9367 - val_loss: 0.9436 - val_acc: 0.9423\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_11 (Batc (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_3 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 41s 439us/step - loss: 2.5425 - acc: 0.5414 - val_loss: 2.4298 - val_acc: 0.1635\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 2.2350 - acc: 0.5923 - val_loss: 2.2674 - val_acc: 0.6773\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 1.8797 - acc: 0.6233 - val_loss: 1.9560 - val_acc: 0.7713\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 1.4717 - acc: 0.7213 - val_loss: 2.2198 - val_acc: 0.8900\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 1.3095 - acc: 0.7523 - val_loss: 1.8413 - val_acc: 0.8710\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 1.3419 - acc: 0.7750 - val_loss: 1.7051 - val_acc: 0.8902\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 1.2707 - acc: 0.7886 - val_loss: 1.6179 - val_acc: 0.9263\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 1.1937 - acc: 0.8038 - val_loss: 1.7425 - val_acc: 0.8995\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 1.1722 - acc: 0.8110 - val_loss: 1.5715 - val_acc: 0.9254\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 1.0720 - acc: 0.8452 - val_loss: 1.5448 - val_acc: 0.9563\n",
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 1.0945 - acc: 0.8479 - val_loss: 2.0758 - val_acc: 0.9022\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 1.0215 - acc: 0.8648 - val_loss: 1.5683 - val_acc: 0.9427\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.9723 - acc: 0.8774 - val_loss: 1.5590 - val_acc: 0.9291\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.9043 - acc: 0.8942 - val_loss: 1.4050 - val_acc: 0.9526\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.8712 - acc: 0.9033 - val_loss: 1.3312 - val_acc: 0.9610\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.8472 - acc: 0.9088 - val_loss: 1.4696 - val_acc: 0.9232\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.8028 - acc: 0.9157 - val_loss: 1.3416 - val_acc: 0.9461\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.8199 - acc: 0.9066 - val_loss: 1.3475 - val_acc: 0.9179\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.7878 - acc: 0.9159 - val_loss: 1.2871 - val_acc: 0.9508\n",
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.7577 - acc: 0.9215 - val_loss: 1.2917 - val_acc: 0.9539\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.7401 - acc: 0.9159 - val_loss: 1.0877 - val_acc: 0.9295\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.7365 - acc: 0.9217 - val_loss: 1.1986 - val_acc: 0.9610\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.7442 - acc: 0.9222 - val_loss: 1.2537 - val_acc: 0.9612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6993 - acc: 0.9291 - val_loss: 1.1425 - val_acc: 0.8700\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.7312 - acc: 0.9223 - val_loss: 0.8463 - val_acc: 0.9480\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.6966 - acc: 0.9290 - val_loss: 1.0324 - val_acc: 0.9601\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6998 - acc: 0.9327 - val_loss: 1.0998 - val_acc: 0.9473\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.6586 - acc: 0.9303 - val_loss: 1.1985 - val_acc: 0.9619\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6698 - acc: 0.9307 - val_loss: 1.1341 - val_acc: 0.9603\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.6940 - acc: 0.9278 - val_loss: 1.0009 - val_acc: 0.9549\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6669 - acc: 0.9303 - val_loss: 1.1078 - val_acc: 0.9591\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 40s 425us/step - loss: 0.6429 - acc: 0.9295 - val_loss: 1.1273 - val_acc: 0.9537\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.6428 - acc: 0.9277 - val_loss: 1.0429 - val_acc: 0.9526\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6383 - acc: 0.9265 - val_loss: 1.0616 - val_acc: 0.9600\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6534 - acc: 0.9309 - val_loss: 1.0955 - val_acc: 0.9580\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.6431 - acc: 0.9299 - val_loss: 1.1492 - val_acc: 0.9618\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 40s 424us/step - loss: 0.6319 - acc: 0.9289 - val_loss: 1.1175 - val_acc: 0.9611\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.6170 - acc: 0.9307 - val_loss: 1.1687 - val_acc: 0.9615\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6165 - acc: 0.9304 - val_loss: 1.0564 - val_acc: 0.9542\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.6231 - acc: 0.9338 - val_loss: 1.1907 - val_acc: 0.9543\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.6020 - acc: 0.9329 - val_loss: 1.0143 - val_acc: 0.9497\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.6260 - acc: 0.9291 - val_loss: 0.8428 - val_acc: 0.9498\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.6266 - acc: 0.9330 - val_loss: 1.1576 - val_acc: 0.9583\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5989 - acc: 0.9315 - val_loss: 0.9464 - val_acc: 0.9580\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5925 - acc: 0.9319 - val_loss: 0.9395 - val_acc: 0.9396\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5836 - acc: 0.9331 - val_loss: 1.0414 - val_acc: 0.9552\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 40s 431us/step - loss: 0.5879 - acc: 0.9339 - val_loss: 1.1425 - val_acc: 0.9556\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5980 - acc: 0.9331 - val_loss: 1.0200 - val_acc: 0.9468\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5656 - acc: 0.9325 - val_loss: 0.9940 - val_acc: 0.9449\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5771 - acc: 0.9351 - val_loss: 1.0850 - val_acc: 0.9483\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5780 - acc: 0.9354 - val_loss: 1.0413 - val_acc: 0.9467\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5759 - acc: 0.9342 - val_loss: 1.1110 - val_acc: 0.9550\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5821 - acc: 0.9327 - val_loss: 0.9953 - val_acc: 0.9301\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5733 - acc: 0.9306 - val_loss: 1.0458 - val_acc: 0.9542\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5635 - acc: 0.9324 - val_loss: 1.0449 - val_acc: 0.9527\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5492 - acc: 0.9348 - val_loss: 1.1681 - val_acc: 0.9526\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5592 - acc: 0.9344 - val_loss: 1.1074 - val_acc: 0.9494\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5536 - acc: 0.9343 - val_loss: 1.0346 - val_acc: 0.9550\n",
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5225 - acc: 0.9374 - val_loss: 1.2693 - val_acc: 0.9555\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5577 - acc: 0.9353 - val_loss: 1.0928 - val_acc: 0.9344\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5279 - acc: 0.9350 - val_loss: 1.0081 - val_acc: 0.9361\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5608 - acc: 0.9341 - val_loss: 1.0469 - val_acc: 0.9480\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5283 - acc: 0.9361 - val_loss: 1.1767 - val_acc: 0.9507\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5432 - acc: 0.9330 - val_loss: 1.0616 - val_acc: 0.9492\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5283 - acc: 0.9363 - val_loss: 1.2301 - val_acc: 0.9257\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5537 - acc: 0.9354 - val_loss: 1.0504 - val_acc: 0.9462\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5384 - acc: 0.9350 - val_loss: 1.0244 - val_acc: 0.9459\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5348 - acc: 0.9289 - val_loss: 1.1802 - val_acc: 0.9482\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.5257 - acc: 0.9349 - val_loss: 0.9571 - val_acc: 0.9321\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 40s 426us/step - loss: 0.5577 - acc: 0.9251 - val_loss: 1.2040 - val_acc: 0.9281\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5747 - acc: 0.9291 - val_loss: 1.0837 - val_acc: 0.9273\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5234 - acc: 0.9378 - val_loss: 1.0895 - val_acc: 0.9508\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5325 - acc: 0.9365 - val_loss: 1.1158 - val_acc: 0.9535\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5089 - acc: 0.9333 - val_loss: 1.1210 - val_acc: 0.9095\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5392 - acc: 0.9312 - val_loss: 1.0150 - val_acc: 0.9248\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5189 - acc: 0.9318 - val_loss: 1.0917 - val_acc: 0.9483\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5158 - acc: 0.9351 - val_loss: 1.0199 - val_acc: 0.9518\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5170 - acc: 0.9347 - val_loss: 1.0909 - val_acc: 0.9444\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5115 - acc: 0.9357 - val_loss: 1.0069 - val_acc: 0.9434\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.4908 - acc: 0.9377 - val_loss: 1.0303 - val_acc: 0.9446\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.4991 - acc: 0.9368 - val_loss: 1.0197 - val_acc: 0.9498\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.4912 - acc: 0.9331 - val_loss: 1.1738 - val_acc: 0.9417\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5024 - acc: 0.9349 - val_loss: 0.9380 - val_acc: 0.9424\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.4978 - acc: 0.9351 - val_loss: 0.9796 - val_acc: 0.9394\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5048 - acc: 0.9373 - val_loss: 1.0045 - val_acc: 0.9530\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 40s 423us/step - loss: 0.5017 - acc: 0.9366 - val_loss: 1.0340 - val_acc: 0.9534\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.4908 - acc: 0.9365 - val_loss: 1.2382 - val_acc: 0.9519\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.4867 - acc: 0.9385 - val_loss: 1.1099 - val_acc: 0.9494\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5064 - acc: 0.9362 - val_loss: 1.0372 - val_acc: 0.9505\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.4918 - acc: 0.9373 - val_loss: 1.0613 - val_acc: 0.9542\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.4766 - acc: 0.9387 - val_loss: 1.2404 - val_acc: 0.9418\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.4935 - acc: 0.9325 - val_loss: 1.1559 - val_acc: 0.9579\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 40s 427us/step - loss: 0.5124 - acc: 0.9342 - val_loss: 1.1590 - val_acc: 0.8625\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.4942 - acc: 0.9344 - val_loss: 1.2118 - val_acc: 0.9519\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.4962 - acc: 0.9383 - val_loss: 0.8866 - val_acc: 0.9432\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.4834 - acc: 0.9330 - val_loss: 1.2021 - val_acc: 0.9527\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.4790 - acc: 0.9369 - val_loss: 1.0998 - val_acc: 0.9412\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.4896 - acc: 0.9362 - val_loss: 1.0294 - val_acc: 0.9212\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.4962 - acc: 0.9374 - val_loss: 1.0490 - val_acc: 0.9308\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 40s 428us/step - loss: 0.4827 - acc: 0.9374 - val_loss: 1.2115 - val_acc: 0.9262\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_12 (Batc (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_4 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 42s 443us/step - loss: 2.5667 - acc: 0.5114 - val_loss: 2.4831 - val_acc: 0.6714\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 2.4222 - acc: 0.5077 - val_loss: 2.4317 - val_acc: 0.5729\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 1.8510 - acc: 0.6937 - val_loss: 2.2991 - val_acc: 0.8222\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 1.5810 - acc: 0.7283 - val_loss: 2.0136 - val_acc: 0.7884\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 41s 434us/step - loss: 1.4454 - acc: 0.7285 - val_loss: 1.8768 - val_acc: 0.7592\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 1.3693 - acc: 0.7585 - val_loss: 1.7862 - val_acc: 0.8181\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 1.2681 - acc: 0.7839 - val_loss: 2.0080 - val_acc: 0.9053\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 1.1994 - acc: 0.8034 - val_loss: 1.7547 - val_acc: 0.8866\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 41s 434us/step - loss: 1.1686 - acc: 0.8224 - val_loss: 1.5175 - val_acc: 0.8814\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 1.0857 - acc: 0.8549 - val_loss: 1.4641 - val_acc: 0.9229\n",
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 41s 434us/step - loss: 1.0188 - acc: 0.8639 - val_loss: 1.3774 - val_acc: 0.9328\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 0.9374 - acc: 0.8871 - val_loss: 1.4925 - val_acc: 0.9633\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.9075 - acc: 0.8919 - val_loss: 1.2639 - val_acc: 0.9457\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 41s 434us/step - loss: 0.8545 - acc: 0.9069 - val_loss: 1.2547 - val_acc: 0.9478\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.8533 - acc: 0.9040 - val_loss: 1.2653 - val_acc: 0.9164\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.8273 - acc: 0.9078 - val_loss: 1.2138 - val_acc: 0.9412\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 41s 434us/step - loss: 0.8229 - acc: 0.9173 - val_loss: 1.1190 - val_acc: 0.9547\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.8209 - acc: 0.9160 - val_loss: 1.2578 - val_acc: 0.9656\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.7818 - acc: 0.9181 - val_loss: 1.1739 - val_acc: 0.9461\n",
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.7873 - acc: 0.9118 - val_loss: 1.0487 - val_acc: 0.9453\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.7823 - acc: 0.9176 - val_loss: 1.0451 - val_acc: 0.9529\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.7660 - acc: 0.9197 - val_loss: 1.2839 - val_acc: 0.9661\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.7511 - acc: 0.9149 - val_loss: 1.1592 - val_acc: 0.9639\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.7399 - acc: 0.9189 - val_loss: 1.1579 - val_acc: 0.9552\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.7266 - acc: 0.9214 - val_loss: 1.0432 - val_acc: 0.9492\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.7117 - acc: 0.9189 - val_loss: 1.0922 - val_acc: 0.8997\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6888 - acc: 0.9231 - val_loss: 1.1748 - val_acc: 0.9430\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6998 - acc: 0.9182 - val_loss: 0.9931 - val_acc: 0.9398\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.6959 - acc: 0.9180 - val_loss: 1.0913 - val_acc: 0.9511\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.6976 - acc: 0.9258 - val_loss: 1.0092 - val_acc: 0.9451\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.6896 - acc: 0.9221 - val_loss: 1.0134 - val_acc: 0.9563\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.6720 - acc: 0.9257 - val_loss: 1.0558 - val_acc: 0.9486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.6778 - acc: 0.9273 - val_loss: 0.9754 - val_acc: 0.9515\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.6531 - acc: 0.9230 - val_loss: 1.0952 - val_acc: 0.9449\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.6420 - acc: 0.9252 - val_loss: 1.0058 - val_acc: 0.9443\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 41s 434us/step - loss: 0.6654 - acc: 0.9239 - val_loss: 0.9792 - val_acc: 0.9377\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 0.6747 - acc: 0.9206 - val_loss: 1.2384 - val_acc: 0.9416\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6493 - acc: 0.9271 - val_loss: 1.0721 - val_acc: 0.9356\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 0.6510 - acc: 0.9253 - val_loss: 0.9806 - val_acc: 0.9344\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6336 - acc: 0.9249 - val_loss: 1.2053 - val_acc: 0.9505\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 0.6386 - acc: 0.9230 - val_loss: 0.8904 - val_acc: 0.9331\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 41s 434us/step - loss: 0.6077 - acc: 0.9230 - val_loss: 1.1414 - val_acc: 0.9536\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6150 - acc: 0.9275 - val_loss: 1.0326 - val_acc: 0.9523\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6407 - acc: 0.9266 - val_loss: 1.1441 - val_acc: 0.9511\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6157 - acc: 0.9260 - val_loss: 1.0265 - val_acc: 0.9570\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6337 - acc: 0.9258 - val_loss: 0.9193 - val_acc: 0.9297\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6326 - acc: 0.9223 - val_loss: 1.0331 - val_acc: 0.9484\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6053 - acc: 0.9250 - val_loss: 0.9380 - val_acc: 0.9457\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6280 - acc: 0.9258 - val_loss: 0.9019 - val_acc: 0.9512\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 0.6358 - acc: 0.9258 - val_loss: 1.0305 - val_acc: 0.9363\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 41s 434us/step - loss: 0.5935 - acc: 0.9258 - val_loss: 0.8648 - val_acc: 0.9430\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.6014 - acc: 0.9270 - val_loss: 1.0841 - val_acc: 0.9477\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5832 - acc: 0.9294 - val_loss: 1.0183 - val_acc: 0.9493\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.5996 - acc: 0.9279 - val_loss: 1.0362 - val_acc: 0.9595\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5853 - acc: 0.9297 - val_loss: 1.0287 - val_acc: 0.9368\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 0.5941 - acc: 0.9266 - val_loss: 1.0200 - val_acc: 0.9349\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5725 - acc: 0.9314 - val_loss: 1.0140 - val_acc: 0.9413\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5634 - acc: 0.9274 - val_loss: 1.1231 - val_acc: 0.9433\n",
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5834 - acc: 0.9234 - val_loss: 1.0320 - val_acc: 0.9475\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.5710 - acc: 0.9318 - val_loss: 0.9934 - val_acc: 0.9498\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5802 - acc: 0.9297 - val_loss: 0.9877 - val_acc: 0.9154\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5794 - acc: 0.9250 - val_loss: 1.0133 - val_acc: 0.9553\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5719 - acc: 0.9303 - val_loss: 1.0859 - val_acc: 0.9494\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.5634 - acc: 0.9280 - val_loss: 0.9407 - val_acc: 0.9487\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 0.5517 - acc: 0.9284 - val_loss: 1.2229 - val_acc: 0.9498\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.6068 - acc: 0.9236 - val_loss: 1.1744 - val_acc: 0.9136\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5790 - acc: 0.9274 - val_loss: 0.9819 - val_acc: 0.8911\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5655 - acc: 0.9294 - val_loss: 1.0284 - val_acc: 0.9488\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5488 - acc: 0.9319 - val_loss: 0.9423 - val_acc: 0.9299\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.5582 - acc: 0.9271 - val_loss: 1.1760 - val_acc: 0.9614\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 41s 434us/step - loss: 0.5646 - acc: 0.9323 - val_loss: 1.0983 - val_acc: 0.9431\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5406 - acc: 0.9296 - val_loss: 1.1058 - val_acc: 0.9500\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 0.5532 - acc: 0.9313 - val_loss: 0.9626 - val_acc: 0.9291\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.5459 - acc: 0.9290 - val_loss: 1.0452 - val_acc: 0.9403\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 41s 434us/step - loss: 0.5337 - acc: 0.9302 - val_loss: 1.1457 - val_acc: 0.9282\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5647 - acc: 0.9306 - val_loss: 0.9766 - val_acc: 0.9265\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5425 - acc: 0.9309 - val_loss: 0.9831 - val_acc: 0.9409\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5396 - acc: 0.9304 - val_loss: 1.1711 - val_acc: 0.9602\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 0.5343 - acc: 0.9333 - val_loss: 1.0599 - val_acc: 0.9469\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5296 - acc: 0.9322 - val_loss: 1.0351 - val_acc: 0.9497\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5404 - acc: 0.9319 - val_loss: 0.9601 - val_acc: 0.9508\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5520 - acc: 0.9301 - val_loss: 1.0097 - val_acc: 0.9443\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5472 - acc: 0.9309 - val_loss: 0.9435 - val_acc: 0.9506\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.5489 - acc: 0.9332 - val_loss: 1.0285 - val_acc: 0.9364\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 0.5315 - acc: 0.9309 - val_loss: 1.2269 - val_acc: 0.9544\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5323 - acc: 0.9344 - val_loss: 1.1037 - val_acc: 0.9516\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.5185 - acc: 0.9330 - val_loss: 1.0161 - val_acc: 0.9528\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.5142 - acc: 0.9338 - val_loss: 1.2381 - val_acc: 0.9539\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 40s 430us/step - loss: 0.5410 - acc: 0.9327 - val_loss: 1.2039 - val_acc: 0.9344\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5362 - acc: 0.9318 - val_loss: 1.0941 - val_acc: 0.9559\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5079 - acc: 0.9342 - val_loss: 1.0907 - val_acc: 0.9468\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5277 - acc: 0.9338 - val_loss: 0.9256 - val_acc: 0.9285\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5259 - acc: 0.9357 - val_loss: 0.9044 - val_acc: 0.9442\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 41s 434us/step - loss: 0.5394 - acc: 0.9337 - val_loss: 0.9786 - val_acc: 0.9140\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 40s 429us/step - loss: 0.5217 - acc: 0.9319 - val_loss: 1.0784 - val_acc: 0.9445\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.5286 - acc: 0.9322 - val_loss: 0.9702 - val_acc: 0.9487\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 41s 432us/step - loss: 0.5232 - acc: 0.9317 - val_loss: 1.0761 - val_acc: 0.9223\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 0.5130 - acc: 0.9352 - val_loss: 1.0759 - val_acc: 0.9575\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 41s 433us/step - loss: 0.5214 - acc: 0.9322 - val_loss: 1.0504 - val_acc: 0.9388\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 41s 431us/step - loss: 0.5162 - acc: 0.9363 - val_loss: 1.1581 - val_acc: 0.9371\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_13 (Batc (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_5 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 22s 235us/step - loss: 2.5639 - acc: 0.6030 - val_loss: 2.5259 - val_acc: 0.6023\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 2.2499 - acc: 0.6032 - val_loss: 2.0434 - val_acc: 0.5895\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 2.0694 - acc: 0.6289 - val_loss: 1.9409 - val_acc: 0.6598\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.8334 - acc: 0.6290 - val_loss: 1.7394 - val_acc: 0.6364\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.4439 - acc: 0.7096 - val_loss: 1.5017 - val_acc: 0.7744\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.2509 - acc: 0.7394 - val_loss: 1.3350 - val_acc: 0.8238\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 1.3047 - acc: 0.7398 - val_loss: 1.3809 - val_acc: 0.7967\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.2213 - acc: 0.7829 - val_loss: 1.3163 - val_acc: 0.8547\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.1476 - acc: 0.8002 - val_loss: 1.3318 - val_acc: 0.8921\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0874 - acc: 0.8173 - val_loss: 1.2225 - val_acc: 0.8917\n",
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.0820 - acc: 0.8223 - val_loss: 1.3600 - val_acc: 0.8429\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0290 - acc: 0.8326 - val_loss: 1.1381 - val_acc: 0.8796\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0038 - acc: 0.8507 - val_loss: 1.1635 - val_acc: 0.9198\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.0468 - acc: 0.8439 - val_loss: 1.1857 - val_acc: 0.8930\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0632 - acc: 0.8391 - val_loss: 1.1502 - val_acc: 0.9124\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.9901 - acc: 0.8627 - val_loss: 1.3652 - val_acc: 0.9348\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.0769 - acc: 0.8317 - val_loss: 1.4661 - val_acc: 0.8436\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.1295 - acc: 0.8403 - val_loss: 1.3179 - val_acc: 0.9057\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.1321 - acc: 0.8121 - val_loss: 1.1405 - val_acc: 0.9040\n",
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0421 - acc: 0.8630 - val_loss: 1.1826 - val_acc: 0.9352\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.9561 - acc: 0.8857 - val_loss: 1.2431 - val_acc: 0.9257\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9201 - acc: 0.8869 - val_loss: 1.7428 - val_acc: 0.8842\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9124 - acc: 0.8946 - val_loss: 1.2720 - val_acc: 0.9333\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.8854 - acc: 0.8917 - val_loss: 1.2448 - val_acc: 0.9342\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8586 - acc: 0.9036 - val_loss: 1.2062 - val_acc: 0.9320\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.8265 - acc: 0.9045 - val_loss: 1.1382 - val_acc: 0.9284\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8206 - acc: 0.9085 - val_loss: 1.1337 - val_acc: 0.9478\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.8145 - acc: 0.9028 - val_loss: 1.3485 - val_acc: 0.8835\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.8258 - acc: 0.9033 - val_loss: 1.2796 - val_acc: 0.9447\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8275 - acc: 0.9099 - val_loss: 1.1921 - val_acc: 0.9199\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8445 - acc: 0.9077 - val_loss: 1.3440 - val_acc: 0.9603\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.8039 - acc: 0.9073 - val_loss: 1.0998 - val_acc: 0.9323\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7802 - acc: 0.9170 - val_loss: 1.1027 - val_acc: 0.9289\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7779 - acc: 0.9188 - val_loss: 1.0365 - val_acc: 0.9185\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7740 - acc: 0.9133 - val_loss: 1.3456 - val_acc: 0.9542\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7639 - acc: 0.9150 - val_loss: 1.1350 - val_acc: 0.9487\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.7434 - acc: 0.9181 - val_loss: 0.9778 - val_acc: 0.9386\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7431 - acc: 0.9171 - val_loss: 1.0646 - val_acc: 0.9093\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7278 - acc: 0.9154 - val_loss: 1.1784 - val_acc: 0.9435\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7676 - acc: 0.9085 - val_loss: 0.9680 - val_acc: 0.9341\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7412 - acc: 0.9201 - val_loss: 1.0169 - val_acc: 0.9474\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6946 - acc: 0.9248 - val_loss: 1.2905 - val_acc: 0.9332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7210 - acc: 0.9183 - val_loss: 1.2574 - val_acc: 0.8160\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7479 - acc: 0.9160 - val_loss: 1.4264 - val_acc: 0.9442\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7132 - acc: 0.9139 - val_loss: 1.3755 - val_acc: 0.9420\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7195 - acc: 0.9159 - val_loss: 1.1749 - val_acc: 0.9355\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6801 - acc: 0.9273 - val_loss: 1.0239 - val_acc: 0.9425\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6801 - acc: 0.9224 - val_loss: 1.2319 - val_acc: 0.9494\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6920 - acc: 0.9213 - val_loss: 1.0575 - val_acc: 0.8882\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7634 - acc: 0.9058 - val_loss: 1.2978 - val_acc: 0.9015\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.7776 - acc: 0.9138 - val_loss: 1.1864 - val_acc: 0.9170\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7046 - acc: 0.9237 - val_loss: 1.0757 - val_acc: 0.9515\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7951 - acc: 0.9086 - val_loss: 1.2811 - val_acc: 0.9123\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8079 - acc: 0.9154 - val_loss: 1.1742 - val_acc: 0.9320\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7090 - acc: 0.9234 - val_loss: 1.2196 - val_acc: 0.9162\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6964 - acc: 0.9219 - val_loss: 1.1363 - val_acc: 0.9324\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.6728 - acc: 0.9276 - val_loss: 1.5014 - val_acc: 0.9588\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.7496 - acc: 0.9259 - val_loss: 1.3331 - val_acc: 0.9471\n",
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6683 - acc: 0.9286 - val_loss: 1.2309 - val_acc: 0.9376\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6497 - acc: 0.9315 - val_loss: 1.2277 - val_acc: 0.9575\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6770 - acc: 0.9228 - val_loss: 1.1162 - val_acc: 0.9402\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6752 - acc: 0.9175 - val_loss: 1.2930 - val_acc: 0.9326\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6917 - acc: 0.9164 - val_loss: 1.6271 - val_acc: 0.9398\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6609 - acc: 0.9242 - val_loss: 1.2300 - val_acc: 0.9368\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6693 - acc: 0.9261 - val_loss: 1.1768 - val_acc: 0.9404\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6372 - acc: 0.9289 - val_loss: 1.0547 - val_acc: 0.9392\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6616 - acc: 0.9218 - val_loss: 1.2650 - val_acc: 0.9189\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6990 - acc: 0.9247 - val_loss: 1.3511 - val_acc: 0.9561\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6773 - acc: 0.9264 - val_loss: 1.2230 - val_acc: 0.9486\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6238 - acc: 0.9338 - val_loss: 1.4042 - val_acc: 0.9500\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6405 - acc: 0.9268 - val_loss: 1.3048 - val_acc: 0.9304\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9134 - acc: 0.8787 - val_loss: 1.7942 - val_acc: 0.8779\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.8890 - acc: 0.8944 - val_loss: 1.5103 - val_acc: 0.9111\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7605 - acc: 0.9132 - val_loss: 1.2763 - val_acc: 0.9056\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7072 - acc: 0.9200 - val_loss: 1.2660 - val_acc: 0.9200\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7009 - acc: 0.9283 - val_loss: 1.2882 - val_acc: 0.9210\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6731 - acc: 0.9256 - val_loss: 1.3003 - val_acc: 0.9439\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6268 - acc: 0.9303 - val_loss: 1.4089 - val_acc: 0.9303\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6464 - acc: 0.9305 - val_loss: 1.6075 - val_acc: 0.9389\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6211 - acc: 0.9366 - val_loss: 1.0219 - val_acc: 0.9237\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6323 - acc: 0.9324 - val_loss: 1.2757 - val_acc: 0.8768\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6249 - acc: 0.9335 - val_loss: 1.2385 - val_acc: 0.9409\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6373 - acc: 0.9354 - val_loss: 1.1818 - val_acc: 0.9415\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6079 - acc: 0.9398 - val_loss: 1.1429 - val_acc: 0.9489\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6070 - acc: 0.9421 - val_loss: 1.0256 - val_acc: 0.9322\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5925 - acc: 0.9374 - val_loss: 1.2656 - val_acc: 0.9552\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6048 - acc: 0.9350 - val_loss: 1.0205 - val_acc: 0.9045\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5965 - acc: 0.9357 - val_loss: 1.3915 - val_acc: 0.9577\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6065 - acc: 0.9325 - val_loss: 1.1324 - val_acc: 0.9345\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6029 - acc: 0.9282 - val_loss: 1.3634 - val_acc: 0.9126\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5944 - acc: 0.9363 - val_loss: 1.1107 - val_acc: 0.9443\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6106 - acc: 0.9315 - val_loss: 1.2671 - val_acc: 0.9263\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5914 - acc: 0.9347 - val_loss: 1.1545 - val_acc: 0.9250\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6121 - acc: 0.9224 - val_loss: 0.9540 - val_acc: 0.9306\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5872 - acc: 0.9327 - val_loss: 0.9766 - val_acc: 0.9262\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.5645 - acc: 0.9334 - val_loss: 1.2627 - val_acc: 0.9257\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5687 - acc: 0.9298 - val_loss: 1.1588 - val_acc: 0.9511\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5593 - acc: 0.9312 - val_loss: 1.5791 - val_acc: 0.9442\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5682 - acc: 0.9349 - val_loss: 1.3834 - val_acc: 0.9493\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.5866 - acc: 0.9297 - val_loss: 1.2960 - val_acc: 0.9377\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_14 (Batc (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_6 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 22s 237us/step - loss: 2.6009 - acc: 0.5154 - val_loss: 2.5603 - val_acc: 0.3215\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 2.4527 - acc: 0.5276 - val_loss: 2.4538 - val_acc: 0.6992\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 2.3396 - acc: 0.5421 - val_loss: 2.1890 - val_acc: 0.3435\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 1.9733 - acc: 0.6357 - val_loss: 2.1056 - val_acc: 0.8843\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 1.8702 - acc: 0.6229 - val_loss: 2.0933 - val_acc: 0.8290\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.7772 - acc: 0.6848 - val_loss: 1.7945 - val_acc: 0.7866\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 1.4850 - acc: 0.7285 - val_loss: 1.5868 - val_acc: 0.7596\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 1.3141 - acc: 0.7623 - val_loss: 1.4280 - val_acc: 0.8015\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 1.2733 - acc: 0.7900 - val_loss: 1.7356 - val_acc: 0.8880\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 1.1858 - acc: 0.8143 - val_loss: 1.2996 - val_acc: 0.6952\n",
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 1.1598 - acc: 0.8204 - val_loss: 1.3356 - val_acc: 0.8131\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 1.0784 - acc: 0.8330 - val_loss: 1.2745 - val_acc: 0.8547\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 1.0589 - acc: 0.8452 - val_loss: 1.2358 - val_acc: 0.8932\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.9835 - acc: 0.8661 - val_loss: 1.3447 - val_acc: 0.9339\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.9708 - acc: 0.8680 - val_loss: 1.1942 - val_acc: 0.9058\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.9250 - acc: 0.8778 - val_loss: 1.1337 - val_acc: 0.9294\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.9244 - acc: 0.8810 - val_loss: 1.1164 - val_acc: 0.9419\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.8641 - acc: 0.8965 - val_loss: 0.9399 - val_acc: 0.9304\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.8366 - acc: 0.9085 - val_loss: 1.1670 - val_acc: 0.9569\n",
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.8293 - acc: 0.9111 - val_loss: 0.9988 - val_acc: 0.9303\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.8001 - acc: 0.9139 - val_loss: 1.1108 - val_acc: 0.9610\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7680 - acc: 0.9176 - val_loss: 0.9770 - val_acc: 0.9559\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7819 - acc: 0.9115 - val_loss: 0.8964 - val_acc: 0.9398\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.7520 - acc: 0.9209 - val_loss: 0.9716 - val_acc: 0.9378\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7395 - acc: 0.9176 - val_loss: 0.9791 - val_acc: 0.9319\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.7567 - acc: 0.9170 - val_loss: 0.8218 - val_acc: 0.9275\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7218 - acc: 0.9225 - val_loss: 0.9564 - val_acc: 0.9472\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.7245 - acc: 0.9269 - val_loss: 1.1119 - val_acc: 0.9586\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.7236 - acc: 0.9234 - val_loss: 0.9200 - val_acc: 0.9538\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.6990 - acc: 0.9251 - val_loss: 0.8754 - val_acc: 0.9460\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6792 - acc: 0.9239 - val_loss: 0.8849 - val_acc: 0.9543\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6741 - acc: 0.9259 - val_loss: 0.8547 - val_acc: 0.9452\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.6555 - acc: 0.9244 - val_loss: 0.7810 - val_acc: 0.9323\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.6523 - acc: 0.9232 - val_loss: 0.8401 - val_acc: 0.9542\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6648 - acc: 0.9267 - val_loss: 0.9038 - val_acc: 0.9614\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6495 - acc: 0.9295 - val_loss: 1.1648 - val_acc: 0.9388\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6466 - acc: 0.9292 - val_loss: 0.8567 - val_acc: 0.9514\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.6189 - acc: 0.9332 - val_loss: 0.9137 - val_acc: 0.9564\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5908 - acc: 0.9321 - val_loss: 0.8109 - val_acc: 0.9546\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6133 - acc: 0.9285 - val_loss: 0.7989 - val_acc: 0.9530\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6140 - acc: 0.9335 - val_loss: 0.9713 - val_acc: 0.9547\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6150 - acc: 0.9312 - val_loss: 0.8055 - val_acc: 0.9471\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.5918 - acc: 0.9307 - val_loss: 0.9326 - val_acc: 0.9449\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.5910 - acc: 0.9298 - val_loss: 0.9252 - val_acc: 0.9501\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5886 - acc: 0.9321 - val_loss: 0.9684 - val_acc: 0.9556\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.5957 - acc: 0.9341 - val_loss: 0.8115 - val_acc: 0.9498\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5747 - acc: 0.9352 - val_loss: 0.8220 - val_acc: 0.9272\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5814 - acc: 0.9306 - val_loss: 0.8642 - val_acc: 0.9551\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5726 - acc: 0.9363 - val_loss: 0.8275 - val_acc: 0.9480\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5654 - acc: 0.9356 - val_loss: 0.8946 - val_acc: 0.9536\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5452 - acc: 0.9356 - val_loss: 0.7795 - val_acc: 0.9485\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.5674 - acc: 0.9360 - val_loss: 0.8311 - val_acc: 0.9466\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5612 - acc: 0.9370 - val_loss: 0.8423 - val_acc: 0.9374\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5686 - acc: 0.9330 - val_loss: 0.7650 - val_acc: 0.9350\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5699 - acc: 0.9349 - val_loss: 0.8764 - val_acc: 0.9461\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5252 - acc: 0.9371 - val_loss: 0.9859 - val_acc: 0.9370\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5581 - acc: 0.9289 - val_loss: 0.8649 - val_acc: 0.9490\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5182 - acc: 0.9387 - val_loss: 0.8097 - val_acc: 0.9444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5359 - acc: 0.9366 - val_loss: 1.0160 - val_acc: 0.9565\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5525 - acc: 0.9354 - val_loss: 0.9187 - val_acc: 0.9491\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5523 - acc: 0.9323 - val_loss: 0.7658 - val_acc: 0.9409\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5359 - acc: 0.9327 - val_loss: 0.8903 - val_acc: 0.9478\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5173 - acc: 0.9373 - val_loss: 1.0857 - val_acc: 0.9587\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5451 - acc: 0.9319 - val_loss: 0.8541 - val_acc: 0.9418\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5381 - acc: 0.9346 - val_loss: 1.0281 - val_acc: 0.9571\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5046 - acc: 0.9402 - val_loss: 1.0510 - val_acc: 0.9511\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.4962 - acc: 0.9411 - val_loss: 1.0966 - val_acc: 0.9489\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.5038 - acc: 0.9430 - val_loss: 0.9464 - val_acc: 0.9508\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5243 - acc: 0.9373 - val_loss: 0.9325 - val_acc: 0.9497\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5170 - acc: 0.9378 - val_loss: 0.9417 - val_acc: 0.9458\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.5016 - acc: 0.9403 - val_loss: 0.8029 - val_acc: 0.9039\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5145 - acc: 0.9357 - val_loss: 1.0190 - val_acc: 0.9433\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 21s 227us/step - loss: 0.5030 - acc: 0.9383 - val_loss: 0.9675 - val_acc: 0.9477\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5203 - acc: 0.9369 - val_loss: 0.8577 - val_acc: 0.9555\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4871 - acc: 0.9397 - val_loss: 1.0607 - val_acc: 0.9568\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5093 - acc: 0.9317 - val_loss: 0.8830 - val_acc: 0.9443\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4948 - acc: 0.9375 - val_loss: 0.8587 - val_acc: 0.9420\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4997 - acc: 0.9384 - val_loss: 0.9768 - val_acc: 0.9499\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4761 - acc: 0.9414 - val_loss: 1.0029 - val_acc: 0.9461\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5180 - acc: 0.9350 - val_loss: 0.9415 - val_acc: 0.9515\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 21s 227us/step - loss: 0.4897 - acc: 0.9388 - val_loss: 0.8908 - val_acc: 0.9548\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4895 - acc: 0.9375 - val_loss: 1.0296 - val_acc: 0.9568\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4855 - acc: 0.9426 - val_loss: 0.8658 - val_acc: 0.9566\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.4812 - acc: 0.9421 - val_loss: 0.8648 - val_acc: 0.9503\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.4793 - acc: 0.9425 - val_loss: 0.9476 - val_acc: 0.9437\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.4824 - acc: 0.9378 - val_loss: 0.8713 - val_acc: 0.9550\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.4537 - acc: 0.9426 - val_loss: 1.1215 - val_acc: 0.9566\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4661 - acc: 0.9422 - val_loss: 1.0189 - val_acc: 0.9547\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.4846 - acc: 0.9384 - val_loss: 1.1084 - val_acc: 0.9535\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4655 - acc: 0.9418 - val_loss: 0.8846 - val_acc: 0.9497\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4658 - acc: 0.9407 - val_loss: 0.7889 - val_acc: 0.9423\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.4854 - acc: 0.9384 - val_loss: 0.8560 - val_acc: 0.9431\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.4685 - acc: 0.9383 - val_loss: 1.0584 - val_acc: 0.9565\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4786 - acc: 0.9415 - val_loss: 0.8560 - val_acc: 0.9443\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4706 - acc: 0.9390 - val_loss: 1.2024 - val_acc: 0.9554\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.4794 - acc: 0.9365 - val_loss: 1.0762 - val_acc: 0.9549\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4723 - acc: 0.9368 - val_loss: 0.9883 - val_acc: 0.9564\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.4669 - acc: 0.9420 - val_loss: 1.0100 - val_acc: 0.9306\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.4645 - acc: 0.9450 - val_loss: 0.9310 - val_acc: 0.9470\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4834 - acc: 0.9386 - val_loss: 1.0533 - val_acc: 0.9342\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_15 (Batc (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_7 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 22s 234us/step - loss: 2.5422 - acc: 0.6056 - val_loss: 2.5748 - val_acc: 0.6154\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 2.4271 - acc: 0.5636 - val_loss: 2.6274 - val_acc: 0.7565\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 2.3410 - acc: 0.5388 - val_loss: 2.3957 - val_acc: 0.7947\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.9608 - acc: 0.6556 - val_loss: 2.0270 - val_acc: 0.7799\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 1.6059 - acc: 0.7396 - val_loss: 2.2760 - val_acc: 0.8225\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.4990 - acc: 0.6800 - val_loss: 2.1411 - val_acc: 0.7376\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.3820 - acc: 0.6989 - val_loss: 1.8917 - val_acc: 0.7716\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.2914 - acc: 0.7219 - val_loss: 2.2201 - val_acc: 0.8199\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.1741 - acc: 0.7729 - val_loss: 1.7492 - val_acc: 0.8209\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.1256 - acc: 0.7958 - val_loss: 1.6933 - val_acc: 0.8506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 1.0574 - acc: 0.8241 - val_loss: 1.6737 - val_acc: 0.9138\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.0051 - acc: 0.8495 - val_loss: 1.6810 - val_acc: 0.9044\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.9582 - acc: 0.8679 - val_loss: 1.7538 - val_acc: 0.9328\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.9169 - acc: 0.8905 - val_loss: 1.6343 - val_acc: 0.9346\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8671 - acc: 0.9043 - val_loss: 1.5119 - val_acc: 0.9222\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.8445 - acc: 0.9062 - val_loss: 1.6475 - val_acc: 0.9239\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.8147 - acc: 0.9098 - val_loss: 1.4032 - val_acc: 0.9352\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.8010 - acc: 0.9148 - val_loss: 1.3885 - val_acc: 0.9245\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.8045 - acc: 0.9093 - val_loss: 1.5017 - val_acc: 0.9476\n",
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7775 - acc: 0.9194 - val_loss: 1.6734 - val_acc: 0.9209\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7693 - acc: 0.9155 - val_loss: 1.6228 - val_acc: 0.9635\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.7434 - acc: 0.9237 - val_loss: 1.4060 - val_acc: 0.8936\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 21s 218us/step - loss: 0.7442 - acc: 0.9221 - val_loss: 1.5435 - val_acc: 0.9542\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7175 - acc: 0.9247 - val_loss: 1.3623 - val_acc: 0.9267\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.7026 - acc: 0.9225 - val_loss: 1.3361 - val_acc: 0.9208\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6898 - acc: 0.9269 - val_loss: 1.3286 - val_acc: 0.9462\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6812 - acc: 0.9307 - val_loss: 1.4205 - val_acc: 0.9114\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6893 - acc: 0.9278 - val_loss: 1.3157 - val_acc: 0.9267\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6581 - acc: 0.9336 - val_loss: 1.3835 - val_acc: 0.9185\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6707 - acc: 0.9293 - val_loss: 1.3832 - val_acc: 0.9470\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6580 - acc: 0.9314 - val_loss: 1.3213 - val_acc: 0.9531\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6396 - acc: 0.9338 - val_loss: 1.2014 - val_acc: 0.9268\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6478 - acc: 0.9313 - val_loss: 1.4034 - val_acc: 0.9623\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6286 - acc: 0.9328 - val_loss: 1.3601 - val_acc: 0.9281\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6352 - acc: 0.9286 - val_loss: 1.3315 - val_acc: 0.9162\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.6174 - acc: 0.9292 - val_loss: 1.3649 - val_acc: 0.9056\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.6205 - acc: 0.9304 - val_loss: 1.3336 - val_acc: 0.9481\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5941 - acc: 0.9302 - val_loss: 1.4093 - val_acc: 0.9596\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5954 - acc: 0.9311 - val_loss: 1.2600 - val_acc: 0.9428\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 21s 221us/step - loss: 0.5823 - acc: 0.9372 - val_loss: 1.4652 - val_acc: 0.9376\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6051 - acc: 0.9320 - val_loss: 1.2154 - val_acc: 0.9348\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5898 - acc: 0.9324 - val_loss: 1.4046 - val_acc: 0.9556\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5871 - acc: 0.9317 - val_loss: 1.3702 - val_acc: 0.9314\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6052 - acc: 0.9324 - val_loss: 1.3768 - val_acc: 0.9427\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5588 - acc: 0.9374 - val_loss: 1.3028 - val_acc: 0.9185\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5770 - acc: 0.9347 - val_loss: 1.2763 - val_acc: 0.9423\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5575 - acc: 0.9360 - val_loss: 1.1167 - val_acc: 0.8868\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5579 - acc: 0.9350 - val_loss: 1.2220 - val_acc: 0.9239\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5584 - acc: 0.9344 - val_loss: 1.2104 - val_acc: 0.9165\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5376 - acc: 0.9342 - val_loss: 1.3227 - val_acc: 0.9387\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5603 - acc: 0.9351 - val_loss: 1.2987 - val_acc: 0.9461\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5476 - acc: 0.9349 - val_loss: 1.2191 - val_acc: 0.9438\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5520 - acc: 0.9383 - val_loss: 1.1448 - val_acc: 0.9277\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5478 - acc: 0.9364 - val_loss: 1.1866 - val_acc: 0.9364\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5503 - acc: 0.9373 - val_loss: 1.3285 - val_acc: 0.9504\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5464 - acc: 0.9399 - val_loss: 1.2996 - val_acc: 0.9418\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5278 - acc: 0.9399 - val_loss: 1.2333 - val_acc: 0.9421\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5317 - acc: 0.9399 - val_loss: 1.2976 - val_acc: 0.9223\n",
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5436 - acc: 0.9345 - val_loss: 1.2676 - val_acc: 0.9254\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5256 - acc: 0.9378 - val_loss: 1.1651 - val_acc: 0.9441\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5399 - acc: 0.9372 - val_loss: 1.2183 - val_acc: 0.9379\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5269 - acc: 0.9376 - val_loss: 1.2970 - val_acc: 0.9433\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.5217 - acc: 0.9399 - val_loss: 1.2229 - val_acc: 0.9338\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5109 - acc: 0.9405 - val_loss: 1.1888 - val_acc: 0.9388\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.5033 - acc: 0.9389 - val_loss: 1.2340 - val_acc: 0.8997\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.4915 - acc: 0.9414 - val_loss: 1.3337 - val_acc: 0.9074\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5190 - acc: 0.9398 - val_loss: 1.2319 - val_acc: 0.9377\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5221 - acc: 0.9360 - val_loss: 1.3293 - val_acc: 0.9554\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5119 - acc: 0.9390 - val_loss: 1.2892 - val_acc: 0.9400\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4979 - acc: 0.9403 - val_loss: 1.2850 - val_acc: 0.9498\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5142 - acc: 0.9407 - val_loss: 1.1657 - val_acc: 0.9463\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4911 - acc: 0.9405 - val_loss: 1.3528 - val_acc: 0.9324\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5161 - acc: 0.9380 - val_loss: 1.4850 - val_acc: 0.9384\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.4999 - acc: 0.9402 - val_loss: 1.2761 - val_acc: 0.9375\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5017 - acc: 0.9404 - val_loss: 1.2178 - val_acc: 0.9296\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5044 - acc: 0.9416 - val_loss: 1.0862 - val_acc: 0.9442\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.4767 - acc: 0.9439 - val_loss: 1.3842 - val_acc: 0.9265\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.4833 - acc: 0.9426 - val_loss: 1.3446 - val_acc: 0.9380\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4778 - acc: 0.9407 - val_loss: 1.3988 - val_acc: 0.9021\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4809 - acc: 0.9427 - val_loss: 1.1744 - val_acc: 0.8916\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.4976 - acc: 0.9377 - val_loss: 1.1513 - val_acc: 0.9360\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.4997 - acc: 0.9378 - val_loss: 1.2432 - val_acc: 0.9459\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.4784 - acc: 0.9431 - val_loss: 1.3122 - val_acc: 0.9513\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 20s 208us/step - loss: 0.4790 - acc: 0.9374 - val_loss: 1.2675 - val_acc: 0.9151\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 21s 219us/step - loss: 0.4743 - acc: 0.9430 - val_loss: 1.1910 - val_acc: 0.9430\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 21s 220us/step - loss: 0.4901 - acc: 0.9420 - val_loss: 1.2437 - val_acc: 0.9375\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.4822 - acc: 0.9375 - val_loss: 1.2304 - val_acc: 0.9518\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.4722 - acc: 0.9396 - val_loss: 1.2499 - val_acc: 0.9289\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.4632 - acc: 0.9404 - val_loss: 1.3234 - val_acc: 0.9380\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.4889 - acc: 0.9409 - val_loss: 1.1917 - val_acc: 0.9468\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.4720 - acc: 0.9398 - val_loss: 1.1081 - val_acc: 0.9387\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.4629 - acc: 0.9423 - val_loss: 1.2414 - val_acc: 0.9480\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.4677 - acc: 0.9413 - val_loss: 1.3183 - val_acc: 0.9519\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4644 - acc: 0.9431 - val_loss: 1.1504 - val_acc: 0.9477\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.4541 - acc: 0.9419 - val_loss: 1.3985 - val_acc: 0.9278\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.4747 - acc: 0.9406 - val_loss: 1.3366 - val_acc: 0.9362\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4870 - acc: 0.9432 - val_loss: 1.3347 - val_acc: 0.9345\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4496 - acc: 0.9441 - val_loss: 1.2269 - val_acc: 0.9551\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4660 - acc: 0.9445 - val_loss: 1.2616 - val_acc: 0.9307\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.4642 - acc: 0.9381 - val_loss: 1.2978 - val_acc: 0.9390\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_16 (Batc (None, 256, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 256, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_8 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 94042 samples, validate on 22946 samples\n",
      "Epoch 1/100\n",
      "94042/94042 [==============================] - 23s 241us/step - loss: 2.5895 - acc: 0.5338 - val_loss: 2.4896 - val_acc: 0.4358\n",
      "Epoch 2/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 2.4470 - acc: 0.5203 - val_loss: 2.4792 - val_acc: 0.2859\n",
      "Epoch 3/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 2.2462 - acc: 0.5209 - val_loss: 2.4732 - val_acc: 0.7731\n",
      "Epoch 4/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 1.8758 - acc: 0.6796 - val_loss: 2.1240 - val_acc: 0.8388\n",
      "Epoch 5/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 1.5305 - acc: 0.7346 - val_loss: 2.1016 - val_acc: 0.7504\n",
      "Epoch 6/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 1.4360 - acc: 0.7204 - val_loss: 1.7798 - val_acc: 0.8143\n",
      "Epoch 7/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 1.3334 - acc: 0.7383 - val_loss: 1.9625 - val_acc: 0.8618\n",
      "Epoch 8/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 1.2245 - acc: 0.7801 - val_loss: 2.0236 - val_acc: 0.8409\n",
      "Epoch 9/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 1.1903 - acc: 0.8013 - val_loss: 1.6755 - val_acc: 0.9158\n",
      "Epoch 10/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 1.1747 - acc: 0.8293 - val_loss: 2.0304 - val_acc: 0.9606\n",
      "Epoch 11/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 1.1261 - acc: 0.8103 - val_loss: 2.0398 - val_acc: 0.9692\n",
      "Epoch 12/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 1.0586 - acc: 0.8527 - val_loss: 1.5764 - val_acc: 0.9630\n",
      "Epoch 13/100\n",
      "94042/94042 [==============================] - 21s 227us/step - loss: 1.0354 - acc: 0.8572 - val_loss: 1.5033 - val_acc: 0.9382\n",
      "Epoch 14/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.9943 - acc: 0.8772 - val_loss: 1.7114 - val_acc: 0.9673\n",
      "Epoch 15/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.9957 - acc: 0.8708 - val_loss: 1.3216 - val_acc: 0.8831\n",
      "Epoch 16/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.9626 - acc: 0.8768 - val_loss: 2.2622 - val_acc: 0.9671\n",
      "Epoch 17/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.9376 - acc: 0.8975 - val_loss: 1.5751 - val_acc: 0.9550\n",
      "Epoch 18/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.9036 - acc: 0.9078 - val_loss: 1.4011 - val_acc: 0.9309\n",
      "Epoch 19/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.8884 - acc: 0.8989 - val_loss: 1.4224 - val_acc: 0.9276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.8921 - acc: 0.9068 - val_loss: 1.5986 - val_acc: 0.9511\n",
      "Epoch 21/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.8469 - acc: 0.9157 - val_loss: 1.8261 - val_acc: 0.9669\n",
      "Epoch 22/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.8435 - acc: 0.9063 - val_loss: 1.4167 - val_acc: 0.9279\n",
      "Epoch 23/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.8261 - acc: 0.9125 - val_loss: 1.8166 - val_acc: 0.9627\n",
      "Epoch 24/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.8060 - acc: 0.9184 - val_loss: 1.5327 - val_acc: 0.9386\n",
      "Epoch 25/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.7887 - acc: 0.9225 - val_loss: 1.4136 - val_acc: 0.9196\n",
      "Epoch 26/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7604 - acc: 0.9231 - val_loss: 1.3232 - val_acc: 0.9250\n",
      "Epoch 27/100\n",
      "94042/94042 [==============================] - 21s 222us/step - loss: 0.7540 - acc: 0.9270 - val_loss: 1.5725 - val_acc: 0.9552\n",
      "Epoch 28/100\n",
      "94042/94042 [==============================] - 21s 227us/step - loss: 0.7404 - acc: 0.9216 - val_loss: 1.1751 - val_acc: 0.9375\n",
      "Epoch 29/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7608 - acc: 0.9238 - val_loss: 1.2984 - val_acc: 0.9411\n",
      "Epoch 30/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.7479 - acc: 0.9246 - val_loss: 1.2596 - val_acc: 0.9406\n",
      "Epoch 31/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7176 - acc: 0.9289 - val_loss: 1.3050 - val_acc: 0.9358\n",
      "Epoch 32/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.7232 - acc: 0.9256 - val_loss: 1.4151 - val_acc: 0.9520\n",
      "Epoch 33/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.6985 - acc: 0.9262 - val_loss: 1.2474 - val_acc: 0.9359\n",
      "Epoch 34/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7106 - acc: 0.9263 - val_loss: 1.3704 - val_acc: 0.9450\n",
      "Epoch 35/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.7184 - acc: 0.9219 - val_loss: 1.2349 - val_acc: 0.9347\n",
      "Epoch 36/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.6963 - acc: 0.9288 - val_loss: 1.2272 - val_acc: 0.9302\n",
      "Epoch 37/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.7017 - acc: 0.9297 - val_loss: 1.1065 - val_acc: 0.9226\n",
      "Epoch 38/100\n",
      "94042/94042 [==============================] - 21s 227us/step - loss: 0.6823 - acc: 0.9276 - val_loss: 1.1684 - val_acc: 0.9287\n",
      "Epoch 39/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.6932 - acc: 0.9216 - val_loss: 1.1830 - val_acc: 0.9238\n",
      "Epoch 40/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.6862 - acc: 0.9215 - val_loss: 1.3165 - val_acc: 0.9463\n",
      "Epoch 41/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.6716 - acc: 0.9304 - val_loss: 1.2599 - val_acc: 0.9503\n",
      "Epoch 42/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.6890 - acc: 0.9270 - val_loss: 1.1787 - val_acc: 0.9404\n",
      "Epoch 43/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.6626 - acc: 0.9292 - val_loss: 1.1793 - val_acc: 0.9292\n",
      "Epoch 44/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.6434 - acc: 0.9287 - val_loss: 1.0566 - val_acc: 0.9288\n",
      "Epoch 45/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.6521 - acc: 0.9298 - val_loss: 1.1791 - val_acc: 0.9450\n",
      "Epoch 46/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.6687 - acc: 0.9275 - val_loss: 1.3011 - val_acc: 0.9209\n",
      "Epoch 47/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.6337 - acc: 0.9254 - val_loss: 1.3683 - val_acc: 0.9411\n",
      "Epoch 48/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.6493 - acc: 0.9299 - val_loss: 1.2879 - val_acc: 0.9325\n",
      "Epoch 49/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.6894 - acc: 0.9269 - val_loss: 1.2232 - val_acc: 0.9435\n",
      "Epoch 50/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.6262 - acc: 0.9321 - val_loss: 1.2174 - val_acc: 0.9111\n",
      "Epoch 51/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.6481 - acc: 0.9344 - val_loss: 1.1009 - val_acc: 0.9173\n",
      "Epoch 52/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.6321 - acc: 0.9314 - val_loss: 1.2075 - val_acc: 0.9386\n",
      "Epoch 53/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6303 - acc: 0.9340 - val_loss: 1.0970 - val_acc: 0.9341\n",
      "Epoch 54/100\n",
      "94042/94042 [==============================] - 21s 227us/step - loss: 0.6314 - acc: 0.9288 - val_loss: 1.2189 - val_acc: 0.9407\n",
      "Epoch 55/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.6363 - acc: 0.9332 - val_loss: 1.3631 - val_acc: 0.9384\n",
      "Epoch 56/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.6307 - acc: 0.9308 - val_loss: 1.1520 - val_acc: 0.9285\n",
      "Epoch 57/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.6134 - acc: 0.9344 - val_loss: 1.1455 - val_acc: 0.9280\n",
      "Epoch 58/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.6175 - acc: 0.9320 - val_loss: 1.1917 - val_acc: 0.9285\n",
      "Epoch 59/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.6182 - acc: 0.9326 - val_loss: 1.3128 - val_acc: 0.9386\n",
      "Epoch 60/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.6214 - acc: 0.9222 - val_loss: 1.2601 - val_acc: 0.9424\n",
      "Epoch 61/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.6054 - acc: 0.9289 - val_loss: 1.1890 - val_acc: 0.9341\n",
      "Epoch 62/100\n",
      "94042/94042 [==============================] - 21s 227us/step - loss: 0.6038 - acc: 0.9304 - val_loss: 1.2317 - val_acc: 0.9322\n",
      "Epoch 63/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.6277 - acc: 0.9250 - val_loss: 1.2951 - val_acc: 0.9162\n",
      "Epoch 64/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5979 - acc: 0.9319 - val_loss: 1.3476 - val_acc: 0.9316\n",
      "Epoch 65/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.6036 - acc: 0.9287 - val_loss: 1.1930 - val_acc: 0.9272\n",
      "Epoch 66/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5861 - acc: 0.9349 - val_loss: 1.3109 - val_acc: 0.9284\n",
      "Epoch 67/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5987 - acc: 0.9263 - val_loss: 1.2454 - val_acc: 0.9269\n",
      "Epoch 68/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5816 - acc: 0.9267 - val_loss: 1.2492 - val_acc: 0.9387\n",
      "Epoch 69/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.5849 - acc: 0.9332 - val_loss: 1.3250 - val_acc: 0.9297\n",
      "Epoch 70/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.5939 - acc: 0.9298 - val_loss: 1.0488 - val_acc: 0.9308\n",
      "Epoch 71/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.5832 - acc: 0.9329 - val_loss: 1.1578 - val_acc: 0.9195\n",
      "Epoch 72/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.6042 - acc: 0.9333 - val_loss: 1.4855 - val_acc: 0.9317\n",
      "Epoch 73/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5877 - acc: 0.9356 - val_loss: 1.3599 - val_acc: 0.9317\n",
      "Epoch 74/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5673 - acc: 0.9337 - val_loss: 1.2452 - val_acc: 0.9403\n",
      "Epoch 75/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5690 - acc: 0.9353 - val_loss: 1.0636 - val_acc: 0.9245\n",
      "Epoch 76/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5718 - acc: 0.9291 - val_loss: 1.3598 - val_acc: 0.9236\n",
      "Epoch 77/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5647 - acc: 0.9343 - val_loss: 1.3836 - val_acc: 0.9270\n",
      "Epoch 78/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5829 - acc: 0.9332 - val_loss: 1.4297 - val_acc: 0.9159\n",
      "Epoch 79/100\n",
      "94042/94042 [==============================] - 21s 227us/step - loss: 0.5730 - acc: 0.9337 - val_loss: 1.3574 - val_acc: 0.9292\n",
      "Epoch 80/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5771 - acc: 0.9353 - val_loss: 1.1877 - val_acc: 0.9212\n",
      "Epoch 81/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5540 - acc: 0.9306 - val_loss: 1.1655 - val_acc: 0.9347\n",
      "Epoch 82/100\n",
      "94042/94042 [==============================] - 21s 227us/step - loss: 0.5645 - acc: 0.9341 - val_loss: 1.3186 - val_acc: 0.9467\n",
      "Epoch 83/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5508 - acc: 0.9330 - val_loss: 1.5006 - val_acc: 0.9471\n",
      "Epoch 84/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5726 - acc: 0.9336 - val_loss: 1.1731 - val_acc: 0.9303\n",
      "Epoch 85/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.5720 - acc: 0.9349 - val_loss: 1.2403 - val_acc: 0.9288\n",
      "Epoch 86/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5660 - acc: 0.9288 - val_loss: 1.1241 - val_acc: 0.9177\n",
      "Epoch 87/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.5629 - acc: 0.9332 - val_loss: 1.2091 - val_acc: 0.9290\n",
      "Epoch 88/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5509 - acc: 0.9322 - val_loss: 1.4720 - val_acc: 0.9285\n",
      "Epoch 89/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5647 - acc: 0.9336 - val_loss: 1.4753 - val_acc: 0.9319\n",
      "Epoch 90/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.5490 - acc: 0.9348 - val_loss: 1.4126 - val_acc: 0.9332\n",
      "Epoch 91/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5517 - acc: 0.9340 - val_loss: 1.3259 - val_acc: 0.9244\n",
      "Epoch 92/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5489 - acc: 0.9375 - val_loss: 1.1756 - val_acc: 0.9270\n",
      "Epoch 93/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5608 - acc: 0.9356 - val_loss: 1.2474 - val_acc: 0.9343\n",
      "Epoch 94/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5374 - acc: 0.9336 - val_loss: 1.3050 - val_acc: 0.9280\n",
      "Epoch 95/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.5278 - acc: 0.9372 - val_loss: 1.1980 - val_acc: 0.9248\n",
      "Epoch 96/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5412 - acc: 0.9326 - val_loss: 1.2133 - val_acc: 0.9372\n",
      "Epoch 97/100\n",
      "94042/94042 [==============================] - 21s 225us/step - loss: 0.5435 - acc: 0.9315 - val_loss: 1.2770 - val_acc: 0.9276\n",
      "Epoch 98/100\n",
      "94042/94042 [==============================] - 21s 224us/step - loss: 0.5295 - acc: 0.9359 - val_loss: 1.3322 - val_acc: 0.9257\n",
      "Epoch 99/100\n",
      "94042/94042 [==============================] - 21s 223us/step - loss: 0.5404 - acc: 0.9360 - val_loss: 1.2406 - val_acc: 0.9264\n",
      "Epoch 100/100\n",
      "94042/94042 [==============================] - 21s 226us/step - loss: 0.5280 - acc: 0.9354 - val_loss: 1.2262 - val_acc: 0.9316\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "model_set_name = 'researchset5'\n",
    "w_list = [256]\n",
    "stride_list = [128]\n",
    "rnntype_list = ['lstm','gru'] #['lstm', 'gru']\n",
    "lr_list = [0.0008] #[0.005, 0.001, 0.0005]\n",
    "batchsize_list = [32, 64]\n",
    "drop_coeff_rnn_list = [0.2, 0.35]\n",
    "drop_coeff_dense_list = [0, 0.2]\n",
    "# Construction of data_frame with | model_id | param_1 | ... | param_n | as columns\n",
    "\n",
    "info_list = list()\n",
    "model_id = 1\n",
    "for w in w_list:\n",
    "    for stride in stride_list:\n",
    "        for rnntype in rnntype_list:\n",
    "            for lr in lr_list:\n",
    "                for batchsize in batchsize_list:\n",
    "                    for drop_rnn in drop_coeff_rnn_list:\n",
    "                        for drop_dense in drop_coeff_dense_list:\n",
    "                            #if (drop_rnn == 0.2 and drop_dense == 0):\n",
    "                            #    print('dropout_rnn == 0.2 and dropout_dense == 0 jumped'.format())\n",
    "                            #    continue\n",
    "                            print([model_id, w, stride, rnntype, lr, batchsize, drop_rnn, drop_dense, False, False])\n",
    "                            info_list.append([model_id, w, stride, rnntype, lr, batchsize, drop_rnn, drop_dense, False, False])\n",
    "                            model_id += 1\n",
    "\n",
    "info_dataframe = pd.DataFrame(info_list, columns = ['model_id', 'w', 'stride', 'rnn_type', 'lr', 'batch_size', 'rnn_dropout', 'dense_dropout', 'two_rnn_layers', 'first_dense'])\n",
    "\n",
    "## Saving the dataframe\n",
    "info_dataframe.to_csv(model_set_name + '_research_summary.csv', index=False)\n",
    "\n",
    "model_id = 1\n",
    "for w in w_list:\n",
    "    for stride in stride_list:\n",
    "        for rnntype in rnntype_list:\n",
    "            for lr in lr_list:\n",
    "                for batchsize in batchsize_list:\n",
    "                    for drop_rnn in drop_coeff_rnn_list:\n",
    "                        for drop_dense in drop_coeff_dense_list:\n",
    "                            #if (drop_rnn == 0.2 and drop_dense == 0):\n",
    "                            #    print('dropout_rnn == 0.2 and dropout_dense == 0 jumped'.format())\n",
    "                            #    continue\n",
    "                            results = trainRNNModel(dataTrWinValues[:,:,:3], dataTrWinLabel, dataTestWinValues[:,:,:3], dataTestWinLabel, epochs = 100, lr=lr, w = w, stride = stride, batch_size = batchsize, rnn_type = rnntype, two_rnn_layers=False, drop_coeff_rnn=drop_rnn, drop_coeff_dense=drop_dense, first_dense=False)\n",
    "                            train_info = results[1].history\n",
    "                            eval_info = results[2]\n",
    "                            model_performance_info = { 'train_history' : train_info, 'eval_results' : eval_info, 'optional_data' : 'n_test_subjects=8, w=256, stride=128'}\n",
    "                            # Saving both model and performance_info\n",
    "                            np.save(model_set_name + '_model_id_' + str(model_id) + '_info.npy', model_performance_info)\n",
    "                            results[0].save(model_set_name + '_model_id_' + str(model_id) + '_fullmodel.h5')\n",
    "                            model_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "\n",
    "research_set_folder = 'researchset5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>w</th>\n",
       "      <th>stride</th>\n",
       "      <th>rnn_type</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>rnn_dropout</th>\n",
       "      <th>dense_dropout</th>\n",
       "      <th>two_rnn_layers</th>\n",
       "      <th>first_dense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>32</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>32</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>64</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>64</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>64</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>lstm</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>64</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>gru</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>gru</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>gru</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>32</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>gru</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>32</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>gru</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>64</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>gru</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>64</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>gru</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>64</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>gru</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>64</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_id    w  stride rnn_type      lr  batch_size  rnn_dropout  \\\n",
       "0          1  256     128     lstm  0.0008          32         0.20   \n",
       "1          2  256     128     lstm  0.0008          32         0.20   \n",
       "2          3  256     128     lstm  0.0008          32         0.35   \n",
       "3          4  256     128     lstm  0.0008          32         0.35   \n",
       "4          5  256     128     lstm  0.0008          64         0.20   \n",
       "5          6  256     128     lstm  0.0008          64         0.20   \n",
       "6          7  256     128     lstm  0.0008          64         0.35   \n",
       "7          8  256     128     lstm  0.0008          64         0.35   \n",
       "8          9  256     128      gru  0.0008          32         0.20   \n",
       "9         10  256     128      gru  0.0008          32         0.20   \n",
       "10        11  256     128      gru  0.0008          32         0.35   \n",
       "11        12  256     128      gru  0.0008          32         0.35   \n",
       "12        13  256     128      gru  0.0008          64         0.20   \n",
       "13        14  256     128      gru  0.0008          64         0.20   \n",
       "14        15  256     128      gru  0.0008          64         0.35   \n",
       "15        16  256     128      gru  0.0008          64         0.35   \n",
       "\n",
       "    dense_dropout  two_rnn_layers  first_dense  \n",
       "0             0.0           False        False  \n",
       "1             0.2           False        False  \n",
       "2             0.0           False        False  \n",
       "3             0.2           False        False  \n",
       "4             0.0           False        False  \n",
       "5             0.2           False        False  \n",
       "6             0.0           False        False  \n",
       "7             0.2           False        False  \n",
       "8             0.0           False        False  \n",
       "9             0.2           False        False  \n",
       "10            0.0           False        False  \n",
       "11            0.2           False        False  \n",
       "12            0.0           False        False  \n",
       "13            0.2           False        False  \n",
       "14            0.0           False        False  \n",
       "15            0.2           False        False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_set_table = pd.read_csv(research_set_folder + '/' + research_set_folder + '_research_summary.csv')\n",
    "research_set_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent model results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n_test_subjects=8, w=256, stride=128'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_model_info = np.load(research_set_folder + '/' + research_set_folder +  '_model_id_10_info.npy')\n",
    "ex_model_info = ex_model_info[()]\n",
    "ex_model_info['optional_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Train history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_history = ex_model_info['train_history']\n",
    "plt.plot(train_history['val_loss'])\n",
    "plt.show()\n",
    "plt.plot(train_history['val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Evaluation with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.94 0.05 0.01]\n",
      " [0.1  0.85 0.05]\n",
      " [0.   0.04 0.95]]\n",
      "Confusion matrix, without normalization\n",
      "[[20723  1042   202]\n",
      " [   34   290    18]\n",
      " [    1    28   608]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAEmCAYAAAAqWvi2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XeYVEXWx/HvDxAQAQFBHZKgIqioJIE1r66IATELooIB1DW7q2JaMa0Jc1x9DWAA84qKsphFAQmCWUFFyVkBE+m8f1Q1NuOEnqGnu2fmfHjuM911U3X3cKb63LpVMjOcc85lTpVsV8A55yobD7zOOZdhHnidcy7DPPA651yGeeB1zrkM88DrnHMZ5oG3AJI2lvSSpJ8kPbMBx+kj6X/prFu2SNpT0le5cj5JLSSZpGqZqlN5IWmGpL/Fx5dK+r8yOMf9kq5I93ErC5XnfrySjgMuANoAy4EpwHVmNmYDj3sCcDawm5mt3uCK5jhJBrQys+nZrkthJM0ATjWz1+PzFsB3wEbp/owkPQrMMrPL03ncTMn/XqXheP3i8fZIx/FcOW7xSroAuB34N7AF0By4F+iZhsNvBXxdGYJuKrxVWXb8va2kzKzcLcCmwArg6CK2qUEIzHPicjtQI67bB5gF/ANYAMwFTorrrgJWAqviOU4BBgGPJx27BWBAtfi8H/AtodX9HdAnqXxM0n67AROAn+LP3ZLWvQ1cA7wfj/M/oGEhry1R/4uS6n8YcBDwNbAEuDRp+87AWODHuO3dQPW47t34Wn6Or/fYpONfDMwDHkuUxX22iefoEJ83BhYB+6Tw2Q0B/hEfN4nn/nt8vm08rvKd7zFgLfBrrONFSZ9BX+CHeP7LUvz81/tcYpnF8w+In/3KeK6XCnkdBpwOTAOWAvfwxzfIKsDlwPfx8xkKbJrvd+eUWO93k8pOAmbG450O7Ap8HD+3u5POvQ3wJrA4vu4ngHpJ62cAf4uPBxF/d+PnviJpWQ0MiusGAt8Qfvc+Bw6P5dsDvwFr4j4/xvJHgWuTztkfmB4/vxFA41Teq8q6ZL0Cpao0dI+/NNWK2OZqYBywOdAI+AC4Jq7bJ+5/NbARIWD9AtTP/8tayPPEf5RqwCbAMqB1XJcH7Bgf9yP+BwcaxF+6E+J+vePzzeL6t+Mv/nbAxvH5DYW8tkT9/xXr3x9YCDwJ1AF2jP9Zto7bdwS6xvO2AL4Azks6ngHbFnD8GwkBbGOSAmHcpn88Ti1gFDA4xc/uZGIwA46Lr/mppHUvJtUh+XwziMEk32fwYKzfLsDvwPYpfP7rPpeC3gPyBZVCXocBLwP1CN+2FgLdk17HdGBroDbwPPBYvnoPJfzubJxUdj9QE+gWP7//xvo3IQTwveMxtgX2j59NI0Lwvr2g94p8v7tJ27SLdW4fnx9N+ANahfDH92cgr4j3a917BOxL+APQIdbpLuDdVN6ryrqU11TDZsAiKzoV0Ae42swWmNlCQkv2hKT1q+L6VWY2kvDXvHUp67MWaCtpYzOba2afFbDNwcA0M3vMzFab2TDgS6BH0jaPmNnXZvYr8DThP0dhVhHy2auA4UBD4A4zWx7P/xmwM4CZTTKzcfG8M4D/AHun8JquNLPfY33WY2YPElow4wl/bC4r5ngJ7wB7SqoC7AXcBOwe1+0d15fEVWb2q5lNBaYSAjAU//mnww1m9qOZ/QC8xR+fVx/gVjP71sxWAJcAvfKlFQaZ2c/53ttrzOw3M/sfIfANi/WfDbwHtAcws+lmNjp+NguBWyn+81xHUiNCUD/bzD6Kx3zGzOaY2Voze4rw2XZO8ZB9gIfNbLKZ/R5f719iHj6hsPeqUiqvgXcx0LCY/Fhjwle9hO9j2bpj5AvcvxBaJyViZj8TWginA3MlvSKpTQr1SdSpSdLzeSWoz2IzWxMfJ/7zzk9a/2tif0nbSXpZ0jxJywh58YZFHBtgoZn9Vsw2DwJtgbvif7himdk3hD9y7YA9CS2hOZJaU7rAW9h7Vtznnw4lOXc1wrWIhJkFHC//51fY57m5pOGSZsfP83GK/zyJ+24EPAs8aWbDk8pPlDRF0o+SfiR8rikdk3yvN/6xWUzpf7crvPIaeMcSvoodVsQ2cwgXyRKax7LS+JnwlTphy+SVZjbKzPYntPy+JASk4uqTqNPsUtapJO4j1KuVmdUFLiXkUYtSZHcXSbUJedOHgEGSGpSgPu8ARxHyzLPj8xOB+oSeKSWuTwGK+vzX+zwlrfd5luJcqZx7NesH0g05x/Vx/53j53k8xX+eCXcR8rjremxI2orwO3sWIfVVD/g06ZjF1XW91ytpE8K30kz8bpdL5TLwmtlPhPzmPZIOk1RL0kaSDpR0U9xsGHC5pEaSGsbtHy/lKacAe0lqLmlTwlcpACRtIenQ+Mv2O6E1t6aAY4wEtpN0nKRqko4FdiC0+MpaHUIeekVsjZ+Rb/18Qj6yJO4AJpnZqcArhPwkAJIGSXq7iH3fIfwnfzc+f5vQfW9MUis+v5LWsajPfyqwo6R2kmoS8qAbcq6Czn2+pJbxD9S/CXnsdPWSqUO80CWpCXBhKjtJOo3wreI4M1ubtGoTQnBdGLc7idDiTZgPNJVUvZBDPwmcFN/PGoTXOz6mtVwBymXgBTCzWwl9eC8n/MLMJPxn/m/c5FpgIuGq8CfA5FhWmnONBp6Kx5rE+sGyCqF3xBzCFd29gb8XcIzFwCFx28WEK/OHmNmi0tSphP5JuJC1nNCyeSrf+kHAkPg185jiDiapJ+EC5+mx6AKgg6Q+8XkzQu+MwrxDCB6JwDuG0AJ9t9A9Qivv8ljHfxZXR4r4/M3sa8LFt9cJucz8/b4fAnaI5/ovJfcwoSfGu4ReLr8R/rCky1WEC1k/Ef7oPZ/ifr0Jf1DmSFoRl0vN7HPgFsI3yfnATqz/+b1JuGYwT9Kffl/N7A3gCuA5Qq+ZbYBepXlhlUW5voHC5SZJU4D94h8b51w+Hnidcy7Dym2qwTnnyisPvM45l2EeeJ1zLsMq3QAdqraxqXqdbFcjJ+3cplm2q5DTqijVrrKVzw/fz2DRokVpe4Oq1t3KbPWfbpgskP26cJSZdU/XuTOh8gXe6nWo0brYHlOV0pvv3Z7tKuS0mhtVzXYVctYef9k1rcez1b+m/P/0tyn3pHqHXc6odIHXOVceCFRxM6EeeJ1zuUdAlYr7DcMDr3MuN1XgnHrFbcs758qxmGpIZSnuSFIzSW9J+kLSZ5LOjeUNJI2WNC3+rB/LJelOSdMlfSypQ9Kx+sbtp0nqm1TeUdIncZ87paL/anjgdc7lJim1pXirCbOebE+YEOBMSTsQZt14w8xaAW/E5wAHAq3iMoAwuh9xBL4rgS6EsYqvTATruM2ApP2K7GXhgdc5l3tE2lq8cXKCyfHxcsLMKU0I8zMOiZsN4Y9hZnsCQy0YB9STlAccAIw2syVmthQYDXSP6+qa2VgLYzAMpeghaz3H65zLRSrJxbWGkiYmPX/AzB4o8KhhVoz2hJlTtjCzuRCCs6TN42ZNWH+g+lmxrKjyWQWUF8oDr3MuN6V+cW2RmXUq/nCqTRi68jwzW1ZEGragFVaK8kJ5qsE5l4PSd3EN1k159BzwhJklxi+eH9MExJ8LYvkswpjSCU0J420XVd60gPJCeeB1zuUekbaLa7GHwUPAF3EChYQRQKJnQl/gxaTyE2Pvhq7ATzElMQroJql+vKjWDRgV1y2X1DWe68SkYxXIUw3OudyUvjvXdifMMP1JHKQfwryDNwBPSzoF+IEwxT2EaboOAqYTJuY8CcDMlki6BpgQt7vazJbEx2cQprzfGHg1LoXywOucy0GCqum5c83MxlD4ZKD7FbC9AWcWcqyHCVM75S+fyPrz1BXJA69zLvckupNVUB54nXO5qQLfMuyB1zmXg3x0Muecyzxv8TrnXAapRHeulTseeJ1zuclTDc45l2GeanDOuUzyi2vOOZd53uJ1zrkMkqBKxQ1PFfeVOefKN2/xOudchnmO1znnMsxbvM45l0HyXg3OOZdxqlJxA2/FfWUZ0nSLerz2wDl89NzlTHr2Ms7svQ8A9evW4uX7zuKTF//Fy/edRb06GwNw/on7MW74QMYNH8jEZy5lxcQ7qV+3VqHHAfjX3w/mw6cuYdzwgbx075nkNdo0C690w519xqm0btGY3Xdtt65s6ZIlHNGjO7vusj1H9OjOj0uXrrfP5EkTaFS3BiNeeA6ATz6ewgH77sFunXZhzy7teeHZpzP6GjJh1syZHNhtXzrsvAOd2rXlnrvuAGDJkiUccmA3dt5hOw45sBtL43s1fNgTdO64C5077sK+e+/Oxx9PzWb10yJMQKGUlvJIYczfyqNKrc2tRutj0na8LRvWZcuGdZny5Sxq16rBB09ezDEXPMAJPbqwdNkvDH5kNP88aX/q1anF5XeuPxvIQXu15ew+f+XA0+4q9DhffjuPOpvUZPnPvwHw995702brPM65bnjaXkPC7DG3p/2YyT4Y8x6b1N6Ev/c/mfcnhIkABl0+kHr1G3DePy7i9ltu4scflzLomusBWLNmDUf06E7NmjXpc0I/Dj38SKZP+xpJbLNtK+bOncN+e3Rh7KRP2LRevTKtO0DNjTIzdsDcuXOZN28u7dt3YPny5ezRtRPDn32Bx4c+Sv0GDfjnhQMZfPMN/Lh0Kdf++0bGjf2A1m22p379+ox67VX+fe1VvDNmXEbqmrDHX3Zl8qSJaYuCVRu0sJr7XZnStr88e/Kkoia7lPQwcAiwwMzaxrKngNZxk3rAj2bWLs5C/AXwVVw3zsxOj/t05I9ZJkYC55qZSWoAPAW0AGYAx8Tp3wvlLd4NNG/RMqZ8GWZ2XvHL73z53TwaN6rHIfvszOMvjQfg8ZfG0+OvO/9p32O6d+Lp1yYVeRxgXdAFqLVxDcrrH8vd9tiT+vUbrFc28pWX6NXnBAB69TmBkS+PWLfuwfvvpkfPw2nYqNG6sm1bbcc227YCIC+vMQ0bNWLRooUZqH3m5OXl0b59BwDq1KlD6zbbM2f2bF55aQR9jg9ThPU5vi8vjwh/yLv+ZTfq168PQOcuXZk9e1bBBy5XUmvtptjifRTonlxgZseaWTsza0eYBPP5pNXfJNYlgm50HzAAaBWXxDEHAm+YWSvgjfi8SB5406h5XgPatW7KhE9nsPlmdZi3aBkQgmqjBnXW23bjmhux/27b8983phR5nIRBZ/Zg2qvX0OvATlxz3ytl+joyaeGC+Wy5ZR4AW26Zx6KFYaLXOXNm88qIFznp1NMK3XfSxA9ZuXIVLbfeJiN1zYbvZ8xg6tSP2LVzFxYsmE9eXniv8vLyWLhwwZ+2H/LIQ3Q7oPufysujdAVeM3sXWFLQujg55THAsGLqkgfUNbOxcWqgocBhcXVPYEh8PCSpvFA5EXglrZE0RdJUSZMl7RbLW0j6NGm7/nF9/fj8AklfSvok7ntrnMY54zbZuDrDBp/KhYOfW6+FWpiD99qJsVO+ZemyX1I6zqB7XqLVgVcw/NWJnH7sXmmvf6657KJ/8K9r/k3VQubdmjdvLmf0P4m77n+QKhX0IsyKFSs4rtdR3DT4NurWrVvs9u+8/RZDH32Ya667MQO1K3sZyvHuCcw3s2lJZS0lfSTpHUl7xrImhGncE2bFMoAt4kzDxJ+bF3fSXPmN/TU263cBLgGuz7+BpBOAs4FuZrZU0umE6ZW7mtlOwK7AAkL+JaOqVavCsMH9eerVibz4ZriwsWDxcrZsGP6zbNmwLguXLF9vn6MP6MgzMc1Q1HHye/rVCRy2X7sC15VHjTbfgnnz5gIhmDZsFH5np3w0if79jqfdDtvy0n+f58Lzz+aVl8JX62XLltH7yEO57Iqr2LVz16zVvSytWrWK4449imN7HUfPw44AYPPNt2Du3PBezZ07l0aN/vj//cknH3Pm6f156tn/stlmm2WlzmklUBWltAANJU1MWgaU4Ey9Wb+1OxdobmbtgQuAJyXVpeDJMkud88uVwJusLrBeYlrSMYS8STczWxSLLwPOMLMfAcxspZndYGbLMlpb4P4r+/DVd/O48/E315W98s4nHN+jCwDH9+jCy29/vG5d3do12aPjtryUVFbYcQC2af5HjvPgvXfm6xnzy+JlZMWBBx3C8CceA2D4E49x0ME9APjos2lM+Xw6Uz6fTo/DjuDm2+7i4B49WblyJSf2Popjjzuenkcclc2qlxkz44zTTqV1mzacc94F68oPOqQHTzwevtE+8fgQDu5xKAAzf/iB4445kv97ZCitttsuK3VON5Usx7vIzDolLQ+kdA6pGnAE4cIYAGb2u5ktjo8nAd8A2xFauE2Tdm8KzImP58dURCIl8eccUD650o934zjffU0gD9g3ad1WwN1AezObByCpDlDbzL5L5eDxL2D4K7hR7TRWG3ZrtzV9DunCJ1/PZtzwkFO/8u4RDH5kNI/feDJ9D/sLM+cupc9FD63b59C/7sIb477kl99WFnucUWM+59pzetJqq81Zu9b4Ye6SMunRkAn9+x3P+++9w+LFi2i7XQsGXvYvzr3gIk4+sTdPDH2EJk2b8chjRb+2/z7/DGPff4+lSxYz7PGhANz9n4fYaeeK8y1g7AfvM+yJx9ix7U503bU9AIOuvo5/XDiQE447lqGPPEzTZs15fFjoSnf9v69myZLFnHdOmJG8WrVqjBk7IWv1T5cMdBX7G/Clma1LIUhqBCwxszWStiZcRPvWzJZIWi6pKzAeOBG4K+42AugL3BB/rt99qQA50Z1M0gozqx0f/wX4P8Ic9VsBbxIS40+Y2W1xm7rADDNrEJ8fANxI6BZynJl9UNi50t2drCIp6+5k5V2mupOVR+nuTlZts62t7kHXprTt0sf7FNedbBiwD9AQmA9caWYPSXqU0F3s/qRtjwSuBlYDa+K2L8V1nfijO9mrwNmxO9lmwNNAc+AH4GgzK/Bi3rrXl9IryyAzGyupIZD4fv0LcCAwRtICM3vCzJZJ+llSSzP7zsxGAaMkvQxUz1bdnXPpk64Wr5n1LqS8XwFlzxG6lxW0/URCgzB/+WJgv5LUKedyvJLaAFWBxYkyM1tI6DP379i6hXAB7j5J9eJ+IqQqnHPlXckurpU7udLiTeR4IVw97BtzLOs2MLPvJB0KjJR0BKEzcy1gvKTfgRXA+8BHma26cy7dEhfXKqqcCLxmVmDyzMxmkNS0N7Op/NF3DmBwXJxzFYwHXuecy7SKG3c98DrncpC8xeuccxlXUW8FBw+8zrkc5BfXnHMuGypu3PXA65zLQZ7jdc65zPPA65xzGVZe70pLhQde51xO8havc85lUHmeQTgVHnidcznJA69zzmWYB17nnMswv7jmnHOZVMH78Vbcm6Gdc+WWACm1pdhjSQ9LWiDp06SyQZJmS5oSl4OS1l0iabqkr5ImXkBS91g2XdLApPKWksZLmibpKUnFzoLjgdc5l4NKNMtwcR4lzGCT321m1i4uIwEk7QD0AnaM+9wrqaqkqsA9hGnIdgB6x20hzPd4m5m1IsyQfkpxFfLA65zLSelq8ZrZu4QJc1PRExgep3n/DpgOdI7LdDP71sxWAsOBnnHKsX2BZ+P+Q4DDijuJB17nXO4RVKmilJYNcJakj2Mqon4sawLMTNpmViwrrHwz4EczW52vvEgeeJ1zOUeUKPA2lDQxaRmQwinuA7YB2gFzgVuSTp2flaK8SN6rwTmXk0rQqWGRmXUqybHNbP4f59GDwMvx6SygWdKmTYE58XFB5YuAepKqxVZv8vaF8havcy4npfHiWkHHzkt6ejiQ6PEwAuglqYaklkAr4ENgAtAq9mCoTrgAN8LMDHgLOCru3xd4sbjze4vXOZd7UrxwltKhpGHAPoSUxCzgSmAfSe0IaYEZwGkAZvaZpKeBz4HVwJlmtiYe5yxgFFAVeNjMPounuBgYLula4CPgoeLq5IHXOZdzhNI255qZ9S6guNDgaGbXAdcVUD4SGFlA+beEXg8p88DrnMtJFfjGNQ+8zrncVJFvGfbA65zLPWnM8eYiD7zOuZwTxmqouJHXA69zLidt4F1pOc0Dr3MuJ1XgBm/lC7ztt2/O++PvznY1ctKatcXe6VipVeQW2IZK+ztTwcfjrXSB1zmX+xLj8VZUHnidcznIZxl2zrmMq8ipHQ+8zrnc4/14nXMus7wfr3POZYEHXuecy7AKHHc98DrncpD84ppzzmWUvDuZc85lXgWOuz7nmnMuN1WRUlqKE6dvXyDp06SymyV9Gad3f0FSvVjeQtKvkqbE5f6kfTpK+kTSdEl3KjbJJTWQNFrStPiz/p9rke+1leodcc65MialtqTgUaB7vrLRQFsz2xn4Grgkad03ZtYuLqcnld8HDCBMgNkq6ZgDgTfMrBXwRnxepEIDr6S6RS3FHdg550pLSt8sw2b2LrAkX9n/4nTsAOMI07IXUR/lAXXNbGycWXgocFhc3RMYEh8PSSovVFE53s8IM3Amv7LEcwOaF3dw55wrraqp92poKGli0vMHzOyBEpzqZOCppOctJX0ELAMuN7P3gCbArKRtZsUygC3MbC6Amc2VtHlxJyw08JpZsxJU3Dnn0qoEF9cWmVmn0p1DlxGmcX8iFs0FmpvZYkkdgf9K2pGCR74s9TiqKeV4JfWSdGl83DRWyDnnyoSIXcpS+Ffqc0h9gUOAPjF9gJn9bmaL4+NJwDfAdoQWbnI6oikwJz6eH1MRiZTEguLOXWzglXQ38FfghFj0C3B/4Xs459yGq6LUltKQ1B24GDjUzH5JKm8kqWp8vDXhItq3MZWwXFLX2JvhRODFuNsIoG983DepvFCp9OPdzcw6xJwHZrZEUvXUXp5zzpVCihfOUjuUhgH7EHLBs4ArCb0YagCj43nGxR4MewFXS1oNrAFON7PEhbkzCD0kNgZejQvADcDTkk4BfgCOLq5OqQTeVZKqEPMZkjYD1qawn3POlYoo0cW1IplZ7wKKHypk2+eA5wpZNxFoW0D5YmC/ktQplRzvPbEijSRdBYwBbizJSZxzrqTS2I835xTb4jWzoZImAX+LRUeb2adF7eOccxvKx2qAqsAqQrrB73ZzzpWp8tyaTUUqvRouA4YBjQldKJ6UdEnReznn3IZJ11gNuSiVFu/xQMdElwtJ1wGTgOvLsmLOucqtvAbVVKQSeL/Pt1014NuyqY5zzoVeDRV4HPTCA6+k2wg53V+AzySNis+7EXo2OOdc2UhjP95cVFSLN9Fz4TPglaTycWVXHeecCypw3C1ykJwCOxg751wmVOQWbyq9GraRNDyO1P51YslE5SqS3377jT3+0pnOHXahwy47cs1VV663/vxzz6ZhvdpZql3mzZo5kwO77UuHnXegU7u23HPXHQB88vFU9t1rNzp32JmjDz+UZcuWrdtn8E3Xs/P2rWjftg2v/29UtqqecaedejLNG29Ox3Z/3DQ1dcoU9tq9K106tmP3Lp2Y8OGHWaxh+iXuXEtlKY9S6ZP7KPAI4b04EHgaGF6GdaqQatSowWuj3+TDyVMZP3EK/xv1GuPHhazNpIkT+enHH7Ncw8yqVq0a1984mMkff85b743lwfvv5YsvPufM0/tz1bXX8+Hkj+nR8zBuv/VmAL744nOeffopJkz5lBdeepXzzzmTNWvWZPlVZMYJffvx4suvrVd22SUXcdkVVzJ+0hSuGHQ1l11yUZZqV3aU4lIepRJ4a5nZKAAz+8bMLieMVuZKQBK1a4cW7apVq1i9ahWSWLNmDZcOvJDrbrgpyzXMrC3z8mjXvgMAderUoXWb7Zk7ezbTvv6KPfbcC4B999ufF194HoBXXnqRo445lho1atCiZUu23mZbJk6oWK28wuyx5140aNBgvTJJ674N/PTTT+Q1bpyNqpUZyfvx/h6HQftG0unAbKDYEdbdn61Zs4bdOnfkm2+mc9oZZ9K5SxfuvvMODj7kUPLy8rJdvaz5fsYMpk79iE6du7DDjm155aURHHJoT1547hlmz5oJwJzZs+ncpeu6fZo0bcKcObOzVeWsu/mW2+lx8AFccvE/Wbt2LW+9+0G2q5R25TSmpiSVFu/5QG3gHGB3oD9hqoxiSTpckklqE5+3SJ7pM2m7RyV9lzSz5wexvJ+khbHsS0nnx/LLkrZdk/T4nNRednZUrVqV8ZOmMH3GLCZO+JAx773L8889w9/POjvbVcuaFStW0KfXUdw4+Dbq1q3Lvf95iAfuv5c9unZi+YrlVK8eRiCN41SvpyJffCnOA/+5j5sG38b072Zy0+DbOGPAKdmuUtqla861XJTKIDnj48Pl/DEYeqp6E/r89gIGFbPthWb2bAHlT5nZWXE4yq8kPWtm1wHXAUhaYWbtSlivrKpXrx577b0P77z9Ft9+M50d22wLwC+//MKObbblsy+nZ7mGmbFq1Sr6HHsUx/Y6jp6HHQFA6zZtGDEyXDib9vXXjHp1JABNmjZlVmz9AsyeNZu8vIr19boknnhsCLfcFi5IHnnU0fz9tFOzXKP0EuX3wlkqippl+AVJzxe2FHdgSbUJLeRTCIF3g8QxL6cD5fI7+cKFC/kxXkD79ddfefON12nfoSMzZs3jq+kz+Gr6DGrVqlVpgq6Z8ffTTqV1mzacfd4F68oXLAizpqxdu5abbriOU/qfBsBBhxzKs08/xe+//86M777jm+nT6LRr56zUPRfkNW7Me+++A8Dbb73Jttu2ynKN0izFISHLaYO3yBbv3Rt47MOA18zsa0lLJHUg3xTL+dws6fL4+DMz65O8UlJzoCbwcUkrImkAMACgWfPsTI48b+5c+p/clzVr1rDW1nLkUcdw0MGHZKUuuWDsB+8z7InH2LHtTvxl1/YADLr6OqZPn8aD998LwKGHHc4JfU8CYIcdduSIo46m0y47Uq1aNW69426qVq2atfpn0onH9+a9d95m0aJFbNOiKVf86yruue9BLrzgXFavXk2NmjW5+76STKpbPpTXNEIqVFDuLC0Hll4Bbjez0TH32owwqPrLZtY237aPxvJn85X3A24mTB7XGuhvZo/k22aFmaXcAbZjx072/viJxW9YCa1ZWza/CxVFRf7qu6HOZ6eUAAAZ3klEQVR279KJSZMmpu0N2nzbtnbszc+ktO3dR+wwqahZhiU9TJjUckEi9khqQJjSvQUwAzjGzJbGjgR3AAcRhkvoZ2aT4z59gUTj8FozGxLLO/LHlEAjgXOtmMBaJmPrxnzsvsD/SZoBXAgcS+m63T1lZjsCewK3SNoybRV1zuUkkdaLa48C3fOVDQTeMLNWwBvxOYR7FVrFZQBwH6wL1FcCXYDOwJWS6sd97ovbJvbLf64/KatBzY8ChprZVmbWwsyaAd+x/vTIJWJmY4HHgHPTVEfnXA6rViW1pThm9i5/TnP2BIbEx0MIqdFE+VALxgH14pTtBwCjzWyJmS0FRgPd47q6ZjY2tnKHJh2rUCkHXkk1Ut2W0JvhhXxlzwGXAq0lzUpaEjNy3pzULWxKITMZ3wicJKlOCerinCtnwoWzlFu8DSVNTFoGpHCKLeKU7cSfiXsTmgAzk7abFcuKKp9VQHmRiu1OJqkzYUbOTYHmknYBTjWzQjufmtk+BZTdCdxZyC6FJXMejUviGHOA9VINJcnvOufKjxKk1BcVleMtoYLOaqUoL1IqLd47CYnpxQBmNhW/Zdg5V8bKuDvZ/JgmIP5cEMtnEToCJDQF5hRT3rSA8iKlEnirmNn3+coqx+gkzrmsCDNQlOlYDSOAvvFxX+DFpPITFXQFfoqpiFFAN0n140W1bsCouG65pK6xR8SJSccqVCpjNcyM6QaTVBU4G/BhIZ1zZapqmjqnSRoG7EPIBc8i9E64AXha0inAD0DiWtNIQley6YTuZCcBmNkSSdcAE+J2V5tZ4oLdGfzRnezVuBQplcB7BiHd0ByYD7wey5xzrkwojSOPmVnvQlbtV8C2BpxZyHEeBh4uoHwi0PbPexQulbEaFpCGW36dc64kKvCNayn1aniQAq7SmVkqXTacc65UKvKNgqmkGl5PelwTOJz1+7M551xaJS6uVVSppBqeSn4u6THCXRvOOVc2BFXL6r7aHJBKize/lsBW6a6Ic84lU7mdUa14qeR4l/JHjrcK4Z7ngYXv4ZxzGyakGrJdi7JTZOCNHYJ3IcyzBrC2uOHOnHMuHSpy4C0yixKD7AtmtiYuHnSdcxlRkedcSyV9/WGcPcI55zJC8eJaKkt5VGiqQVI1M1sN7AH0l/QN8DMh/WJm5sHYOVdmKmt3sg+BDqQwqK9zzqVTZb64JgAz+yZDdXHOuXUqcIO3yMDbSNIFha00s1vLoD7OOQeIKpW0H29VoDalm6DSOedKLUx2me1alJ2iAu9cM7s6YzVxzrkEQbUKnOQtNsfrnHOZVplbvH8aJNg55zKlIncnK7T7cdK0Fs45l3HpmuxSUmtJU5KWZZLOkzRI0uyk8oOS9rlE0nRJX0k6IKm8eyybLqnUY9aUZnQy55wrUyK122pTYWZfAe0A4ryRs4EXCPOp3WZmg9c7t7QDYdadHYHGwOuStour7wH2J8wuPEHSCDP7vKR18sDrnMs9KrNUw37AN2b2fRHjPPQEhpvZ78B3kqYDneO66Wb2LYCk4XHbEgfecnqns3OuIivh9O4NJU1MWoqalqwXMCzp+VmSPpb0cJy2HaAJ68+yMyuWFVZeYh54nXM5SSkuwCIz65S0PFDg8aTqwKHAM7HoPmAbQhpiLnBL0qnzsyLKS8xTDc65nFQGmYYDgclmNh8g8TOcSw8CL8ens4BmSfs1BebEx4WVl4i3eJ1zOSi1sXhLOB5vb5LSDJLyktYdDnwaH48AekmqIakl0IowaNgEoJWklrH13CtuW2Le4nXO5RwBVdPY5JVUi9Ab4bSk4psktSOkC2Yk1pnZZ5KeJlw0Ww2caWZr4nHOAkYRhlR42Mw+K019PPC6dapW4Fs002Hl6rXZrkLOKot3Jp2/jWb2C7BZvrITitj+OuC6AspHAiM3tD4eeJ1zuUeU22l9UuGB1zmXc9J5A0Uu8sDrnMtJ3uJ1zrkMq8iXHDzwOudyTkg1VNzI64HXOZeTKnCmwQOvcy4XCXmL1znnMstbvM45l0FSeu9cyzUeeJ1zOakCx10PvM653OQ5Xuecy6AwEHq2a1F2PPA653KSt3idcy7DKvL07h54nXM5x1MNzjmXcX4DhXPOZZYqdneyijzkpXOuHCvBLMPFH0uaIekTSVMkTYxlDSSNljQt/qwfyyXpTknT49TvHZKO0zduP01S39K+Ng+8zrmck5hzLZWlBP5qZu3MrFN8PhB4w8xaAW/E5xBmI24VlwGEaeCR1AC4EugCdAauTATrkvLA65zLTels8hasJzAkPh4CHJZUPtSCcUC9OCPxAcBoM1tiZkuB0UD30pzYA69zLicpxX9AQ0kTk5YBBRzOgP9JmpS0fgszmwsQf24ey5sAM5P2nRXLCisvMb+45pzLSSXIIixKSh8UZnczmyNpc2C0pC+LOnUBZVZEeYl5i9c5l5PSmWkwsznx5wLgBUKOdn5MIRB/LoibzwKaJe3eFJhTRHmJeeB1zuUcESa7TGUp9ljSJpLqJB4D3YBPgRFAomdCX+DF+HgEcGLs3dAV+CmmIkYB3STVjxfVusWyEvNUg3Mu96S3H+8WwAsxSFcDnjSz1yRNAJ6WdArwA3B03H4kcBAwHfgFOAnAzJZIugaYELe72syWlKZCHnidczkpXXHXzL4FdimgfDGwXwHlBpxZyLEeBh7e0Dp54HXO5aYKfOeaB17nXA7ysRqccy6jKvroZN6rIQtOO/VkmjfenI7t2ma7Kjlh5syZHPC3v9Jup+3psMuO3H3nHQBMnTKFvXbvSpeO7di9SycmfPhhlmuaOT/++CMn9D6aTrvswK7tduTDcWNZsmQJPQ/uRvu2rel5cDeWLl0KwE8//cSxRx7K7p3b06XDTjw+9JEs1z5Nyv7OtazxwJsFJ/Ttx4svv5btauSMatWqccNNtzDlky94Z8w4/nP/PXzx+edcdslFXHbFlYyfNIUrBl3NZZdclO2qZszAf57H37odwMSpn/P+hx+xXZvtuW3wjey9z3589OlX7L3Pftw2+EYAHvzPvbRuswPvf/gRr4x6k8sGXsjKlSuz/Ao2XAnuXCt3PPBmwR577kWDBg2yXY2ckZeXR/sOYQCoOnXq0KbN9syZMxtJLFu2DAiturzGjbNZzYxZtmwZ7495jxP7nQJA9erVqVevHiNfHsFxx58IwHHHn8grL4Vup5JYsWI5ZsaKn1dQv34DqlUr/1lEKbWlPCr/n46rUL6fMYMpUz5i185duPmW2+lx8AFccvE/Wbt2LW+9+0G2q5cRM777loYNG/H3ASfzyScf0659B24cfDsLF8xny7w8ALbMy2PhwnCj1YDTz6T3UYfReuumrFi+nEceG0aVKuW/TVVOY2pKsvbpSFoTx8ZMLC2S1t0habakKkll/STdXcBxZkhqmJlau7K0YsUKeh9zJDffcjt169blgf/cx02Db2P6dzO5afBtnDHglGxXMSNWr17N1CmTOaX/6YwZN4lNam2yLq1QkDdGj2KnnXfhq29n8d74yfzz/HPWfVMot5S+O9dyUTb/LP4ax8ZMLDMAYrA9nDAK0F5ZrJ/LoFWrVtH7mCM5tncfDjv8CACeeGzIusdHHnU0EydUjotrTZo0pUmTpnTq3AWAnocfydQpk2m0+RbMmzsXgHlz59KoURhM64nHHqVHz8ORxDbbbMtWLVoy7auixoDJfeGW4YqbasjF7yN/JdxHfR/QO8t1cRlgZpze/xRat9mec8+/YF15XuPGvPfuOwC8/dabbLttq2xVMaO22HJLmjRtxrSvvwLgnbffpHWbHTjw4B48+fhQAJ58fCgHHXIoAE2bNeedt98EYMH8+Uz/+itatNw6O5VPowrcqSGrOd6NJU2Jj78zs8Pj497AMMKAFf+WtJGZrdqQE8XxNwcANGvefEMOlRYnHt+b9955m0WLFrFNi6Zc8a+r6Hdy5fgaXZAP3n+fJ594jLZtd6JLx3YAXHXtv7nnvge58IJzWb16NTVq1uTu+x7Ick0z56Zb7+DUk05g1cqVtGjRknseeBhbu5a+x/fisSEP07RZc4Y88RQAFw28nDMGnMRfOu2CmXHVddezWcMKkH0rr1E1BQq3JWfhxNIKM6udr6w6MANobWbLJT0PPGRmr0jqB3Qys7Py7TMjli9K5bwdO3ay98dPTMdLcJXMytVrs12FnLX37p35aNLEtIXKtrt0sGdfG5PStts33mRSCuPx5pRc69XQHdgU+CQmzWsRRgd6JZuVcs5lXnnN36Yi1wJvb+BUMxsG68bO/E5SrexWyzmXaRU58ObMxbUYXA8gqXVrZj8DY4AesaifpFlJS9NY/nFS2a2ZrblzLt3ChbOKe+da1lq8+fO7ZvYL8KfbuczsiKSnjxZwqBZprZhzLvvKcVexVORMi9c555KlqzuZpGaS3pL0haTPJJ0bywfFG7USN3EdlLTPJZKmS/pK0gFJ5d1j2XRJA0v72nItx+ucc0H6WryrgX+Y2eQ499okSaPjutvMbPB6p5V2AHoBOwKNgdclbRdX3wPsT5j4coKkEWb2eUkr5IHXOZeDRJU05RriRJVz4+Plkr4AmhSxS09guJn9Tri4P50wKzHA9DiVEJKGx21LHHg91eCcyzmpphlKGprjmDDtgfGx6CxJH0t6OM4cDCEoz0zabVYsK6y8xDzwOudyU+qRt6GkiUnLgAIPJ9UGngPOM7NlhGEJtgHaEVrEtySdOT8rorzEPNXgnMtJJegqtqi4O9ckbUQIuk+Y2fMAZjY/af2DwMvx6SygWdLuTYE58XFh5SXiLV7nXE5K1+hkCrfBPgR8YWa3JpXnJW12OGFwLoARQC9JNSS1BFoBHwITgFaSWsbhDXrFbUvMW7zOudyjtE52uTtwAmEogsTAXJcCvSW1I6QLZgCnAZjZZ5KeJlw0Ww2caWZrACSdBYwCqgIPm9lnpamQB17nXI5KW6+GMYUcbGQR+1wHXFdA+cii9kuVB17nXM5JDIReUXngdc7lpAocdz3wOudyk7d4nXMuw8rrRJap8MDrnMtJFTfseuB1zuWg8jyDcCo88DrnclJ5HeQ8FR54nXO5qeLGXQ+8zrnclMY713KOB17nXA4qv/OppcIDr3Mu51T0O9d8dDLnnMswb/E653JSRW7xeuB1zuUekbY513KRB17nXM4pzXxq5YkHXudcbqrAkdcDr3MuJ3l3Muecy7AKnOL1wOucy00eeJ1zLsMqcqpBZpbtOmSUpIXA99muR9QQWJTtSuQwf38Kl2vvzVZm1ihdB5P0GuE1pmKRmXVP17kzodIF3lwiaaKZdcp2PXKVvz+F8/emfPNbhp1zLsM88DrnXIZ54M2uB7JdgRzn70/h/L0pxzzH65xzGeYtXuecyzAPvM45l2EeeF25I6lWtuvg3IbwwOvKFUn7AedIqpntujhXWh54c4CkHSV5Z/hiSDoAuAUYY2a/Zbs+zpWWB94sk3Qg8ChwgqTWWa5OzpLUDRgJ3G9mYyRtlO06OVda3p0siyQdBNwMnGRmHyaV1zazFdmrWW6JLd1/A+8DxwCHmtmHkqqa2Zrs1i57JO0B7G5mN2a7Lq5kfHSyLJAkoCZwLPCPfEF3MGCS7jKzH7JVx1whqT5wFHCemb0n6UtglKT9zWxiJQ++C4GzJK01s5sThZJk3qLKaZ5qyAILfiW8/4qBGEnHA3sDLYAzY9CptCRtCvwEnBGDbhUzuxe4BBgtqZOZrZFUNbs1zTxJ1czsK2A/4GRJF8dyJW2zq6Q62aqjK5wH3gyTtJ+kC2OOciWwjZmZpCrAZDPb1cyOBtoCW2e1slkk6RDgWWA8cIikasTfVzO7nxB8R0rqWplavIlAamarY/D9GugJ9JN0SfyjbpJOA+4CNslmfV3BPNWQIUlf/zoDK8xslaQHCcFjmZkNBT6P2x4ObATMyl6Nsyfmvq8GTgG6AhcB35rZx4nUgpndL2ljYJik7YHfK/rXa0ktgYslPWRmE5KDr6SewIuSFgG/ABcDR5jZvKxW2hXIA2+GJAWF2oSgipmNk9QLGC6pITAXqAucCfQys/lZqWwWxffhUmCSmX0EfCRpE2BfSd+Y2c+Jbc3sNkmPVKKuZTWBecCJktaY2eQYfGskBd/XgVrAvmb2cVZr6wrlqYYMkNRW0oj4dAmwcSyXmf0POBBoRsjv7gIcZ2afZ6WyWSSppZktAm4Hlks6J65qBxwHfCbpH5L6J+32U6brmS1m9gXwNDAHOFVSh7hqZfy5GtgX6ORBN7d5d7IMkFQbeBz4GfgAWG5mQ2Net7qZ/SZpEzP7OX51XJ3VCmeBpO6EnOQehK/KfwP2J+S6fwF6AQcTpoM5GehWGb4RSNqH8M30XTNbGct2Ag4BtgIeNLNJkgYAtwLbenoh93ngLUPxa/MaM1sqqQZwL3ASoYXyHNASECHFsAQ4DVhb0XOV+cWgexVwiZm9mcjjSuoBnAW8ama3J21fKf44xV4drxB+T24n/C7dGte1BPoAdYCqhEB8rJlNzVJ1XQl44C0j8QLRIGAGMM3MLotXpG8gtOb2JuR7twaWAsti96BKRdKuwFPAP83seUlbAfcBZxO+Uh8I7AUsNLPr4j6Vpp+qpIGEP8jnE/4IzQJeAN4kBNyLCWmYnmY2JVv1dCXjOd4yEFtwlwLXEe64ai6plpktB/4BTCSMOfCdmf0vXqGudEE32hL4DJgnqR0hJfOqmX0T+zqPAsYCDRP9mit60JW0ZVJ/3FuAVwnpqb8B1YHbgHcJf5BGAh096JYv3uJNM0kNCNNuH2lmL0jqDLxIaKVUNbPTJFUn9FFdZmbHZ7G6WZPcapV0HOGrcgdgiJldn7RdGzP7srLcRi3pYOBKQj57MSG/eymwAnie0GvhJMJNNvsCF5jZ4qxU1pWaB94yEP/zXAv0AwYTLqj9HyHYfmdmvWIXqU3NbE7WKpplkqonXTDqQbho9jDwvpktiXfyXQN0NrOFWaxqRsRvSpcB15nZa4n3R1IzYBIhNXWMmb0ct69lZr9kscqulLwfbxkws1ckrQE+Ai41sxtg3ViyL0raLLZSfi7qOBVRvCJ/LXBYDCrVzWylmb0kqS5wNLAmXjw6DjikkgTdBoS0wREx6G4D/EvShWY2U9LlwM5m9nLSe+ZBt5zyHG8ZMbPXgAOAkyTVi8VHE/rwrix0x4pvBrCK0B+VRPCNj58AXgLOAc4ABpjZZ1mqZ0aZ2RKgByHY7kyYRfgjM1sQN5kK7Cdpu8S3BFd+eeAtQ2Y2GjgPGCPp74Tc3IB4ka1SkbQlQHztfYCVkv4by9YFX8JX6qeAgypL0E0ws1cI+dwpwGgzuz0xAJCZjQeezGb9XPp4jjcD4oAvzwPtK1swgXCBjDAOxR3A52b2YMxx3wbkEcbXtXin2qmE210XZa/G2SVpf8LNJF3M7Kd4S/Dv2a6XSx8PvBlSmS+ExItDw4ERhGEM5xJatZ8SvhFsDrwDXEi4CeCjLFU1ZyjMTHI78JeYhnAViF9cy5DKGnQB4sWhDwndxQ4i5LoHAPUIAwI9AnTHB3ZZx8xejemX1xXm47OK3n+5MvEWrytTif66MYgMJbRw2xCC7euE0djWAFeb2ZfZq2luqiz9lysbb/G6MhWDrghjUkwnDOTSATjfzP4raTvC7cBLs1nPXOVBt2LyFq/LGIVZlN8D7jKza7JdH+eyxbuTuYyJ41FcDFSVVCvb9XEuWzzwukwbC3TMdiWcyyZPNbiMq8xd65wDD7zOOZdxnmpwzrkM88DrnHMZ5oHXOecyzAOvc85lmAdeB4CkNZKmSPpU0jMb0s9W0j6SErMkHBonbCxs23pxyMySnmOQpH+mWp5vm0clHVWCc7WQ9GlJ6+hcYTzwuoRfzaydmbUlDNR+evJKBSX+fTGzEYkZOApRDyhx4HWuPPPA6wryHrBtbOl9IeleYDLQTFI3SWMlTY4t49oQ5guT9KWkMcARiQNJ6ifp7vh4C0kvSJoal90I091vE1vbN8ftLpQ0QdLHkq5KOtZlkr6S9DrQurgXIal/PM5USc/la8X/TdJ7kr6O4yUjqaqkm5POfdqGvpHOFcQDr1uPpGrAgcAnsag1MNTM2hPmiLsc+JuZdSBMU3+BpJrAg4Spa/YkTNlekDuBd8xsF8JAOZ8BA4FvYmv7QkndgFZAZ6Ad0FHSXpI6Ar2A9oTAvmsKL+d5M9s1nu8L4JSkdS2AvQmz+d4fX8MpwE9mtms8fv8495tzaeWjk7mEjSVNiY/fAx4CGgPfm9m4WN4V2AF4Pww4RnXCLcBtCLMnTwOQ9DhhvN389gVOBDCzNcBPkurn26ZbXBKDodcmBOI6wAuJO94kjUjhNbWVdC0hnVEbGJW07mkzWwtMk/RtfA3dgJ2T8r+bxnN/ncK5nEuZB16X8KuZtUsuiME1eSZkEeYC651vu3ZAum6BFHC9mf0n3znOK8U5HiXMZjxVUj9gn6R1+Y9l8dxnm1lygEZSixKe17kiearBlcQ4YHdJ20IYcyGOp/sl0DJOSQ7Qu5D93yDMHpzIp9YFlhNaswmjgJOTcsdNJG0OvAscLmljSXUIaY3i1AHmStqIMMFmsqMlVYl13hr4Kp77jLg9kraLc8M5l1be4nUpM7OFseU4TFKNWHy5mX0taQDwiqRFwBigbQGHOBd4QNIphFknzjCzsZLej921Xo153u2BsbHFvQI43swmS3qKMAPv94R0SHGuAMbH7T9h/QD/FWGety2A083sN0n/R8j9To6Dty8EDkvt3XEudT5IjnPOZZinGpxzLsM88DrnXIZ54HXOuQzzwOuccxnmgdc55zLMA69zzmWYB17nnMuw/wfEVbpRJrOYzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results = ex_model_info['eval_results']\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "mlu.plot_confusion_matrix(eval_results, classes=['BKG', 'ALERT', 'FALL'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "mlu.plot_confusion_matrix(eval_results, classes=['BKG', 'ALERT', 'FALL'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'researchset1_model_id_9_fullmodel.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-5679e6fef1e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mex_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'researchset1_model_id_9_fullmodel.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweighted_categorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mex_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'researchset1_model_id_9_fullmodel.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "ex_model = load_model('researchset1_model_id_9_fullmodel.h5', custom_objects={'loss': mlu.weighted_categorical_crossentropy(target_weights)})\n",
    "ex_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
