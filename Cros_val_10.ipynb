{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.layers import CuDNNLSTM, CuDNNGRU, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json as js\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Import own methods\n",
    "\n",
    "import data_generator_modified as dg\n",
    "import ml_utils as mlu\n",
    "import rnn_generator as rnng\n",
    "\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking if GPU are avaliable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Units detected by tensorflow: \n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6424708338209615732\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2060943975155694549\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4341595800605275982\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10227318784\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10174727839573092421\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n",
      "GPUs used by keras:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "from keras import backend as K\n",
    "\n",
    "print(\"Process Units detected by tensorflow: \")\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "\n",
    "print(\"GPUs used by keras:\")\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading 10-fold organization.** It contains the user information to be used for k-fold and posterior test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group1': [['SA19', 'SA04'], ['SE13']], 'group2': [['SA21', 'SA01'], ['SE08']], 'group3': [['SA10', 'SA12'], ['SE09']], 'group4': [['SA13', 'SE06'], ['SE10']], 'group5': [['SA18', 'SA08'], ['SE15']], 'group6': [['SA14', 'SA09'], ['SE05']], 'group7': [['SA17', 'SA05'], ['SE01']], 'group8': [['SA07', 'SA16'], ['SE12']], 'group9': [['SA22', 'SA11'], ['SE03']], 'group10': [['SA23', 'SA06'], ['SE02']], 'test': [['SA03', 'SA15', 'SA20', 'SA02'], ['SE04', 'SE14', 'SE07', 'SE11']]}\n"
     ]
    }
   ],
   "source": [
    "import json as js\n",
    "\n",
    "with open(\"10_cross_validation_organization.json\") as json_file:  \n",
    "    cross_10_val_organization = js.load(json_file)\n",
    "    print(cross_10_val_organization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the data with data for train/val and test separated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Divided (train - test) found. Loading...\n",
      "\n",
      "Data loaded correctly\n",
      "\n",
      "Estructuring data in blocks...\n",
      "\n",
      "Data generated correctly\n"
     ]
    }
   ],
   "source": [
    "import data_generator_modified as dg\n",
    "\n",
    "dataCVWinValues, dataCVWinLabel, dataTestWinValues, dataTestWinLabel, dataWinOrganization = \\\n",
    "dg.loadDataSetInBlocks('../10_cross_validation/', nTestUsers=8, windowSize=256, stride=128, randomOrder = False, usersForValidation = cross_10_val_organization['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Checking the organization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SA02', 'SA03', 'SA15', 'SA20', 'SE04', 'SE07', 'SE11', 'SE14'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x[0] for x in dataWinOrganization['test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SA01',\n",
       " 'SA04',\n",
       " 'SA05',\n",
       " 'SA06',\n",
       " 'SA07',\n",
       " 'SA08',\n",
       " 'SA09',\n",
       " 'SA10',\n",
       " 'SA11',\n",
       " 'SA12',\n",
       " 'SA13',\n",
       " 'SA14',\n",
       " 'SA16',\n",
       " 'SA17',\n",
       " 'SA18',\n",
       " 'SA19',\n",
       " 'SA21',\n",
       " 'SA22',\n",
       " 'SA23',\n",
       " 'SE01',\n",
       " 'SE02',\n",
       " 'SE03',\n",
       " 'SE05',\n",
       " 'SE06',\n",
       " 'SE08',\n",
       " 'SE09',\n",
       " 'SE10',\n",
       " 'SE12',\n",
       " 'SE13',\n",
       " 'SE15'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x[0] for x in dataWinOrganization['train']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get only the accelerometer data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCVWinValues = dataCVWinValues[:,:,:3]\n",
    "dataTestWinValues = dataTestWinValues[:,:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94667, 256, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.shape(dataCVWinValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  19, -224,  -59],\n",
       "        [  21, -237,  -53],\n",
       "        [  22, -249,  -40],\n",
       "        ...,\n",
       "        [ -22, -292,  -52],\n",
       "        [ -33, -278,  -49],\n",
       "        [ -47, -269,  -47]],\n",
       "\n",
       "       [[ -38, -367,  -30],\n",
       "        [ -26, -358,  -33],\n",
       "        [ -11, -341,  -44],\n",
       "        ...,\n",
       "        [  58, -228,  -77],\n",
       "        [  63, -216,  -66],\n",
       "        [  72, -215,  -56]],\n",
       "\n",
       "       [[ -53, -261,  -35],\n",
       "        [ -60, -251,  -33],\n",
       "        [ -62, -241,  -17],\n",
       "        ...,\n",
       "        [ -49, -256,  -36],\n",
       "        [ -52, -256,  -29],\n",
       "        [ -51, -255,  -24]]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = np.take(dataCVWinValues,[1,2,3], axis=0)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tools for split a subset for val and the remaining k-1 subsets for train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Return info about the samples for each fold\n",
    "    1. The index of each sample corresponding to each fold (group)\n",
    "    2. The number of samples contained in each fold\n",
    "\"\"\"\n",
    "\n",
    "def subsets_samples_info(data_organization,cv_organization):\n",
    "    dict_indices = dict()\n",
    "    n_of_samples = dict()\n",
    "    list_of_groups = list(cv_organization.keys())\n",
    "    list_of_groups.pop(list_of_groups.index(\"test\"))\n",
    "    # print(list_of_groups)\n",
    "    \n",
    "    reverse_cv_org = dict()\n",
    "    for gr in list_of_groups:\n",
    "        for user in cv_organization[gr][0] + cv_organization[gr][1]:\n",
    "            reverse_cv_org[user] = gr\n",
    "        n_of_samples[gr] = 0\n",
    "        dict_indices[gr] = list()\n",
    "    # print(reverse_cv_org)\n",
    "    \n",
    "    for i in range(len(data_organization)):\n",
    "        group = reverse_cv_org[data_organization[i][0]]\n",
    "        n_of_samples[group] = n_of_samples[group] + 1\n",
    "        dict_indices[group].append(i)\n",
    "    \n",
    "    return (dict_indices, n_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicesCV, nSamples = subsets_samples_info(dataWinOrganization['train'],cross_10_val_organization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fold(data, data_indices, fold):\n",
    "    \n",
    "    val_subset = np.take(data, data_indices[fold], axis=0)\n",
    "    tr_indices = list()\n",
    "    \n",
    "    for gr in data_indices.keys():\n",
    "        if gr != fold:\n",
    "            tr_indices = tr_indices + data_indices[gr]\n",
    "    tr_subset = np.take(data, tr_indices, axis=0)\n",
    "    \n",
    "    return tr_subset, val_subset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrWinValues, dataValWinValues = generate_fold(dataCVWinValues, indicesCV, 'group10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9093, 256, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dataValWinValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9093"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nSamples['group10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \"\"\"\n",
    "def train_cv(dataTrValValues, dataTrValLabels, data_organization, cv_organization, arch_params, path):\n",
    "    \n",
    "    info_file_name = \"model_info.npy\"\n",
    "    model_last_epoch_file_name = \"model_last_epoch.hdf5\"\n",
    "    cv_results_file_name = \"cv_results.npy\"\n",
    "    \n",
    "    indicesCV, nSamples = subsets_samples_info(data_organization,cv_organization)\n",
    "    \n",
    "    cv_results = dict()\n",
    "    \n",
    "    first_fold = True\n",
    "    \n",
    "    for fold in indicesCV.keys():\n",
    "        \n",
    "        print(\"Fold # {}:\".format(fold))\n",
    "        \n",
    "        fullpath = os.path.join(path, fold)\n",
    "        if not(os.path.isdir(fullpath)):\n",
    "            # try:  \n",
    "            os.mkdir(fullpath)\n",
    "            \"\"\"except OSError:  \n",
    "                print (\"Creation of the directory {} failed\".format(fullpath))\n",
    "                return\n",
    "            else:  \n",
    "                print (\"Successfully created the directory {}\".format(fullpath\"\"\"\n",
    "        \n",
    "        info_file_path = os.path.join(fullpath, info_file_name)\n",
    "        model_last_epoch_file_path = os.path.join(fullpath, model_last_epoch_file_name)\n",
    "        \n",
    "        if not(os.path.isfile(info_file_path)): # The model training hasn't been done yet\n",
    "            \n",
    "            dataTrValues, dataValValues = generate_fold(dataTrValValues, indicesCV, fold)\n",
    "            dataTrlabels, dataValLabels = generate_fold(dataTrValLabels, indicesCV, fold)\n",
    "\n",
    "            aEpochs = arch_params['epochs']\n",
    "            aLR = arch_params['learning_rate']\n",
    "            aWin = arch_params['window_length']\n",
    "            aStride = arch_params['stride']\n",
    "            aBatchSize = arch_params['batch_size']\n",
    "            aRNNType = arch_params['rnn_type']\n",
    "            aSecondLayer = arch_params['second_rnn_layer']\n",
    "            aFirstDropout = arch_params['first_dropout']\n",
    "            aSecondDropout = arch_params['second_dropout']\n",
    "            aFirstDenseLayer = arch_params['first_dense_layer']\n",
    "\n",
    "            results = rnng.trainRNNModel(\n",
    "                            dataTrValues, dataTrlabels, dataValValues, dataValLabels, \n",
    "                            epochs = aEpochs, lr=aLR, w = aWin, stride = aStride, \n",
    "                            batch_size = aBatchSize, rnn_type = aRNNType, \n",
    "                            two_rnn_layers = aSecondLayer, drop_coeff_rnn = aFirstDropout, \n",
    "                            drop_coeff_dense = aSecondDropout, first_dense = aFirstDenseLayer,\n",
    "                            best_model=True, best_model_path=fullpath)\n",
    "            \n",
    "            model_performance_info = dict()\n",
    "            \n",
    "            for best_model_per_metric in results.keys():\n",
    "                \n",
    "                model, model_train_history, model_confusion_matrix = results[best_model_per_metric]\n",
    "            \n",
    "                train_info = model_train_history.history\n",
    "                metrics = mlu.macro_and_micro_metrics_per_class(model_confusion_matrix, ['BKG', 'ALERT', 'FALL'])\n",
    "                model_performance_info[best_model_per_metric] = { \n",
    "                                            'train_history' : train_info, \n",
    "                                            'eval_results' : model_confusion_matrix,\n",
    "                                            'metrics' : metrics,\n",
    "                                            'optional_data' : fold\n",
    "                                        }\n",
    "\n",
    "            np.save(info_file_path, model_performance_info)\n",
    "            \n",
    "            # TODO: verify\n",
    "            model.save(model_last_epoch_file_path)\n",
    "        \n",
    "        else:\n",
    "            print('{} fold was already validated. Loading results'.format(fold))\n",
    "            model_performance_info = np.load(info_file_path)[()]\n",
    "        print(\"\\n\")\n",
    "        ## TODO: consider improve the implementation with the option to select the metric (not fix f1-score micro)\n",
    "        \n",
    "        if(first_fold):\n",
    "            for best_model_per_metric in model_performance_info.keys():\n",
    "                cv_results[best_model_per_metric] = dict()\n",
    "                cv_results[best_model_per_metric]['f1-score_macro'] = dict()\n",
    "                cv_results[best_model_per_metric]['f1-score_micro'] = dict()\n",
    "                cv_results[best_model_per_metric]['balanced_accuracy'] = dict()\n",
    "            first_fold = False\n",
    "            \n",
    "        for best_model_per_metric in model_performance_info.keys():\n",
    "            \n",
    "            f1_score_m = model_performance_info[best_model_per_metric]['metrics']['macro']['f1-score']\n",
    "            cv_results[best_model_per_metric]['f1-score_macro'][fold] = (f1_score_m, 1- f1_score_m)\n",
    "            \n",
    "            f1_score_u = model_performance_info[best_model_per_metric]['metrics']['micro']['f1-score']\n",
    "            cv_results[best_model_per_metric]['f1-score_micro'][fold] = (f1_score_u, 1- f1_score_u)\n",
    "            \n",
    "            balanced_acc = model_performance_info[best_model_per_metric]['metrics']['macro']['recall']\n",
    "            cv_results[best_model_per_metric]['balanced_accuracy'][fold] = (balanced_acc, 1- balanced_acc)\n",
    "            \n",
    "        \n",
    "    dict_results = {\n",
    "                    'model_params' : arch_params,\n",
    "                    'results_per_best_metric' : dict()\n",
    "                   }\n",
    "        \n",
    "    for best_model_per_metric in cv_results.keys():\n",
    "        \n",
    "        dict_results['results_per_best_metric'][best_model_per_metric] = dict()\n",
    "        \n",
    "        for metric in cv_results[best_model_per_metric].keys():\n",
    "            \n",
    "            mean = np.mean([ r[0] for r in list(cv_results[best_model_per_metric][metric].values()) ])\n",
    "            error = np.mean([ r[1] for r in list(cv_results[best_model_per_metric][metric].values()) ])\n",
    "            sd = np.std([ r[0] for r in list(cv_results[best_model_per_metric][metric].values()) ])\n",
    "            sd_err = np.std([ r[1] for r in list(cv_results[best_model_per_metric][metric].values()) ])\n",
    "            \n",
    "            dict_results['results_per_best_metric'][best_model_per_metric][metric] = {\n",
    "                                                            'fold_results' : cv_results[best_model_per_metric][metric],\n",
    "                                                            'mean' : mean,\n",
    "                                                            'standard_deviation' : sd,\n",
    "                                                            'error' : error,\n",
    "                                                            'std_error' : sd_err\n",
    "                                                          }\n",
    "    \n",
    "    np.save(os.path.join(path, cv_results_file_name), dict_results)\n",
    "\n",
    "    return dict_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "            'epochs' : 2,\n",
    "            'learning_rate' : 0.001,\n",
    "            'window_length' : 256,\n",
    "            'stride' : 128,\n",
    "            'batch_size' : 64,\n",
    "            'rnn_type' : 'gru',\n",
    "            'second_rnn_layer' : False,\n",
    "            'first_dropout' : 0.2,\n",
    "            'second_dropout' : 0.2,\n",
    "            'first_dense_layer' : False\n",
    "        }\n",
    "\n",
    "# train_cv(dataCVWinValues, dataCVWinLabel, dataWinOrganization['train'],cross_10_val_organization, params, './cv_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_analysis_with_cv(study_name, path, data_cv_values, data_cv_labels, data_test_values, data_test_labels, data_organization, folds_organization, model_params_list):\n",
    "    \n",
    "    study_route = os.path.join(path, study_name)\n",
    "    \n",
    "    if not(os.path.isdir(study_route)):\n",
    "        os.mkdir(study_route)\n",
    "    \n",
    "    models_count = 1\n",
    "    model_metric_list = list()\n",
    "    for params in model_params_list:\n",
    "        \n",
    "        model_id = \"model{}\".format(models_count)\n",
    "        model_route = os.path.join(study_route, model_id)\n",
    "        \n",
    "        print(\"###### Model id: {} ######\".format(model_id))\n",
    "        \n",
    "        if not(os.path.isdir(model_route)):\n",
    "            os.mkdir(model_route)\n",
    "        \n",
    "        data_cv = data_cv_values\n",
    "        data_test = data_test_values\n",
    "        \n",
    "        frequency_reduction = params[\"frequency_reduction\"]\n",
    "        \n",
    "        for i in range(frequency_reduction):\n",
    "            data_cv = dg.reduce_frequency_of_window_samples(data_cv)\n",
    "            data_test = dg.reduce_frequency_of_window_samples(data_test)\n",
    "        \n",
    "        train_cv_info = train_cv(data_cv, data_cv_labels, data_organization['train'], folds_organization, params, model_route)\n",
    "        \n",
    "        print(train_cv_info)\n",
    "        for model_results_per_best_metric in train_cv_info['results_per_best_metric'].keys():\n",
    "            aux_results = [model_id, model_results_per_best_metric]\n",
    "            for metric_results in train_cv_info['results_per_best_metric'][model_results_per_best_metric].keys():\n",
    "                metrics_data = train_cv_info['results_per_best_metric'][model_results_per_best_metric][metric_results]\n",
    "                print(type(metrics_data))\n",
    "                aux_results = aux_results + [metrics_data['mean'],metrics_data['standard_deviation'], metrics_data['error'], metrics_data['std_error']]\n",
    "            \n",
    "            model_metric_list.append(aux_results)\n",
    "\n",
    "        models_count = models_count + 1\n",
    "    \n",
    "    basic_columns = ['model_id', 'best_metric']\n",
    "    f1_m_columns = ['f1-score_m mean', 'f1-score_m std', 'f1-score_m error', 'f1-score_m error std']\n",
    "    f1_u_columns = ['f1-score_u mean', 'f1-score_u std', 'f1-score_u error', 'f1-score_u error std']\n",
    "    balanced_acc_columns = ['balanced-accuracy mean', 'balanced-accuracy std', 'balanced-accuracy error', 'balanced-accuracy error std']\n",
    "    results = pd.DataFrame(data=model_metric_list, columns=basic_columns + f1_m_columns + f1_u_columns + balanced_acc_columns)\n",
    "    \n",
    "    return results\n",
    "        ## TODO: decide which model is the best and train the model with all cv folds as train data\n",
    "        ## TODO: extract the metrics of the trained model and save the results in a file\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_params_ls = [\n",
    "        {\n",
    "            'epochs' : 3,\n",
    "            'learning_rate' : 0.001,\n",
    "            'frequency_reduction' : 0,\n",
    "            'window_length' : 256,\n",
    "            'stride' : 128,\n",
    "            'batch_size' : 64,\n",
    "            'rnn_type' : 'gru',\n",
    "            'second_rnn_layer' : False,\n",
    "            'first_dropout' : 0.2,\n",
    "            'second_dropout' : 0.2,\n",
    "            'first_dense_layer' : False\n",
    "        },\n",
    "        {\n",
    "            'epochs' : 3,\n",
    "            'learning_rate' : 0.001,\n",
    "            'frequency_reduction' : 1,\n",
    "            'window_length' : 128,\n",
    "            'stride' : 64,\n",
    "            'batch_size' : 64,\n",
    "            'rnn_type' : 'gru',\n",
    "            'second_rnn_layer' : False,\n",
    "            'first_dropout' : 0.2,\n",
    "            'second_dropout' : 0.2,\n",
    "            'first_dense_layer' : False\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_ls = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Model id: model1 ######\n",
      "Fold # group1:\n",
      "group1 fold was already validated. Loading results\n",
      "\n",
      "\n",
      "Fold # group2:\n",
      "group2 fold was already validated. Loading results\n",
      "\n",
      "\n",
      "Fold # group3:\n",
      "group3 fold was already validated. Loading results\n",
      "\n",
      "\n",
      "Fold # group4:\n",
      "group4 fold was already validated. Loading results\n",
      "\n",
      "\n",
      "Fold # group5:\n",
      "group5 fold was already validated. Loading results\n",
      "\n",
      "\n",
      "Fold # group6:\n",
      "group6 fold was already validated. Loading results\n",
      "\n",
      "\n",
      "Fold # group7:\n",
      "group7 fold was already validated. Loading results\n",
      "\n",
      "\n",
      "Fold # group8:\n",
      "group8 fold was already validated. Loading results\n",
      "\n",
      "\n",
      "Fold # group9:\n",
      "group9 fold was already validated. Loading results\n",
      "\n",
      "\n",
      "Fold # group10:\n",
      "group10 fold was already validated. Loading results\n",
      "\n",
      "\n",
      "{'model_params': {'epochs': 3, 'learning_rate': 0.001, 'frequency_reduction': 0, 'window_length': 256, 'stride': 128, 'batch_size': 64, 'rnn_type': 'gru', 'second_rnn_layer': False, 'first_dropout': 0.2, 'second_dropout': 0.2, 'first_dense_layer': False}, 'results_per_best_metric': {'f1-macro': {'f1-score_macro': {'fold_results': {'group1': (0.46581986255075897, 0.534180137449241), 'group2': (0.4609007884427528, 0.5390992115572473), 'group3': (0.6183532978238637, 0.3816467021761363), 'group4': (0.4377897806039826, 0.5622102193960175), 'group5': (0.39206021675052777, 0.6079397832494722), 'group6': (0.36295347761108127, 0.6370465223889188), 'group7': (0.3685867138505805, 0.6314132861494195), 'group8': (0.39491201616771465, 0.6050879838322853), 'group9': (0.4416620338586538, 0.5583379661413461), 'group10': (0.5810500711819325, 0.4189499288180675)}, 'mean': 0.45240882588418485, 'standard_deviation': 0.0816355073897274, 'error': 0.5475911741158151, 'std_error': 0.0816355073897274}, 'f1-score_micro': {'fold_results': {'group1': (0.6784396415392725, 0.3215603584607275), 'group2': (0.7349499209277807, 0.26505007907221934), 'group3': (0.8758039008961518, 0.12419609910384821), 'group4': (0.7894570374275173, 0.21054296257248273), 'group5': (0.7272240085744909, 0.2727759914255091), 'group6': (0.6986548035165766, 0.3013451964834234), 'group7': (0.6439547108774768, 0.3560452891225232), 'group8': (0.6875065893516078, 0.3124934106483922), 'group9': (0.7830487033523087, 0.2169512966476913), 'group10': (0.8322885736280655, 0.16771142637193448)}, 'mean': 0.7451327890091248, 'standard_deviation': 0.06975937391343975, 'error': 0.2548672109908751, 'std_error': 0.06975937391343975}, 'balanced_accuracy': {'fold_results': {'group1': (0.805388012175173, 0.19461198782482703), 'group2': (0.6657292984884903, 0.3342707015115097), 'group3': (0.7294721555406399, 0.27052784445936007), 'group4': (0.6816046928466678, 0.3183953071533322), 'group5': (0.6025161291896479, 0.3974838708103521), 'group6': (0.5975468657748827, 0.4024531342251173), 'group7': (0.7279068589434559, 0.27209314105654414), 'group8': (0.743877198831448, 0.256122801168552), 'group9': (0.6680071647131777, 0.33199283528682233), 'group10': (0.6501156484610048, 0.3498843515389952)}, 'mean': 0.6872164024964588, 'standard_deviation': 0.06170060525694747, 'error': 0.31278359750354123, 'std_error': 0.06170060525694747}}, 'f1-micro': {'f1-score_macro': {'fold_results': {'group1': (0.46581986255075897, 0.534180137449241), 'group2': (0.4609007884427528, 0.5390992115572473), 'group3': (0.6183532978238637, 0.3816467021761363), 'group4': (0.4377897806039826, 0.5622102193960175), 'group5': (0.39206021675052777, 0.6079397832494722), 'group6': (0.36295347761108127, 0.6370465223889188), 'group7': (0.36498305285165406, 0.635016947148346), 'group8': (0.3624417143481393, 0.6375582856518607), 'group9': (0.4416620338586538, 0.5583379661413461), 'group10': (0.5626855881778215, 0.43731441182217845)}, 'mean': 0.4469649813019235, 'standard_deviation': 0.08207613410411392, 'error': 0.5530350186980765, 'std_error': 0.08207613410411392}, 'f1-score_micro': {'fold_results': {'group1': (0.6784396415392725, 0.3215603584607275), 'group2': (0.7349499209277807, 0.26505007907221934), 'group3': (0.8758039008961518, 0.12419609910384821), 'group4': (0.7894570374275173, 0.21054296257248273), 'group5': (0.7272240085744909, 0.2727759914255091), 'group6': (0.6986548035165766, 0.3013451964834234), 'group7': (0.7138091386979377, 0.2861908613020623), 'group8': (0.7105956773853452, 0.28940432261465476), 'group9': (0.7830487033523087, 0.2169512966476913), 'group10': (0.8785879247773012, 0.12141207522269881)}, 'mean': 0.7590570757094683, 'standard_deviation': 0.06749458357818473, 'error': 0.24094292429053174, 'std_error': 0.06749458357818473}, 'balanced_accuracy': {'fold_results': {'group1': (0.805388012175173, 0.19461198782482703), 'group2': (0.6657292984884903, 0.3342707015115097), 'group3': (0.7294721555406399, 0.27052784445936007), 'group4': (0.6816046928466678, 0.3183953071533322), 'group5': (0.6025161291896479, 0.3974838708103521), 'group6': (0.5975468657748827, 0.4024531342251173), 'group7': (0.5881123058542413, 0.41188769414575865), 'group8': (0.5752986361299003, 0.4247013638700997), 'group9': (0.6680071647131777, 0.33199283528682233), 'group10': (0.5744192126735307, 0.4255807873264693)}, 'mean': 0.6488094473386352, 'standard_deviation': 0.07221252955014501, 'error': 0.3511905526613649, 'std_error': 0.072212529550145}}, 'balanced-acc': {'f1-score_macro': {'fold_results': {'group1': (0.46581986255075897, 0.534180137449241), 'group2': (0.4609007884427528, 0.5390992115572473), 'group3': (0.6183532978238637, 0.3816467021761363), 'group4': (0.3655280079768089, 0.6344719920231912), 'group5': (0.375178494584383, 0.624821505415617), 'group6': (0.3594097484873779, 0.640590251512622), 'group7': (0.3685867138505805, 0.6314132861494195), 'group8': (0.39491201616771465, 0.6050879838322853), 'group9': (0.4416620338586538, 0.5583379661413461), 'group10': (0.5810500711819325, 0.4189499288180675)}, 'mean': 0.4431401034924827, 'standard_deviation': 0.08722853149382559, 'error': 0.5568598965075173, 'std_error': 0.08722853149382559}, 'f1-score_micro': {'fold_results': {'group1': (0.6784396415392725, 0.3215603584607275), 'group2': (0.7349499209277807, 0.26505007907221934), 'group3': (0.8758039008961518, 0.12419609910384821), 'group4': (0.6536636794939378, 0.3463363205060622), 'group5': (0.637620578778135, 0.36237942122186495), 'group6': (0.6267344560957526, 0.3732655439042474), 'group7': (0.6439547108774768, 0.3560452891225232), 'group8': (0.6875065893516078, 0.3124934106483922), 'group9': (0.7830487033523087, 0.2169512966476913), 'group10': (0.8322885736280655, 0.16771142637193448)}, 'mean': 0.715401075494049, 'standard_deviation': 0.08325985024817678, 'error': 0.2845989245059511, 'std_error': 0.08325985024817678}, 'balanced_accuracy': {'fold_results': {'group1': (0.805388012175173, 0.19461198782482703), 'group2': (0.6657292984884903, 0.3342707015115097), 'group3': (0.7294721555406399, 0.27052784445936007), 'group4': (0.7109123893324644, 0.28908761066753563), 'group5': (0.7752907906420968, 0.22470920935790317), 'group6': (0.7759145816413883, 0.22408541835861173), 'group7': (0.7279068589434559, 0.27209314105654414), 'group8': (0.743877198831448, 0.256122801168552), 'group9': (0.6680071647131777, 0.33199283528682233), 'group10': (0.6501156484610048, 0.3498843515389952)}, 'mean': 0.7252614098769338, 'standard_deviation': 0.04953295089999691, 'error': 0.2747385901230661, 'std_error': 0.04953295089999691}}}}\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "###### Model id: model2 ######\n",
      "Fold # group1:\n",
      "samples: {0: 81163, 1: 1021, 2: 2998} \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 128, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 85182 samples, validate on 9485 samples\n",
      "Epoch 1/3\n",
      "85182/85182 [==============================] - 18s 214us/step - loss: 2.5603 - acc: 0.4822 - val_loss: 2.5454 - val_acc: 0.6600\n",
      "[[5919  975 2116]\n",
      " [  81   37   33]\n",
      " [  13    7  304]]\n",
      " — val_micro_f1: 0.659989 — val_micro_precision: 0.659989 — val_micro_recall 0.659989\n",
      " — val_macro_f1: 0.356727 — val_macro_precision: 0.381536 — val_macro_recall 0.613414\n",
      "Epoch 2/3\n",
      "85182/85182 [==============================] - 11s 130us/step - loss: 2.1947 - acc: 0.5784 - val_loss: 1.7489 - val_acc: 0.8286\n",
      "[[7502 1159  349]\n",
      " [  48  100    3]\n",
      " [  58    9  257]]\n",
      " — val_micro_f1: 0.828571 — val_micro_precision: 0.828571 — val_micro_recall 0.828571\n",
      " — val_macro_f1: 0.531577 — val_macro_precision: 0.495645 — val_macro_recall 0.762697\n",
      "Epoch 3/3\n",
      "85182/85182 [==============================] - 11s 130us/step - loss: 1.5457 - acc: 0.7295 - val_loss: 1.7159 - val_acc: 0.8323\n",
      "[[7538 1433   39]\n",
      " [  34  115    2]\n",
      " [  66   17  241]]\n",
      " — val_micro_f1: 0.832261 — val_micro_precision: 0.832261 — val_micro_recall 0.832261\n",
      " — val_macro_f1: 0.611662 — val_macro_precision: 0.638333 — val_macro_recall 0.780681\n",
      "TP: 7538, FP: 100 and FN: 1472\n",
      "precision: 0.9869075674260278, recall: 0.8366259711431743 and f1-score: 0.9055742431523307\n",
      "TP: 115, FP: 1450 and FN: 36\n",
      "precision: 0.07348242811501597, recall: 0.7615894039735099 and f1-score: 0.13403263403263402\n",
      "TP: 241, FP: 41 and FN: 83\n",
      "precision: 0.8546099290780141, recall: 0.7438271604938271 and f1-score: 0.7953795379537955\n",
      "precision_u: 0.8322614654717976, recall_u: 0.8322614654717976 and f1-score_u: 0.8322614654717976\n",
      "TP: 7538, FP: 100 and FN: 1472\n",
      "precision: 0.9869075674260278, recall: 0.8366259711431743 and f1-score: 0.9055742431523307\n",
      "TP: 115, FP: 1450 and FN: 36\n",
      "precision: 0.07348242811501597, recall: 0.7615894039735099 and f1-score: 0.13403263403263402\n",
      "TP: 241, FP: 41 and FN: 83\n",
      "precision: 0.8546099290780141, recall: 0.7438271604938271 and f1-score: 0.7953795379537955\n",
      "precision_u: 0.8322614654717976, recall_u: 0.8322614654717976 and f1-score_u: 0.8322614654717976\n",
      "TP: 7538, FP: 100 and FN: 1472\n",
      "precision: 0.9869075674260278, recall: 0.8366259711431743 and f1-score: 0.9055742431523307\n",
      "TP: 115, FP: 1450 and FN: 36\n",
      "precision: 0.07348242811501597, recall: 0.7615894039735099 and f1-score: 0.13403263403263402\n",
      "TP: 241, FP: 41 and FN: 83\n",
      "precision: 0.8546099290780141, recall: 0.7438271604938271 and f1-score: 0.7953795379537955\n",
      "precision_u: 0.8322614654717976, recall_u: 0.8322614654717976 and f1-score_u: 0.8322614654717976\n",
      "\n",
      "\n",
      "Fold # group2:\n",
      "samples: {0: 81116, 1: 1082, 2: 2984} \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 128, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 85182 samples, validate on 9485 samples\n",
      "Epoch 1/3\n",
      "85182/85182 [==============================] - 12s 145us/step - loss: 2.5118 - acc: 0.4833 - val_loss: 2.1905 - val_acc: 0.6935\n",
      "[[6251  597 2209]\n",
      " [  40    7   43]\n",
      " [   4   14  320]]\n",
      " — val_micro_f1: 0.693516 — val_micro_precision: 0.693516 — val_micro_recall 0.693516\n",
      " — val_macro_f1: 0.351354 — val_macro_precision: 0.376251 — val_macro_recall 0.571569\n",
      "Epoch 2/3\n",
      "85182/85182 [==============================] - 11s 133us/step - loss: 1.8919 - acc: 0.6753 - val_loss: 1.9018 - val_acc: 0.8308\n",
      "[[7607 1436   14]\n",
      " [  48   40    2]\n",
      " [  86   19  233]]\n",
      " — val_micro_f1: 0.830785 — val_micro_precision: 0.830785 — val_micro_recall 0.830785\n",
      " — val_macro_f1: 0.583348 — val_macro_precision: 0.648396 — val_macro_recall 0.657899\n",
      "Epoch 3/3\n",
      "85182/85182 [==============================] - 11s 134us/step - loss: 1.4880 - acc: 0.7537 - val_loss: 1.8020 - val_acc: 0.7515\n",
      "[[6827 2214   16]\n",
      " [  43   44    3]\n",
      " [  69   12  257]]\n",
      " — val_micro_f1: 0.751502 — val_micro_precision: 0.751502 — val_micro_recall 0.751502\n",
      " — val_macro_f1: 0.576003 — val_macro_precision: 0.644801 — val_macro_recall 0.667675\n",
      "TP: 7607, FP: 134 and FN: 1450\n",
      "precision: 0.9826895749903113, recall: 0.839902837584189 and f1-score: 0.905703059888082\n",
      "TP: 40, FP: 1455 and FN: 50\n",
      "precision: 0.026755852842809364, recall: 0.4444444444444444 and f1-score: 0.050473186119873815\n",
      "TP: 233, FP: 16 and FN: 105\n",
      "precision: 0.9357429718875502, recall: 0.6893491124260355 and f1-score: 0.7938671209540034\n",
      "precision_u: 0.83078545071165, recall_u: 0.83078545071165 and f1-score_u: 0.83078545071165\n",
      "TP: 7607, FP: 134 and FN: 1450\n",
      "precision: 0.9826895749903113, recall: 0.839902837584189 and f1-score: 0.905703059888082\n",
      "TP: 40, FP: 1455 and FN: 50\n",
      "precision: 0.026755852842809364, recall: 0.4444444444444444 and f1-score: 0.050473186119873815\n",
      "TP: 233, FP: 16 and FN: 105\n",
      "precision: 0.9357429718875502, recall: 0.6893491124260355 and f1-score: 0.7938671209540034\n",
      "precision_u: 0.83078545071165, recall_u: 0.83078545071165 and f1-score_u: 0.83078545071165\n",
      "TP: 6827, FP: 112 and FN: 2230\n",
      "precision: 0.98385934572705, recall: 0.7537816053880976 and f1-score: 0.8535883970992748\n",
      "TP: 44, FP: 2226 and FN: 46\n",
      "precision: 0.019383259911894272, recall: 0.4888888888888889 and f1-score: 0.037288135593220334\n",
      "TP: 257, FP: 19 and FN: 81\n",
      "precision: 0.9311594202898551, recall: 0.7603550295857988 and f1-score: 0.8371335504885994\n",
      "precision_u: 0.7515023721665788, recall_u: 0.7515023721665788 and f1-score_u: 0.7515023721665788\n",
      "\n",
      "\n",
      "Fold # group3:\n",
      "samples: {0: 81099, 1: 1080, 2: 3003} \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_3 (Batch (None, 128, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_3 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 85182 samples, validate on 9485 samples\n",
      "Epoch 1/3\n",
      "85182/85182 [==============================] - 13s 151us/step - loss: 2.5379 - acc: 0.5010 - val_loss: 2.1102 - val_acc: 0.0471\n",
      "[[  91 6950 2033]\n",
      " [   3   70   19]\n",
      " [   0   33  286]]\n",
      " — val_micro_f1: 0.047127 — val_micro_precision: 0.047127 — val_micro_recall 0.047127\n",
      " — val_macro_f1: 0.084909 — val_macro_precision: 0.366779 — val_macro_recall 0.555817\n",
      "Epoch 2/3\n",
      "85182/85182 [==============================] - 12s 136us/step - loss: 2.0889 - acc: 0.5864 - val_loss: 1.4675 - val_acc: 0.6005\n",
      "[[5350 2981  743]\n",
      " [  19   72    1]\n",
      " [  13   32  274]]\n",
      " — val_micro_f1: 0.600527 — val_micro_precision: 0.600527 — val_micro_recall 0.600527\n",
      " — val_macro_f1: 0.398459 — val_macro_precision: 0.428849 — val_macro_recall 0.743713\n",
      "Epoch 3/3\n",
      "85182/85182 [==============================] - 12s 137us/step - loss: 1.5020 - acc: 0.7223 - val_loss: 1.0568 - val_acc: 0.7799\n",
      "[[7045 2005   24]\n",
      " [  22   70    0]\n",
      " [  19   18  282]]\n",
      " — val_micro_f1: 0.779863 — val_micro_precision: 0.779863 — val_micro_recall 0.779863\n",
      " — val_macro_f1: 0.612793 — val_macro_precision: 0.649742 — val_macro_recall 0.807092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 7045, FP: 41 and FN: 2029\n",
      "precision: 0.9942139429861699, recall: 0.7763940930130042 and f1-score: 0.8719059405940595\n",
      "TP: 70, FP: 2023 and FN: 22\n",
      "precision: 0.033444816053511704, recall: 0.7608695652173914 and f1-score: 0.06407322654462243\n",
      "TP: 282, FP: 24 and FN: 37\n",
      "precision: 0.9215686274509803, recall: 0.8840125391849529 and f1-score: 0.9024000000000001\n",
      "precision_u: 0.7798629414865578, recall_u: 0.7798629414865578 and f1-score_u: 0.7798629414865578\n",
      "TP: 7045, FP: 41 and FN: 2029\n",
      "precision: 0.9942139429861699, recall: 0.7763940930130042 and f1-score: 0.8719059405940595\n",
      "TP: 70, FP: 2023 and FN: 22\n",
      "precision: 0.033444816053511704, recall: 0.7608695652173914 and f1-score: 0.06407322654462243\n",
      "TP: 282, FP: 24 and FN: 37\n",
      "precision: 0.9215686274509803, recall: 0.8840125391849529 and f1-score: 0.9024000000000001\n",
      "precision_u: 0.7798629414865578, recall_u: 0.7798629414865578 and f1-score_u: 0.7798629414865578\n",
      "TP: 7045, FP: 41 and FN: 2029\n",
      "precision: 0.9942139429861699, recall: 0.7763940930130042 and f1-score: 0.8719059405940595\n",
      "TP: 70, FP: 2023 and FN: 22\n",
      "precision: 0.033444816053511704, recall: 0.7608695652173914 and f1-score: 0.06407322654462243\n",
      "TP: 282, FP: 24 and FN: 37\n",
      "precision: 0.9215686274509803, recall: 0.8840125391849529 and f1-score: 0.9024000000000001\n",
      "precision_u: 0.7798629414865578, recall_u: 0.7798629414865578 and f1-score_u: 0.7798629414865578\n",
      "\n",
      "\n",
      "Fold # group4:\n",
      "samples: {0: 81148, 1: 1087, 2: 2947} \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_4 (Batch (None, 128, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_4 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 85182 samples, validate on 9485 samples\n",
      "Epoch 1/3\n",
      "85182/85182 [==============================] - 14s 160us/step - loss: 2.5037 - acc: 0.4940 - val_loss: 2.1363 - val_acc: 0.6512\n",
      "[[5812  902 2311]\n",
      " [  33   33   19]\n",
      " [   6   37  332]]\n",
      " — val_micro_f1: 0.651239 — val_micro_precision: 0.651239 — val_micro_recall 0.651239\n",
      " — val_macro_f1: 0.354157 — val_macro_precision: 0.384001 — val_macro_recall 0.639186\n",
      "Epoch 2/3\n",
      "85182/85182 [==============================] - 12s 138us/step - loss: 2.0337 - acc: 0.6154 - val_loss: 1.8101 - val_acc: 0.6599\n",
      "[[5901 1330 1794]\n",
      " [   4   65   16]\n",
      " [  40   42  293]]\n",
      " — val_micro_f1: 0.659884 — val_micro_precision: 0.659884 — val_micro_recall 0.659884\n",
      " — val_macro_f1: 0.370091 — val_macro_precision: 0.392386 — val_macro_recall 0.733297\n",
      "Epoch 3/3\n",
      "85182/85182 [==============================] - 12s 139us/step - loss: 1.5778 - acc: 0.7091 - val_loss: 2.0700 - val_acc: 0.7690\n",
      "[[7037 1984    4]\n",
      " [  23   62    0]\n",
      " [ 112   68  195]]\n",
      " — val_micro_f1: 0.769004 — val_micro_precision: 0.769004 — val_micro_recall 0.769004\n",
      " — val_macro_f1: 0.534919 — val_macro_precision: 0.663468 — val_macro_recall 0.676378\n",
      "TP: 7037, FP: 135 and FN: 1988\n",
      "precision: 0.9811767986614612, recall: 0.7797229916897507 and f1-score: 0.8689263443847626\n",
      "TP: 62, FP: 2052 and FN: 23\n",
      "precision: 0.0293282876064333, recall: 0.7294117647058823 and f1-score: 0.05638926784902229\n",
      "TP: 195, FP: 4 and FN: 180\n",
      "precision: 0.9798994974874372, recall: 0.52 and f1-score: 0.6794425087108015\n",
      "precision_u: 0.7690036900369004, recall_u: 0.7690036900369004 and f1-score_u: 0.7690036900369003\n",
      "TP: 7037, FP: 135 and FN: 1988\n",
      "precision: 0.9811767986614612, recall: 0.7797229916897507 and f1-score: 0.8689263443847626\n",
      "TP: 62, FP: 2052 and FN: 23\n",
      "precision: 0.0293282876064333, recall: 0.7294117647058823 and f1-score: 0.05638926784902229\n",
      "TP: 195, FP: 4 and FN: 180\n",
      "precision: 0.9798994974874372, recall: 0.52 and f1-score: 0.6794425087108015\n",
      "precision_u: 0.7690036900369004, recall_u: 0.7690036900369004 and f1-score_u: 0.7690036900369003\n",
      "TP: 5901, FP: 44 and FN: 3124\n",
      "precision: 0.9925988225399496, recall: 0.6538504155124654 and f1-score: 0.7883767535070141\n",
      "TP: 65, FP: 1372 and FN: 20\n",
      "precision: 0.04523312456506611, recall: 0.7647058823529411 and f1-score: 0.08541392904073587\n",
      "TP: 293, FP: 1810 and FN: 82\n",
      "precision: 0.1393247741321921, recall: 0.7813333333333333 and f1-score: 0.23648103309120258\n",
      "precision_u: 0.6598840274117027, recall_u: 0.6598840274117027 and f1-score_u: 0.6598840274117027\n",
      "\n",
      "\n",
      "Fold # group5:\n",
      "samples: {0: 81286, 1: 1049, 2: 3002} \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_5 (Batch (None, 128, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_5 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 85337 samples, validate on 9330 samples\n",
      "Epoch 1/3\n",
      "85337/85337 [==============================] - 15s 171us/step - loss: 2.5325 - acc: 0.4928 - val_loss: 2.2421 - val_acc: 0.6431\n",
      "[[5646  861 2380]\n",
      " [  50   45   28]\n",
      " [   1   10  309]]\n",
      " — val_micro_f1: 0.643087 — val_micro_precision: 0.643087 — val_micro_recall 0.643087\n",
      " — val_macro_f1: 0.354795 — val_macro_precision: 0.384634 — val_macro_recall 0.655596\n",
      "Epoch 2/3\n",
      "85337/85337 [==============================] - 12s 143us/step - loss: 2.1325 - acc: 0.5702 - val_loss: 1.5846 - val_acc: 0.7467\n",
      "[[6634 2239   14]\n",
      " [   9  114    0]\n",
      " [  40   61  219]]\n",
      " — val_micro_f1: 0.746731 — val_micro_precision: 0.746731 — val_micro_recall 0.746731\n",
      " — val_macro_f1: 0.578022 — val_macro_precision: 0.659936 — val_macro_recall 0.785896\n",
      "Epoch 3/3\n",
      "85337/85337 [==============================] - 12s 143us/step - loss: 1.5323 - acc: 0.7219 - val_loss: 1.0939 - val_acc: 0.8936\n",
      "[[7963  910   14]\n",
      " [  30   91    2]\n",
      " [  30    7  283]]\n",
      " — val_micro_f1: 0.893569 — val_micro_precision: 0.893569 — val_micro_recall 0.893569\n",
      " — val_macro_f1: 0.672369 — val_macro_precision: 0.676429 — val_macro_recall 0.840080\n",
      "TP: 7963, FP: 60 and FN: 924\n",
      "precision: 0.9925215006855291, recall: 0.8960279059300101 and f1-score: 0.9418095801301005\n",
      "TP: 91, FP: 917 and FN: 32\n",
      "precision: 0.09027777777777778, recall: 0.7398373983739838 and f1-score: 0.16091954022988506\n",
      "TP: 283, FP: 16 and FN: 37\n",
      "precision: 0.9464882943143813, recall: 0.884375 and f1-score: 0.91437802907916\n",
      "precision_u: 0.8935691318327974, recall_u: 0.8935691318327974 and f1-score_u: 0.8935691318327974\n",
      "TP: 7963, FP: 60 and FN: 924\n",
      "precision: 0.9925215006855291, recall: 0.8960279059300101 and f1-score: 0.9418095801301005\n",
      "TP: 91, FP: 917 and FN: 32\n",
      "precision: 0.09027777777777778, recall: 0.7398373983739838 and f1-score: 0.16091954022988506\n",
      "TP: 283, FP: 16 and FN: 37\n",
      "precision: 0.9464882943143813, recall: 0.884375 and f1-score: 0.91437802907916\n",
      "precision_u: 0.8935691318327974, recall_u: 0.8935691318327974 and f1-score_u: 0.8935691318327974\n",
      "TP: 7963, FP: 60 and FN: 924\n",
      "precision: 0.9925215006855291, recall: 0.8960279059300101 and f1-score: 0.9418095801301005\n",
      "TP: 91, FP: 917 and FN: 32\n",
      "precision: 0.09027777777777778, recall: 0.7398373983739838 and f1-score: 0.16091954022988506\n",
      "TP: 283, FP: 16 and FN: 37\n",
      "precision: 0.9464882943143813, recall: 0.884375 and f1-score: 0.91437802907916\n",
      "precision_u: 0.8935691318327974, recall_u: 0.8935691318327974 and f1-score_u: 0.8935691318327974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Fold # group6:\n",
      "samples: {0: 81162, 1: 1078, 2: 2986} \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_6 (Batch (None, 128, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_6 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 85226 samples, validate on 9441 samples\n",
      "Epoch 1/3\n",
      "85226/85226 [==============================] - 16s 184us/step - loss: 2.4329 - acc: 0.5532 - val_loss: 2.3786 - val_acc: 0.3264\n",
      "[[2733 4092 2186]\n",
      " [   1   74   19]\n",
      " [  10   51  275]]\n",
      " — val_micro_f1: 0.326448 — val_micro_precision: 0.326448 — val_micro_recall 0.326448\n",
      " — val_macro_f1: 0.231546 — val_macro_precision: 0.374809 — val_macro_recall 0.636327\n",
      "Epoch 2/3\n",
      "85226/85226 [==============================] - 13s 148us/step - loss: 2.0648 - acc: 0.5970 - val_loss: 1.7364 - val_acc: 0.6689\n",
      "[[5973 1508 1530]\n",
      " [   6   76   12]\n",
      " [  32   38  266]]\n",
      " — val_micro_f1: 0.668891 — val_micro_precision: 0.668891 — val_micro_recall 0.668891\n",
      " — val_macro_f1: 0.377315 — val_macro_precision: 0.395886 — val_macro_recall 0.754345\n",
      "Epoch 3/3\n",
      "85226/85226 [==============================] - 13s 150us/step - loss: 1.6051 - acc: 0.7206 - val_loss: 1.3375 - val_acc: 0.8508\n",
      "[[7704 1291   16]\n",
      " [  17   75    2]\n",
      " [  45   38  253]]\n",
      " — val_micro_f1: 0.850757 — val_micro_precision: 0.850757 — val_micro_recall 0.850757\n",
      " — val_macro_f1: 0.617381 — val_macro_precision: 0.659672 — val_macro_recall 0.801935\n",
      "TP: 7704, FP: 62 and FN: 1307\n",
      "precision: 0.992016482101468, recall: 0.8549550549328598 and f1-score: 0.9184001907373189\n",
      "TP: 75, FP: 1329 and FN: 19\n",
      "precision: 0.053418803418803416, recall: 0.7978723404255319 and f1-score: 0.10013351134846461\n",
      "TP: 253, FP: 18 and FN: 83\n",
      "precision: 0.933579335793358, recall: 0.7529761904761905 and f1-score: 0.8336079077429983\n",
      "precision_u: 0.850757335028069, recall_u: 0.850757335028069 and f1-score_u: 0.850757335028069\n",
      "TP: 7704, FP: 62 and FN: 1307\n",
      "precision: 0.992016482101468, recall: 0.8549550549328598 and f1-score: 0.9184001907373189\n",
      "TP: 75, FP: 1329 and FN: 19\n",
      "precision: 0.053418803418803416, recall: 0.7978723404255319 and f1-score: 0.10013351134846461\n",
      "TP: 253, FP: 18 and FN: 83\n",
      "precision: 0.933579335793358, recall: 0.7529761904761905 and f1-score: 0.8336079077429983\n",
      "precision_u: 0.850757335028069, recall_u: 0.850757335028069 and f1-score_u: 0.850757335028069\n",
      "TP: 7704, FP: 62 and FN: 1307\n",
      "precision: 0.992016482101468, recall: 0.8549550549328598 and f1-score: 0.9184001907373189\n",
      "TP: 75, FP: 1329 and FN: 19\n",
      "precision: 0.053418803418803416, recall: 0.7978723404255319 and f1-score: 0.10013351134846461\n",
      "TP: 253, FP: 18 and FN: 83\n",
      "precision: 0.933579335793358, recall: 0.7529761904761905 and f1-score: 0.8336079077429983\n",
      "precision_u: 0.850757335028069, recall_u: 0.850757335028069 and f1-score_u: 0.850757335028069\n",
      "\n",
      "\n",
      "Fold # group7:\n",
      "samples: {0: 80749, 1: 1028, 2: 2998} \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_7 (Batch (None, 128, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_7 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 84775 samples, validate on 9892 samples\n",
      "Epoch 1/3\n",
      "84775/84775 [==============================] - 17s 199us/step - loss: 2.5286 - acc: 0.5532 - val_loss: 2.3642 - val_acc: 0.4781\n",
      "[[4399 3208 1817]\n",
      " [  61   67   16]\n",
      " [   3   58  263]]\n",
      " — val_micro_f1: 0.478063 — val_micro_precision: 0.478063 — val_micro_recall 0.478063\n",
      " — val_macro_f1: 0.296479 — val_macro_precision: 0.377080 — val_macro_recall 0.581264\n",
      "Epoch 2/3\n",
      "84775/84775 [==============================] - 13s 153us/step - loss: 2.0002 - acc: 0.6245 - val_loss: 1.7716 - val_acc: 0.8003\n",
      "[[7555 1625  244]\n",
      " [  40  103    1]\n",
      " [  55   10  259]]\n",
      " — val_micro_f1: 0.800344 — val_micro_precision: 0.800344 — val_micro_recall 0.800344\n",
      " — val_macro_f1: 0.540011 — val_macro_precision: 0.520245 — val_macro_recall 0.772112\n",
      "Epoch 3/3\n",
      "84775/84775 [==============================] - 13s 153us/step - loss: 1.4726 - acc: 0.7286 - val_loss: 1.5470 - val_acc: 0.7691\n",
      "[[7252 2138   34]\n",
      " [  24  118    2]\n",
      " [  64   22  238]]\n",
      " — val_micro_f1: 0.769106 — val_micro_precision: 0.769106 — val_micro_recall 0.769106\n",
      " — val_macro_f1: 0.586205 — val_macro_precision: 0.636141 — val_macro_recall 0.774512\n",
      "TP: 7252, FP: 88 and FN: 2172\n",
      "precision: 0.9880108991825614, recall: 0.7695246179966044 and f1-score: 0.8651873061321881\n",
      "TP: 118, FP: 2160 and FN: 26\n",
      "precision: 0.05179982440737489, recall: 0.8194444444444444 and f1-score: 0.09744013212221304\n",
      "TP: 238, FP: 36 and FN: 86\n",
      "precision: 0.8686131386861314, recall: 0.7345679012345679 and f1-score: 0.7959866220735786\n",
      "precision_u: 0.7691063485644966, recall_u: 0.7691063485644966 and f1-score_u: 0.7691063485644967\n",
      "TP: 7555, FP: 95 and FN: 1869\n",
      "precision: 0.9875816993464053, recall: 0.8016765704584041 and f1-score: 0.8849713013939323\n",
      "TP: 103, FP: 1635 and FN: 41\n",
      "precision: 0.059263521288837745, recall: 0.7152777777777778 and f1-score: 0.10945802337938365\n",
      "TP: 259, FP: 245 and FN: 65\n",
      "precision: 0.5138888888888888, recall: 0.7993827160493827 and f1-score: 0.6256038647342994\n",
      "precision_u: 0.8003437120905782, recall_u: 0.8003437120905782 and f1-score_u: 0.8003437120905783\n",
      "TP: 7252, FP: 88 and FN: 2172\n",
      "precision: 0.9880108991825614, recall: 0.7695246179966044 and f1-score: 0.8651873061321881\n",
      "TP: 118, FP: 2160 and FN: 26\n",
      "precision: 0.05179982440737489, recall: 0.8194444444444444 and f1-score: 0.09744013212221304\n",
      "TP: 238, FP: 36 and FN: 86\n",
      "precision: 0.8686131386861314, recall: 0.7345679012345679 and f1-score: 0.7959866220735786\n",
      "precision_u: 0.7691063485644966, recall_u: 0.7691063485644966 and f1-score_u: 0.7691063485644967\n",
      "\n",
      "\n",
      "Fold # group8:\n",
      "samples: {0: 81129, 1: 1079, 2: 2974} \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_8 (Batch (None, 128, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_8 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 85182 samples, validate on 9485 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85182/85182 [==============================] - 18s 213us/step - loss: 2.5147 - acc: 0.5248 - val_loss: 2.2287 - val_acc: 0.1127\n",
      "[[ 682 6192 2170]\n",
      " [   6   75   12]\n",
      " [   4   32  312]]\n",
      " — val_micro_f1: 0.112704 — val_micro_precision: 0.112704 — val_micro_recall 0.112704\n",
      " — val_macro_f1: 0.127710 — val_macro_precision: 0.374185 — val_macro_recall 0.592804\n",
      "Epoch 2/3\n",
      "85182/85182 [==============================] - 13s 154us/step - loss: 2.0691 - acc: 0.6085 - val_loss: 1.6683 - val_acc: 0.8009\n",
      "[[7307 1163  574]\n",
      " [  21   68    4]\n",
      " [  73   53  222]]\n",
      " — val_micro_f1: 0.800949 — val_micro_precision: 0.800949 — val_micro_recall 0.800949\n",
      " — val_macro_f1: 0.458061 — val_macro_precision: 0.439253 — val_macro_recall 0.725684\n",
      "Epoch 3/3\n",
      "85182/85182 [==============================] - 13s 155us/step - loss: 1.4887 - acc: 0.7238 - val_loss: 1.1095 - val_acc: 0.8480\n",
      "[[7673 1352   19]\n",
      " [  14   77    2]\n",
      " [  27   28  293]]\n",
      " — val_micro_f1: 0.847970 — val_micro_precision: 0.847970 — val_micro_recall 0.847970\n",
      " — val_macro_f1: 0.633431 — val_macro_precision: 0.660218 — val_macro_recall 0.839440\n",
      "TP: 7673, FP: 41 and FN: 1371\n",
      "precision: 0.9946849883329012, recall: 0.8484077841662981 and f1-score: 0.9157417352906075\n",
      "TP: 77, FP: 1380 and FN: 16\n",
      "precision: 0.05284831846259437, recall: 0.8279569892473119 and f1-score: 0.09935483870967741\n",
      "TP: 293, FP: 21 and FN: 55\n",
      "precision: 0.9331210191082803, recall: 0.8419540229885057 and f1-score: 0.8851963746223565\n",
      "precision_u: 0.847970479704797, recall_u: 0.847970479704797 and f1-score_u: 0.847970479704797\n",
      "TP: 7673, FP: 41 and FN: 1371\n",
      "precision: 0.9946849883329012, recall: 0.8484077841662981 and f1-score: 0.9157417352906075\n",
      "TP: 77, FP: 1380 and FN: 16\n",
      "precision: 0.05284831846259437, recall: 0.8279569892473119 and f1-score: 0.09935483870967741\n",
      "TP: 293, FP: 21 and FN: 55\n",
      "precision: 0.9331210191082803, recall: 0.8419540229885057 and f1-score: 0.8851963746223565\n",
      "precision_u: 0.847970479704797, recall_u: 0.847970479704797 and f1-score_u: 0.847970479704797\n",
      "TP: 7673, FP: 41 and FN: 1371\n",
      "precision: 0.9946849883329012, recall: 0.8484077841662981 and f1-score: 0.9157417352906075\n",
      "TP: 77, FP: 1380 and FN: 16\n",
      "precision: 0.05284831846259437, recall: 0.8279569892473119 and f1-score: 0.09935483870967741\n",
      "TP: 293, FP: 21 and FN: 55\n",
      "precision: 0.9331210191082803, recall: 0.8419540229885057 and f1-score: 0.8851963746223565\n",
      "precision_u: 0.847970479704797, recall_u: 0.847970479704797 and f1-score_u: 0.847970479704797\n",
      "\n",
      "\n",
      "Fold # group9:\n",
      "samples: {0: 81106, 1: 1070, 2: 3005} \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_9 (Batch (None, 128, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_9 (CuDNNGRU)       (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 85181 samples, validate on 9486 samples\n",
      "Epoch 1/3\n",
      "85181/85181 [==============================] - 20s 237us/step - loss: 2.4948 - acc: 0.5144 - val_loss: 2.3300 - val_acc: 0.6243\n",
      "[[5605  957 2505]\n",
      " [  28   26   48]\n",
      " [  10   16  291]]\n",
      " — val_micro_f1: 0.624288 — val_micro_precision: 0.624288 — val_micro_recall 0.624288\n",
      " — val_macro_f1: 0.331138 — val_macro_precision: 0.373871 — val_macro_recall 0.597020\n",
      "Epoch 2/3\n",
      "85181/85181 [==============================] - 13s 155us/step - loss: 1.9633 - acc: 0.6169 - val_loss: 1.9817 - val_acc: 0.5784\n",
      "[[5154 1708 2205]\n",
      " [  10   49   43]\n",
      " [   6   27  284]]\n",
      " — val_micro_f1: 0.578431 — val_micro_precision: 0.578431 — val_micro_recall 0.578431\n",
      " — val_macro_f1: 0.325120 — val_macro_precision: 0.378845 — val_macro_recall 0.648242\n",
      "Epoch 3/3\n",
      "85181/85181 [==============================] - 13s 151us/step - loss: 1.4601 - acc: 0.7345 - val_loss: 1.6196 - val_acc: 0.8755\n",
      "[[7997 1034   36]\n",
      " [  25   63   14]\n",
      " [  22   50  245]]\n",
      " — val_micro_f1: 0.875501 — val_micro_precision: 0.875501 — val_micro_recall 0.875501\n",
      " — val_macro_f1: 0.612085 — val_macro_precision: 0.626531 — val_macro_recall 0.757502\n",
      "TP: 7997, FP: 47 and FN: 1070\n",
      "precision: 0.9941571357533565, recall: 0.8819896327340907 and f1-score: 0.9347203553269826\n",
      "TP: 63, FP: 1084 and FN: 39\n",
      "precision: 0.05492589363557106, recall: 0.6176470588235294 and f1-score: 0.1008807045636509\n",
      "TP: 245, FP: 50 and FN: 72\n",
      "precision: 0.8305084745762712, recall: 0.7728706624605678 and f1-score: 0.8006535947712418\n",
      "precision_u: 0.8755007379295804, recall_u: 0.8755007379295804 and f1-score_u: 0.8755007379295804\n",
      "TP: 7997, FP: 47 and FN: 1070\n",
      "precision: 0.9941571357533565, recall: 0.8819896327340907 and f1-score: 0.9347203553269826\n",
      "TP: 63, FP: 1084 and FN: 39\n",
      "precision: 0.05492589363557106, recall: 0.6176470588235294 and f1-score: 0.1008807045636509\n",
      "TP: 245, FP: 50 and FN: 72\n",
      "precision: 0.8305084745762712, recall: 0.7728706624605678 and f1-score: 0.8006535947712418\n",
      "precision_u: 0.8755007379295804, recall_u: 0.8755007379295804 and f1-score_u: 0.8755007379295804\n",
      "TP: 7997, FP: 47 and FN: 1070\n",
      "precision: 0.9941571357533565, recall: 0.8819896327340907 and f1-score: 0.9347203553269826\n",
      "TP: 63, FP: 1084 and FN: 39\n",
      "precision: 0.05492589363557106, recall: 0.6176470588235294 and f1-score: 0.1008807045636509\n",
      "TP: 245, FP: 50 and FN: 72\n",
      "precision: 0.8305084745762712, recall: 0.7728706624605678 and f1-score: 0.8006535947712418\n",
      "precision_u: 0.8755007379295804, recall_u: 0.8755007379295804 and f1-score_u: 0.8755007379295804\n",
      "\n",
      "\n",
      "Fold # group10:\n",
      "samples: {0: 81599, 1: 974, 2: 3001} \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_10 (Batc (None, 128, 3)            12        \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128, 3)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_10 (CuDNNGRU)      (None, 32)                3552      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 3,663\n",
      "Trainable params: 3,657\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "Train on 85574 samples, validate on 9093 samples\n",
      "Epoch 1/3\n",
      "85574/85574 [==============================] - 20s 232us/step - loss: 2.5567 - acc: 0.4966 - val_loss: 3.4077 - val_acc: 0.6862\n",
      "[[5924  565 2085]\n",
      " [ 107   28   63]\n",
      " [  21   12  288]]\n",
      " — val_micro_f1: 0.686242 — val_micro_precision: 0.686242 — val_micro_recall 0.686242\n",
      " — val_macro_f1: 0.362908 — val_macro_precision: 0.381119 — val_macro_recall 0.576512\n",
      "Epoch 2/3\n",
      "85574/85574 [==============================] - 13s 154us/step - loss: 2.0825 - acc: 0.5923 - val_loss: 3.3071 - val_acc: 0.6557\n",
      "[[5589  915 2070]\n",
      " [  53   81   64]\n",
      " [   9   20  292]]\n",
      " — val_micro_f1: 0.655669 — val_micro_precision: 0.655669 — val_micro_recall 0.655669\n",
      " — val_macro_f1: 0.377279 — val_macro_precision: 0.396372 — val_macro_recall 0.656868\n",
      "Epoch 3/3\n",
      "85574/85574 [==============================] - 13s 157us/step - loss: 1.6908 - acc: 0.6616 - val_loss: 2.6810 - val_acc: 0.8218\n",
      "[[7176 1391    7]\n",
      " [  77  119    2]\n",
      " [  90   53  178]]\n",
      " — val_micro_f1: 0.821841 — val_micro_precision: 0.821841 — val_micro_recall 0.821841\n",
      " — val_macro_f1: 0.579205 — val_macro_precision: 0.668422 — val_macro_recall 0.664159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 7176, FP: 167 and FN: 1398\n",
      "precision: 0.9772572518044396, recall: 0.8369489153254024 and f1-score: 0.9016774517811145\n",
      "TP: 119, FP: 1444 and FN: 79\n",
      "precision: 0.07613563659628919, recall: 0.601010101010101 and f1-score: 0.13515048268029528\n",
      "TP: 178, FP: 9 and FN: 143\n",
      "precision: 0.9518716577540107, recall: 0.5545171339563862 and f1-score: 0.7007874015748031\n",
      "precision_u: 0.8218409765753877, recall_u: 0.8218409765753877 and f1-score_u: 0.8218409765753877\n",
      "TP: 7176, FP: 167 and FN: 1398\n",
      "precision: 0.9772572518044396, recall: 0.8369489153254024 and f1-score: 0.9016774517811145\n",
      "TP: 119, FP: 1444 and FN: 79\n",
      "precision: 0.07613563659628919, recall: 0.601010101010101 and f1-score: 0.13515048268029528\n",
      "TP: 178, FP: 9 and FN: 143\n",
      "precision: 0.9518716577540107, recall: 0.5545171339563862 and f1-score: 0.7007874015748031\n",
      "precision_u: 0.8218409765753877, recall_u: 0.8218409765753877 and f1-score_u: 0.8218409765753877\n",
      "TP: 7176, FP: 167 and FN: 1398\n",
      "precision: 0.9772572518044396, recall: 0.8369489153254024 and f1-score: 0.9016774517811145\n",
      "TP: 119, FP: 1444 and FN: 79\n",
      "precision: 0.07613563659628919, recall: 0.601010101010101 and f1-score: 0.13515048268029528\n",
      "TP: 178, FP: 9 and FN: 143\n",
      "precision: 0.9518716577540107, recall: 0.5545171339563862 and f1-score: 0.7007874015748031\n",
      "precision_u: 0.8218409765753877, recall_u: 0.8218409765753877 and f1-score_u: 0.8218409765753877\n",
      "\n",
      "\n",
      "{'model_params': {'epochs': 3, 'learning_rate': 0.001, 'frequency_reduction': 1, 'window_length': 128, 'stride': 64, 'batch_size': 64, 'rnn_type': 'gru', 'second_rnn_layer': False, 'first_dropout': 0.2, 'second_dropout': 0.2, 'first_dense_layer': False}, 'results_per_best_metric': {'f1-macro': {'f1-score_macro': {'fold_results': {'group1': (0.6116621383795867, 0.3883378616204133), 'group2': (0.5833477889873198, 0.41665221101268024), 'group3': (0.612793055712894, 0.387206944287106), 'group4': (0.5349193736481954, 0.4650806263518046), 'group5': (0.6723690498130486, 0.32763095018695143), 'group6': (0.617380536609594, 0.382619463390406), 'group7': (0.5862046867759932, 0.41379531322400676), 'group8': (0.6334309828742137, 0.36656901712578627), 'group9': (0.6120848848872917, 0.38791511511270826), 'group10': (0.579205112012071, 0.42079488798792897)}, 'mean': 0.6043397609700207, 'standard_deviation': 0.0347129544507201, 'error': 0.39566023902997915, 'std_error': 0.034712954450720104}, 'f1-score_micro': {'fold_results': {'group1': (0.8322614654717976, 0.16773853452820242), 'group2': (0.83078545071165, 0.16921454928835), 'group3': (0.7798629414865578, 0.22013705851344223), 'group4': (0.7690036900369003, 0.23099630996309972), 'group5': (0.8935691318327974, 0.1064308681672026), 'group6': (0.850757335028069, 0.14924266497193095), 'group7': (0.7691063485644967, 0.23089365143550333), 'group8': (0.847970479704797, 0.152029520295203), 'group9': (0.8755007379295804, 0.12449926207041961), 'group10': (0.8218409765753877, 0.17815902342461232)}, 'mean': 0.8270658557342034, 'standard_deviation': 0.040980088847466234, 'error': 0.17293414426579665, 'std_error': 0.040980088847466234}, 'balanced_accuracy': {'fold_results': {'group1': (0.7806808452035038, 0.21931915479649622), 'group2': (0.6578987981515563, 0.3421012018484437), 'group3': (0.8070920658051163, 0.19290793419488372), 'group4': (0.6763782521318777, 0.32362174786812226), 'group5': (0.8400801014346646, 0.1599198985653354), 'group6': (0.8019345286115275, 0.19806547138847252), 'group7': (0.7745123212252056, 0.22548767877479436), 'group8': (0.8394395988007052, 0.16056040119929482), 'group9': (0.7575024513393961, 0.2424975486606039), 'group10': (0.6641587167639632, 0.3358412832360368)}, 'mean': 0.7599677679467517, 'standard_deviation': 0.06629251522513581, 'error': 0.24003223205324836, 'std_error': 0.06629251522513581}}, 'f1-micro': {'f1-score_macro': {'fold_results': {'group1': (0.6116621383795867, 0.3883378616204133), 'group2': (0.5833477889873198, 0.41665221101268024), 'group3': (0.612793055712894, 0.387206944287106), 'group4': (0.5349193736481954, 0.4650806263518046), 'group5': (0.6723690498130486, 0.32763095018695143), 'group6': (0.617380536609594, 0.382619463390406), 'group7': (0.5400110631692051, 0.4599889368307949), 'group8': (0.6334309828742137, 0.36656901712578627), 'group9': (0.6120848848872917, 0.38791511511270826), 'group10': (0.579205112012071, 0.42079488798792897)}, 'mean': 0.5997203986093419, 'standard_deviation': 0.03955478153840685, 'error': 0.400279601390658, 'std_error': 0.03955478153840685}, 'f1-score_micro': {'fold_results': {'group1': (0.8322614654717976, 0.16773853452820242), 'group2': (0.83078545071165, 0.16921454928835), 'group3': (0.7798629414865578, 0.22013705851344223), 'group4': (0.7690036900369003, 0.23099630996309972), 'group5': (0.8935691318327974, 0.1064308681672026), 'group6': (0.850757335028069, 0.14924266497193095), 'group7': (0.8003437120905783, 0.1996562879094217), 'group8': (0.847970479704797, 0.152029520295203), 'group9': (0.8755007379295804, 0.12449926207041961), 'group10': (0.8218409765753877, 0.17815902342461232)}, 'mean': 0.8301895920868116, 'standard_deviation': 0.03748448748617414, 'error': 0.1698104079131885, 'std_error': 0.03748448748617414}, 'balanced_accuracy': {'fold_results': {'group1': (0.7806808452035038, 0.21931915479649622), 'group2': (0.6578987981515563, 0.3421012018484437), 'group3': (0.8070920658051163, 0.19290793419488372), 'group4': (0.6763782521318777, 0.32362174786812226), 'group5': (0.8400801014346646, 0.1599198985653354), 'group6': (0.8019345286115275, 0.19806547138847252), 'group7': (0.7721123547618548, 0.2278876452381452), 'group8': (0.8394395988007052, 0.16056040119929482), 'group9': (0.7575024513393961, 0.2424975486606039), 'group10': (0.6641587167639632, 0.3358412832360368)}, 'mean': 0.7597277713004166, 'standard_deviation': 0.06624375194966384, 'error': 0.24027222869958345, 'std_error': 0.06624375194966384}}, 'balanced-acc': {'f1-score_macro': {'fold_results': {'group1': (0.6116621383795867, 0.3883378616204133), 'group2': (0.5760033610603649, 0.42399663893963513), 'group3': (0.612793055712894, 0.387206944287106), 'group4': (0.37009057187965083, 0.6299094281203492), 'group5': (0.6723690498130486, 0.32763095018695143), 'group6': (0.617380536609594, 0.382619463390406), 'group7': (0.5862046867759932, 0.41379531322400676), 'group8': (0.6334309828742137, 0.36656901712578627), 'group9': (0.6120848848872917, 0.38791511511270826), 'group10': (0.579205112012071, 0.42079488798792897)}, 'mean': 0.5871224380004708, 'standard_deviation': 0.07713709292571302, 'error': 0.4128775619995292, 'std_error': 0.07713709292571304}, 'f1-score_micro': {'fold_results': {'group1': (0.8322614654717976, 0.16773853452820242), 'group2': (0.7515023721665788, 0.24849762783342122), 'group3': (0.7798629414865578, 0.22013705851344223), 'group4': (0.6598840274117027, 0.3401159725882973), 'group5': (0.8935691318327974, 0.1064308681672026), 'group6': (0.850757335028069, 0.14924266497193095), 'group7': (0.7691063485644967, 0.23089365143550333), 'group8': (0.847970479704797, 0.152029520295203), 'group9': (0.8755007379295804, 0.12449926207041961), 'group10': (0.8218409765753877, 0.17815902342461232)}, 'mean': 0.8082255816171765, 'standard_deviation': 0.06596868259203496, 'error': 0.19177441838282352, 'std_error': 0.06596868259203496}, 'balanced_accuracy': {'fold_results': {'group1': (0.7806808452035038, 0.21931915479649622), 'group2': (0.6676751746209284, 0.3323248253790716), 'group3': (0.8070920658051163, 0.19290793419488372), 'group4': (0.7332965437329132, 0.2667034562670868), 'group5': (0.8400801014346646, 0.1599198985653354), 'group6': (0.8019345286115275, 0.19806547138847252), 'group7': (0.7745123212252056, 0.22548767877479436), 'group8': (0.8394395988007052, 0.16056040119929482), 'group9': (0.7575024513393961, 0.2424975486606039), 'group10': (0.6641587167639632, 0.3358412832360368)}, 'mean': 0.7666372347537924, 'standard_deviation': 0.0594358083216671, 'error': 0.23336276524620758, 'std_error': 0.0594358083216671}}}}\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "results = model_analysis_with_cv(\"short_test_gru_different_frequency\", \"../10_cross_validation\", \n",
    "                                 dataCVWinValues, dataCVWinLabel, dataTestWinValues, dataTestWinLabel, \n",
    "                                 dataWinOrganization, cross_10_val_organization, short_params_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>best_metric</th>\n",
       "      <th>f1-score_m mean</th>\n",
       "      <th>f1-score_m std</th>\n",
       "      <th>f1-score_m error</th>\n",
       "      <th>f1-score_m error std</th>\n",
       "      <th>f1-score_u mean</th>\n",
       "      <th>f1-score_u std</th>\n",
       "      <th>f1-score_u error</th>\n",
       "      <th>f1-score_u error std</th>\n",
       "      <th>balanced-accuracy mean</th>\n",
       "      <th>balanced-accuracy std</th>\n",
       "      <th>balanced-accuracy error</th>\n",
       "      <th>balanced-accuracy error std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model1</td>\n",
       "      <td>f1-macro</td>\n",
       "      <td>0.452409</td>\n",
       "      <td>0.081636</td>\n",
       "      <td>0.547591</td>\n",
       "      <td>0.081636</td>\n",
       "      <td>0.745133</td>\n",
       "      <td>0.069759</td>\n",
       "      <td>0.254867</td>\n",
       "      <td>0.069759</td>\n",
       "      <td>0.687216</td>\n",
       "      <td>0.061701</td>\n",
       "      <td>0.312784</td>\n",
       "      <td>0.061701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model1</td>\n",
       "      <td>f1-micro</td>\n",
       "      <td>0.446965</td>\n",
       "      <td>0.082076</td>\n",
       "      <td>0.553035</td>\n",
       "      <td>0.082076</td>\n",
       "      <td>0.759057</td>\n",
       "      <td>0.067495</td>\n",
       "      <td>0.240943</td>\n",
       "      <td>0.067495</td>\n",
       "      <td>0.648809</td>\n",
       "      <td>0.072213</td>\n",
       "      <td>0.351191</td>\n",
       "      <td>0.072213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model1</td>\n",
       "      <td>balanced-acc</td>\n",
       "      <td>0.443140</td>\n",
       "      <td>0.087229</td>\n",
       "      <td>0.556860</td>\n",
       "      <td>0.087229</td>\n",
       "      <td>0.715401</td>\n",
       "      <td>0.083260</td>\n",
       "      <td>0.284599</td>\n",
       "      <td>0.083260</td>\n",
       "      <td>0.725261</td>\n",
       "      <td>0.049533</td>\n",
       "      <td>0.274739</td>\n",
       "      <td>0.049533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model2</td>\n",
       "      <td>f1-macro</td>\n",
       "      <td>0.604340</td>\n",
       "      <td>0.034713</td>\n",
       "      <td>0.395660</td>\n",
       "      <td>0.034713</td>\n",
       "      <td>0.827066</td>\n",
       "      <td>0.040980</td>\n",
       "      <td>0.172934</td>\n",
       "      <td>0.040980</td>\n",
       "      <td>0.759968</td>\n",
       "      <td>0.066293</td>\n",
       "      <td>0.240032</td>\n",
       "      <td>0.066293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model2</td>\n",
       "      <td>f1-micro</td>\n",
       "      <td>0.599720</td>\n",
       "      <td>0.039555</td>\n",
       "      <td>0.400280</td>\n",
       "      <td>0.039555</td>\n",
       "      <td>0.830190</td>\n",
       "      <td>0.037484</td>\n",
       "      <td>0.169810</td>\n",
       "      <td>0.037484</td>\n",
       "      <td>0.759728</td>\n",
       "      <td>0.066244</td>\n",
       "      <td>0.240272</td>\n",
       "      <td>0.066244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model2</td>\n",
       "      <td>balanced-acc</td>\n",
       "      <td>0.587122</td>\n",
       "      <td>0.077137</td>\n",
       "      <td>0.412878</td>\n",
       "      <td>0.077137</td>\n",
       "      <td>0.808226</td>\n",
       "      <td>0.065969</td>\n",
       "      <td>0.191774</td>\n",
       "      <td>0.065969</td>\n",
       "      <td>0.766637</td>\n",
       "      <td>0.059436</td>\n",
       "      <td>0.233363</td>\n",
       "      <td>0.059436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_id   best_metric  f1-score_m mean  f1-score_m std  f1-score_m error  \\\n",
       "0   model1      f1-macro         0.452409        0.081636          0.547591   \n",
       "1   model1      f1-micro         0.446965        0.082076          0.553035   \n",
       "2   model1  balanced-acc         0.443140        0.087229          0.556860   \n",
       "3   model2      f1-macro         0.604340        0.034713          0.395660   \n",
       "4   model2      f1-micro         0.599720        0.039555          0.400280   \n",
       "5   model2  balanced-acc         0.587122        0.077137          0.412878   \n",
       "\n",
       "   f1-score_m error std  f1-score_u mean  f1-score_u std  f1-score_u error  \\\n",
       "0              0.081636         0.745133        0.069759          0.254867   \n",
       "1              0.082076         0.759057        0.067495          0.240943   \n",
       "2              0.087229         0.715401        0.083260          0.284599   \n",
       "3              0.034713         0.827066        0.040980          0.172934   \n",
       "4              0.039555         0.830190        0.037484          0.169810   \n",
       "5              0.077137         0.808226        0.065969          0.191774   \n",
       "\n",
       "   f1-score_u error std  balanced-accuracy mean  balanced-accuracy std  \\\n",
       "0              0.069759                0.687216               0.061701   \n",
       "1              0.067495                0.648809               0.072213   \n",
       "2              0.083260                0.725261               0.049533   \n",
       "3              0.040980                0.759968               0.066293   \n",
       "4              0.037484                0.759728               0.066244   \n",
       "5              0.065969                0.766637               0.059436   \n",
       "\n",
       "   balanced-accuracy error  balanced-accuracy error std  \n",
       "0                 0.312784                     0.061701  \n",
       "1                 0.351191                     0.072213  \n",
       "2                 0.274739                     0.049533  \n",
       "3                 0.240032                     0.066293  \n",
       "4                 0.240272                     0.066244  \n",
       "5                 0.233363                     0.059436  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
